[
  {
    "url": "https://arxiv.org/abs/2405.17556",
    "title": "Probabilistic Verification of Neural Networks using Branch and Bound",
    "published_date": "2024-05-27",
    "abstract": "Probabilistic verification of neural networks is concerned with formally analysing the output distribution of a neural network under a probability distribution of the inputs. Examples of probabilistic verification include verifying the demographic parity fairness notion or quantifying the safety of a neural network. We present a new algorithm for the probabilistic verification of neural networks based on an algorithm for computing and iteratively refining lower and upper bounds on probabilities over the outputs of a neural network. By applying state-of-the-art bound propagation and branch and bound techniques from non-probabilistic neural network verification, our algorithm significantly outpaces existing probabilistic verification algorithms, reducing solving times for various benchmarks from the literature from tens of minutes to tens of seconds. Furthermore, our algorithm compares favourably even to dedicated algorithms for restricted subsets of probabilistic verification. We complement our empirical evaluation with a theoretical analysis, proving that our algorithm is sound and, under mildly restrictive conditions, also complete when using a suitable set of heuristics.",
    "summary": "This paper introduces a novel branch-and-bound algorithm for probabilistic neural network verification, significantly improving upon existing methods by leveraging advanced bound propagation techniques to reduce computation time from minutes to seconds on various benchmarks. The algorithm is proven sound and, under certain conditions, complete."
  },
  {
    "url": "https://arxiv.org/abs/2401.11627",
    "title": "Tight Verification of Probabilistic Robustness in Bayesian Neural Networks",
    "published_date": "2024-01-21",
    "abstract": "We introduce two algorithms for computing tight guarantees on the probabilistic robustness of Bayesian Neural Networks (BNNs). Computing robustness guarantees for BNNs is a significantly more challenging task than verifying the robustness of standard Neural Networks (NNs) because it requires searching the parameters' space for safe weights. Moreover, tight and complete approaches for the verification of standard NNs, such as those based on Mixed-Integer Linear Programming (MILP), cannot be directly used for the verification of BNNs because of the polynomial terms resulting from the consecutive multiplication of variables encoding the weights. Our algorithms efficiently and effectively search the parameters' space for safe weights by using iterative expansion and the network's gradient and can be used with any verification algorithm of choice for BNNs. In addition to proving that our algorithms compute tighter bounds than the SoA, we also evaluate our algorithms against the SoA on standard benchmarks, such as MNIST and CIFAR10, showing that our algorithms compute bounds up to 40% tighter than the SoA.",
    "citation_count": 3,
    "summary": "This paper presents two novel algorithms for verifying the probabilistic robustness of Bayesian Neural Networks (BNNs), achieving significantly tighter robustness guarantees (up to 40% improvement) than existing methods by efficiently searching the weight space using iterative expansion and gradient information."
  },
  {
    "title": "Quantitative analysis of assertion violations in probabilistic programs",
    "abstract": "We consider the fundamental problem of deriving quantitative bounds on the probability that a given assertion is violated in a probabilistic program. We provide automated algorithms that obtain both lower and upper bounds on the assertion violation probability. The main novelty of our approach is that we prove new and dedicated fixed-point theorems which serve as the theoretical basis of our algorithms and enable us to reason about assertion violation bounds in terms of pre and post fixed-point functions. To synthesize such fixed-points, we devise algorithms that utilize a wide range of mathematical tools, including repulsing ranking supermartingales, Hoeffding's lemma, Minkowski decompositions, Jensen's inequality, and convex optimization. On the theoretical side, we provide (i) the first automated algorithm for lower-bounds on assertion violation probabilities, (ii) the first complete algorithm for upper-bounds of exponential form in affine programs, and (iii) provably and significantly tighter upper-bounds than the previous approaches. On the practical side, we show our algorithms can handle a wide variety of programs from the literature and synthesize bounds that are remarkably tighter than previous results, in some cases by thousands of orders of magnitude.",
    "published_date": "2020-11-30",
    "citation_count": 18,
    "url": "https://dl.acm.org/doi/10.1145/3453483.3454102",
    "summary": "This paper presents novel automated algorithms for computing both upper and lower bounds on the probability of assertion violations in probabilistic programs, leveraging new fixed-point theorems and a variety of mathematical techniques to achieve significantly tighter bounds than prior methods. The algorithms are shown to be effective on a range of benchmark programs."
  },
  {
    "title": "Relatively complete verification of probabilistic programs: an expressive language for expectation-based reasoning",
    "abstract": "We study a syntax for specifying quantitative assertions—functions mapping program states to numbers—for probabilistic program verification. We prove that our syntax is expressive in the following sense: Given any probabilistic program C, if a function f is expressible in our syntax, then the function mapping each initial state σ to the expected value of evaluated in the final states reached after termination of C on σ (also called the weakest preexpectation wp[C](f)) is also expressible in our syntax. As a consequence, we obtain a relatively complete verification system for reasoning about expected values and probabilities in the sense of Cook: Apart from proving a single inequality between two functions given by syntactic expressions in our language, given f, g, and C, we can check whether g ≼ wp[C](f).",
    "published_date": "2020-10-27",
    "citation_count": 20,
    "url": "https://dl.acm.org/doi/10.1145/3434320",
    "summary": "This paper introduces a syntax for specifying quantitative assertions about probabilistic programs, proving its expressiveness by showing that the weakest preexpectation of any expressible function is also expressible within the same syntax. This yields a relatively complete verification system for reasoning about expected values and probabilities in probabilistic programs."
  },
  {
    "url": "https://arxiv.org/pdf/2010.14548v2.pdf",
    "title": "Relatively complete verification of probabilistic programs: an expressive language for expectation-based reasoning",
    "published_date": "2020-10-27",
    "abstract": "We study a syntax for specifying quantitative assertions—functions mapping program states to numbers—for probabilistic program verification. We prove that our syntax is expressive in the following sense: Given any probabilistic program C, if a function f is expressible in our syntax, then the function mapping each initial state σ to the expected value of evaluated in the final states reached after termination of C on σ (also called the weakest preexpectation wp[C](f)) is also expressible in our syntax. As a consequence, we obtain a relatively complete verification system for reasoning about expected values and probabilities in the sense of Cook: Apart from proving a single inequality between two functions given by syntactic expressions in our language, given f, g, and C, we can check whether g ≼ wp[C](f).",
    "citation_count": 20,
    "summary": "The paper introduces a syntax for specifying quantitative assertions about probabilistic programs, proving its expressiveness by showing that the weakest preexpectation of any expressible function remains expressible within the system. This yields a relatively complete verification system for reasoning about expected values and probabilities in probabilistic programs."
  },
  {
    "url": "https://www.alignmentforum.org/posts/LkECxpbjvSifPfjnb/towards-guaranteed-safe-ai-a-framework-for-ensuring-robust-1",
    "author": "Joar Skalse",
    "title": "Towards Guaranteed Safe AI: A Framework for Ensuring Robust and Reliable AI Systems",
    "published_date": "2024-05-17",
    "summary": "There is no article provided to summarize."
  },
  {
    "url": "https://www.alignmentforum.org/posts/SyeQjjBoEC48MvnQC/formal-verification-heuristic-explanations-and-surprise",
    "author": "Jacob Hilton",
    "title": "Formal verification, heuristic explanations and surprise accounting",
    "published_date": "2024-06-25",
    "summary": "The article discusses the challenges of formally verifying neural network behavior, arguing that rigorous proofs are impractical for large networks due to the complexity of accounting for all possible interactions. Instead, the authors propose \"heuristic explanations,\" a less formal approach focused on quantifiable insights into network performance, exemplified by \"surprise accounting.\""
  },
  {
    "url": "https://www.alignmentforum.org/posts/B2bg677TaS4cmDPzL/limitations-on-formal-verification-for-ai-safety",
    "author": "Andrew Dickson",
    "title": "Limitations on Formal Verification for AI Safety",
    "published_date": "2024-08-19",
    "summary": "The article argues that applying formal verification to guarantee AI safety is currently impractical due to the inherent complexity of the real world and the limitations of modeling it with complete symbolic rule sets. The author expresses skepticism towards claims that formal verification can provide strong, near-term guarantees against major AI threats."
  }
]
[
  {
    "url": "https://arxiv.org/pdf/2103.06624.pdf",
    "title": "Beta-CROWN: Efficient Bound Propagation with Per-neuron Split Constraints for Neural Network Robustness Verification",
    "published_date": "2021-03-11",
    "abstract": "Bound propagation based incomplete neural network verifiers such as CROWN are very efficient and can significantly accelerate branch-and-bound (BaB) based complete verification of neural networks. However, bound propagation cannot fully handle the neuron split constraints introduced by BaB commonly handled by expensive linear programming (LP) solvers, leading to loose bounds and hurting verification efficiency. In this work, we develop $\\beta$-CROWN, a new bound propagation based method that can fully encode neuron splits via optimizable parameters $\\beta$ constructed from either primal or dual space. When jointly optimized in intermediate layers, $\\beta$-CROWN generally produces better bounds than typical LP verifiers with neuron split constraints, while being as efficient and parallelizable as CROWN on GPUs. Applied to complete robustness verification benchmarks, $\\beta$-CROWN with BaB is up to three orders of magnitude faster than LP-based BaB methods, and is notably faster than all existing approaches while producing lower timeout rates. By terminating BaB early, our method can also be used for efficient incomplete verification. We consistently achieve higher verified accuracy in many settings compared to powerful incomplete verifiers, including those based on convex barrier breaking techniques. Compared to the typically tightest but very costly semidefinite programming (SDP) based incomplete verifiers, we obtain higher verified accuracy with three orders of magnitudes less verification time. Our algorithm empowered the $\\alpha,\\!\\beta$-CROWN (alpha-beta-CROWN) verifier, the winning tool in VNN-COMP 2021. Our code is available at http://PaperCode.cc/BetaCROWN",
    "citation_count": 160,
    "summary": "Î²-CROWN is a novel bound propagation method for neural network robustness verification that efficiently handles neuron split constraints, significantly outperforming existing LP and SDP-based methods in speed and accuracy, achieving up to three orders of magnitude faster verification times on complete verification benchmarks. Its efficiency allows for both complete and incomplete verification with improved results compared to state-of-the-art techniques."
  },
  {
    "url": "https://arxiv.org/pdf/2011.13824v1.pdf",
    "title": "Fast and Complete: Enabling Complete Neural Network Verification with Rapid and Massively Parallel Incomplete Verifiers",
    "published_date": "2020-11-27",
    "abstract": "Formal verification of neural networks (NNs) is a challenging and important problem. Existing efficient complete solvers typically require the branch-and-bound (BaB) process, which splits the problem domain into sub-domains and solves each sub-domain using faster but weaker incomplete verifiers, such as Linear Programming (LP) on linearly relaxed sub-domains. In this paper, we propose to use the backward mode linear relaxation based perturbation analysis (LiRPA) to replace LP during the BaB process, which can be efficiently implemented on the typical machine learning accelerators such as GPUs and TPUs. However, unlike LP, LiRPA when applied naively can produce much weaker bounds and even cannot check certain conflicts of sub-domains during splitting, making the entire procedure incomplete after BaB. To address these challenges, we apply a fast gradient based bound tightening procedure combined with batch splits and the design of minimal usage of LP bound procedure, enabling us to effectively use LiRPA on the accelerator hardware for the challenging complete NN verification problem and significantly outperform LP-based approaches. On a single GPU, we demonstrate an order of magnitude speedup compared to existing LP-based approaches.",
    "citation_count": 150,
    "summary": "This paper presents a faster method for complete neural network verification by using a GPU-accelerated linear relaxation technique (LiRPA) within a branch-and-bound framework, overcoming limitations through bound tightening and strategic use of linear programming to achieve significant speedups over existing LP-based approaches. The resulting method demonstrates an order of magnitude performance improvement on a single GPU."
  },
  {
    "url": "https://arxiv.org/pdf/1903.06758.pdf",
    "title": "Algorithms for Verifying Deep Neural Networks",
    "published_date": "2019-03-15",
    "abstract": "Deep neural networks are widely used for nonlinear function approximation with applications ranging from computer vision to control. Although these networks involve the composition of simple arithmetic operations, it can be very challenging to verify whether a particular network satisfies certain input-output properties. This article surveys methods that have emerged recently for soundly verifying such properties. These methods borrow insights from reachability analysis, optimization, and search. We discuss fundamental differences and connections between existing algorithms. In addition, we provide pedagogical implementations of existing methods and compare them on a set of benchmark problems.",
    "citation_count": 368,
    "summary": "This paper surveys recent algorithms for verifying properties of deep neural networks, drawing on techniques from reachability analysis, optimization, and search, and offers comparisons via pedagogical implementations and benchmark results."
  },
  {
    "url": "https://arxiv.org/pdf/2107.12855.pdf",
    "title": "Neural Network Branch-and-Bound for Neural Network Verification",
    "published_date": "2021-07-27",
    "abstract": "Many available formal verification methods have been shown to be instances of a unified Branch-and-Bound (BaB) formulation. We propose a novel machine learning framework that can be used for designing an effective branching strategy as well as for computing better lower bounds. Specifically, we learn two graph neural networks (GNN) that both directly treat the network we want to verify as a graph input and perform forward-backward passes through the GNN layers. We use one GNN to simulate the strong branching heuristic behaviour and another to compute a feasible dual solution of the convex relaxation, thereby providing a valid lower bound. \nWe provide a new verification dataset that is more challenging than those used in the literature, thereby providing an effective alternative for testing algorithmic improvements for verification. Whilst using just one of the GNNs leads to a reduction in verification time, we get optimal performance when combining the two GNN approaches. Our combined framework achieves a 50\\% reduction in both the number of branches and the time required for verification on various convolutional networks when compared to several state-of-the-art verification methods. In addition, we show that our GNN models generalize well to harder properties on larger unseen networks.",
    "citation_count": 8,
    "summary": "This paper presents a novel neural network branch-and-bound method for neural network verification, using graph neural networks to learn both an improved branching strategy and tighter lower bounds, resulting in a 50% reduction in verification time compared to state-of-the-art methods. The approach also demonstrates good generalization to unseen networks and properties."
  },
  {
    "url": "https://arxiv.org/pdf/2006.10864.pdf",
    "title": "Effective Formal Verification of Neural Networks using the Geometry of Linear Regions",
    "published_date": "2020-06-18",
    "abstract": "Neural Networks (NNs) have increasingly apparent safety implications commensurate with their proliferation in real-world applications: both unanticipated as well as adversarial misclassifications can result in fatal outcomes. As a consequence, techniques of formal verification have been recognized as crucial to the design and deployment of safe NNs. In this paper, we introduce a new approach to formally verify the most commonly considered safety specification for ReLU NNs -- i.e. polytopic specifications on the input and output of the network. Like some other approaches, ours uses a relaxed convex program to mitigate the combinatorial complexity of the problem. However, unique in our approach is the way we exploit the geometry of neuronal activation regions to further prune the search space of relaxed neuron activations. In particular, conditioning on neurons from input layer to output layer, we can regard each relaxed neuron as having the simplest possible geometry for its activation region: a half-space.This paradigm can be leveraged to create a verification algorithm that is not only faster in general than competing approaches, but is also able to verify considerably more safety properties. For example, our approach completes the standard MNIST verification test bench 2.7-50 times faster than competing algorithms while still proving 14-30% more properties. We also used our framework to verify the safety of a neural network controlled autonomous robot in a structured environment, and observed a 1900 times speed up compared to existing methods.",
    "citation_count": 4,
    "summary": "This paper presents a novel formal verification method for ReLU neural networks that leverages the geometry of neuronal activation regions to efficiently verify polytopic specifications on network inputs and outputs. The resulting algorithm significantly outperforms existing methods in both speed and the number of verifiable safety properties, as demonstrated through experiments on MNIST and an autonomous robot control task."
  },
  {
    "title": "NEURODIFF: Scalable Differential Verification of Neural Networks using Fine-Grained Approximation",
    "abstract": "As neural networks make their way into safety-critical systems, where misbehavior can lead to catastrophes, there is a growing interest in certifying the equivalence of two structurally similar neural networks - a problem known as differential verification. For example, compression techniques are often used in practice for deploying trained neural networks on computationally- and energy-constrained devices, which raises the question of how faithfully the compressed network mimics the original network. Unfortunately, existing methods either focus on verifying a single network or rely on loose approximations to prove the equivalence of two networks. Due to overly conservative approximation, differential verification lacks scalability in terms of both accuracy and computational cost. To overcome these problems, we propose NEURODIFF, a symbolic and fine-grained approximation technique that drastically increases the accuracy of differential verification on feed-forward ReLU networks while achieving many orders-of-magnitude speedup. NEURODIFF has two key contributions. The first one is new convex approximations that more accurately bound the difference of two networks under all possible inputs. The second one is judicious use of symbolic variables to represent neurons whose difference bounds have accumulated significant error. We find that these two techniques are complementary, i.e., when combined, the benefit is greater than the sum of their individual benefits. We have evaluated NEURODIFF on a variety of differential verification tasks. Our results show that NEURODIFF is up to 1000X faster and 5X more accurate than the state-of-the-art tool.",
    "published_date": "2020-09-01",
    "citation_count": 33,
    "url": "https://dl.acm.org/doi/10.1145/3324884.3416560",
    "summary": "NEURODIFF is a novel differential verification technique for neural networks that uses fine-grained convex approximations and symbolic variables to significantly improve both the speed and accuracy of verifying the equivalence of two networks, achieving up to 1000x faster and 5x more accurate results than existing methods. This addresses the scalability limitations of current differential verification approaches."
  },
  {
    "title": "Quantitative Verification of Neural Networks and Its Security Applications",
    "abstract": "Neural networks are increasingly employed in safety-critical domains. This has prompted interest in verifying or certifying logically encoded properties of neural networks. Prior work has largely focused on checking existential properties, wherein the goal is to check whether there exists any input that violates a given property of interest. However, neural network training is a stochastic process, and many questions arising in their analysis require probabilistic and quantitative reasoning, i.e., estimating how many inputs satisfy a given property. To this end, our paper proposes a novel and principled framework to quantitative verification of logical properties specified over neural networks. Our framework is the first to provide PAC-style soundness guarantees, in that its quantitative estimates are within a controllable and bounded error from the true count. We instantiate our algorithmic framework by building a prototype tool called NPAQ that enables checking rich properties over binarized neural networks. We show how emerging security analyses can utilize our framework in 3 applications: quantifying robustness to adversarial inputs, efficacy of trojan attacks, and fairness/bias of given neural networks.",
    "published_date": "2019-06-25",
    "citation_count": 99,
    "url": "https://dl.acm.org/doi/10.1145/3319535.3354245",
    "summary": "This paper introduces a novel framework for quantitatively verifying logical properties of neural networks, providing PAC-style soundness guarantees for estimating the number of inputs satisfying a given property. The framework is applied to analyze neural network robustness, trojan attacks, and fairness, demonstrating its utility in security applications."
  },
  {
    "url": "https://www.alignmentforum.org/posts/SyeQjjBoEC48MvnQC/formal-verification-heuristic-explanations-and-surprise",
    "author": "Jacob Hilton",
    "title": "Formal verification, heuristic explanations and surprise accounting",
    "published_date": "2024-06-25",
    "summary": "The article discusses the challenges of formally verifying neural networks, arguing that proving guarantees for complex networks is unrealistic due to the need to account for all possible interactions. Instead, the authors propose \"heuristic explanations,\" which quantify the quality of explanations using \"surprise accounting\" to overcome the limitations of formal verification."
  }
]
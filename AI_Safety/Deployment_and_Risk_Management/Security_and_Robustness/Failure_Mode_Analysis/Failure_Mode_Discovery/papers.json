[
  {
    "url": "https://arxiv.org/abs/2411.12159",
    "title": "Sensor-fusion based Prognostics Framework for Complex Engineering Systems Exhibiting Multiple Failure Modes",
    "published_date": "2024-11-19",
    "abstract": "Complex engineering systems are often subject to multiple failure modes. Developing a remaining useful life (RUL) prediction model that does not consider the failure mode causing degradation is likely to result in inaccurate predictions. However, distinguishing between causes of failure without manually inspecting the system is nontrivial. This challenge is increased when the causes of historically observed failures are unknown. Sensors, which are useful for monitoring the state-of-health of systems, can also be used for distinguishing between multiple failure modes as the presence of multiple failure modes results in discriminatory behavior of the sensor signals. When systems are equipped with multiple sensors, some sensors may exhibit behavior correlated with degradation, while other sensors do not. Furthermore, which sensors exhibit this behavior may differ for each failure mode. In this paper, we present a simultaneous clustering and sensor selection approach for unlabeled training datasets of systems exhibiting multiple failure modes. The cluster assignments and the selected sensors are then utilized in real-time to first diagnose the active failure mode and then to predict the system RUL. We validate the complete pipeline of the methodology using a simulated dataset of systems exhibiting two failure modes and on a turbofan degradation dataset from NASA.",
    "summary": "This paper proposes a sensor-fusion-based prognostics framework that simultaneously clusters failure modes and selects relevant sensors from unlabeled data to improve remaining useful life (RUL) prediction in complex systems with multiple failure modes. The approach uses sensor data to diagnose the active failure mode before predicting RUL, validated through simulated and real-world datasets."
  },
  {
    "url": "https://arxiv.org/abs/2406.08221",
    "title": "FAIL: Analyzing Software Failures from the News Using LLMs",
    "published_date": "2024-06-12",
    "abstract": "Software failures inform engineering work, standards, regulations. For example, the Log4J vulnerability brought government and industry attention to evaluating and securing software supply chains. Retrospective failure analysis is thus a valuable line of software engineering research. Accessing private engineering records is difficult, so such analyses tend to use information reported by the news media. However, prior works in this direction have relied on manual analysis. That has limited the scale of their analyses. The community lacks automated support to enable such analyses to consider a wide range of news sources and incidents.To fill this gap, we propose the Failure Analysis Investigation with LLMs (FAIL) system. FAIL is a novel LLM-based pipeline that collects, analyzes, and summarizes software failures as reported in the news. FAIL groups articles that describe the same incidents. It then analyzes incidents using existing taxonomies for postmortems, faults, and system characteristics. To tune and evaluate FAIL, we followed the methods of prior works by manually analyzing 31 software failures. FAIL achieved an F1 score of 90% for collecting news about software failures, a V-measure of 0.98 for merging articles reporting on the same incident, and extracted 90% of the facts about failures. We then applied FAIL to a total of 137,427 news articles from 11 providers published between 2010 and 2022. FAIL identified and analyzed 2,457 distinct failures reported across 4,184 articles. Our findings include: (1) current generation of large language models are capable of identifying news articles that describe failures, and analyzing them according to structured taxonomies; (2) high recurrences of similar failures within organizations and across organizations; and (3) severity of the consequences of software failures have increased over the past decade. The full FAIL database is available so that researchers, engineers, and policymakers can learn from a diversity of software failures.CCS CONCEPTS• Software and its engineering → Software defect analysis.",
    "citation_count": 2,
    "summary": "FAIL is an LLM-based system that automatically analyzes news articles to identify, categorize, and summarize software failures, enabling large-scale retrospective analysis of incidents and revealing trends such as recurring failures and increasing severity over time. The system achieves high accuracy in identifying and analyzing failures, offering a valuable resource for researchers and practitioners."
  },
  {
    "url": "https://arxiv.org/pdf/2302.01032.pdf",
    "title": "A novel failure indexing approach with run-time values of program variables",
    "published_date": "2023-02-02",
    "abstract": "Failures with different root causes can disturb multi-fault localization significantly, therefore, dividing failures into distinct groups according to the responsible faults is highly important. In such a failure indexing task, the crux lies in the failure proximity, which involves two points, i.e., how to effectively represent failures (e.g., extract the signature of failures) and how to properly measure the distance between the proxies for those failures. Existing studies have proposed a variety of failure proximities. The prevalent of them extract signatures of failures from execution coverage or suspiciousness ranking lists, and accordingly employ the Euclid or the Kendall tau distances. However, such strategies may not properly reflect the essential characteristics of failures, thus resulting in unsatisfactory effectiveness. In this paper, we propose a new failure proximity, namely, program variable-based failure proximity, and based on which present a novel failure indexing approach. Specifically, the proposed approach utilizes the run-time values of program variables to represent failures, and designs a set of rules to measure the similarity between them. Experimental results demonstrate the competitiveness of the proposed approach: it can achieve 44.12% and 27.59% improvements in faults number estimation, as well as 47.30% and 26.93% improvements in clustering effectiveness, compared with the state-of-the-art technique in this field, in simulated and real-world environments, respectively.",
    "summary": "This paper introduces a novel failure indexing approach that uses run-time values of program variables to represent and measure the similarity of failures, significantly improving fault localization accuracy compared to existing methods based on execution coverage or suspiciousness rankings. The approach achieves substantial improvements in both fault estimation and clustering effectiveness in both simulated and real-world settings."
  },
  {
    "url": "https://arxiv.org/pdf/2210.08667.pdf",
    "title": "From Function to Failure",
    "published_date": "2022-10-17",
    "abstract": "Failure Mode Reasoning (FMR) is a method for formal analysis of system-related faults. The method was originally developed for identifying failure modes of safety-critical systems based on an analysis of their programs. In this paper, we generalize the method and present a mathematical framework for its use in model-based system and safety analyses. We explain the concepts, formalize the method, formulate models for example systems, and discuss the practical application of the method.",
    "summary": "This paper generalizes Failure Mode Reasoning (FMR), a method for analyzing system faults, providing a mathematical framework applicable to model-based system and safety analyses. The authors formalize the method, illustrate it with examples, and discuss its practical applications."
  },
  {
    "url": "https://arxiv.org/abs/2210.08728",
    "title": "Fault Injection based Failure Analysis of three CentOS-like Operating Systems",
    "published_date": "2022-10-17",
    "abstract": "The reliability of operating system (OS) has always been a major concern in the academia and industry. This paper studies how to perform OS failure analysis by fault injection based on the fault mode library. Firstly, we use the fault mode generation method based on Linux abstract hierarchy structure analysis to systematically define the Linux-like fault modes, construct a Linux fault mode library and develop a fault injection tool based on the fault mode library (FIFML). Then, fault injection experiments are carried out on three commercial Linux distributions, CentOS, Anolis OS and openEuler, to identify their reliability problems and give improvement suggestions. We also use the virtual file systems of these three OSs as experimental objects, to perform fault injection at levels of Light and Normal, measure the performance of 13 common file operations before and after fault injection.",
    "summary": "This paper analyzes the reliability of CentOS, Anolis OS, and openEuler by injecting faults based on a Linux fault mode library, identifying vulnerabilities in their virtual file systems and offering improvement suggestions. The study uses a custom fault injection tool (FIFML) to measure performance changes in common file operations after fault injection at different intensity levels."
  },
  {
    "url": "https://arxiv.org/pdf/2206.13562v1.pdf",
    "title": "Incorporating Failure Knowledge into Design Decisions for IoT Systems: A Controlled Experiment on Novices",
    "published_date": "2022-06-27",
    "abstract": "Internet of Things (IoT) systems allow software to directly interact with the physical world. Recent IoT failures can be attributed to recurring software design flaws, suggesting IoT software engineers may not be learning from past failures. We examine the use of failure stories to improve IoT system designs.We conducted an experiment to evaluate the influence of failure-related learning treatments on design decisions. Our experiment used a between-subjects comparison of novices (computer engineering students) completing a design questionnaire. There were three treatments: a control group (N=7); a group considering a set of design guidelines (N=8); and a group considering failure stories (proposed treatment, N=6). We measured their design decisions and their design rationales. All subjects made comparable decisions. Their rationales varied by treatment: subjects treated with guidelines and failure stories made greater use of criticality as a rationale, while subjects exposed to failure stories more frequently used safety as a rationale. Building on these findings, we suggest several research directions toward a failure-aware IoT engineering process.",
    "citation_count": 3,
    "summary": "A controlled experiment with novice engineering students found that incorporating failure stories into IoT system design education, compared to design guidelines alone, led to increased consideration of safety in design rationales, while both treatments improved consideration of criticality. The overall design decisions, however, remained largely unchanged across all groups."
  },
  {
    "url": "https://arxiv.org/pdf/2209.02930.pdf",
    "title": "Reflections on software failure analysis",
    "published_date": "2022-09-07",
    "abstract": "Failure studies are important in revealing the root causes, behaviors, and life cycle of defects in software systems. These studies either focus on understanding the characteristics of defects in specific classes of systems, or the characteristics of a specific type of defect in the systems it manifests in. Failure studies have influenced various software engineering research directions, especially in the area of software evolution, defect detection, and program repair. In this paper, we reflect on the conduct of failure studies in software engineering. We reviewed a sample of 52 failure study papers. We identified several recurring problems in these studies, some of which hinder the ability of software engineering community to trust or replicate the results. Based on our findings, we suggest future research directions, including identifying and analyzing failure causal chains, standardizing the conduct of failure studies, and tool support for faster defect analysis.",
    "citation_count": 11,
    "summary": "This paper reviews 52 software failure studies, identifying recurring methodological problems that limit reproducibility and trustworthiness, and proposes solutions including standardized methodologies, causal chain analysis, and improved tooling."
  },
  {
    "url": "https://www.lesswrong.com/posts/d9MkMeLWvoDEsqpQP/a-compilation-of-misuses-of-statistics",
    "author": "Younes Kamel",
    "title": "A compilation of misuses of statistics",
    "published_date": "2022-02-14",
    "summary": "The article highlights common statistical errors, primarily focusing on the misuse of Gaussian assumptions in modeling fat-tailed distributions and misinterpretations of p-values, base rates, and statistical power. These errors lead to flawed conclusions in various fields, including finance and science."
  }
]
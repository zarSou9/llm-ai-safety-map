[
  {
    "url": "https://www.lesswrong.com/posts/kyvCNgx9oAwJCuevo/deep-q-networks-explained",
    "author": "Jay Bailey",
    "title": "Deep Q-Networks Explained",
    "published_date": "2022-09-13"
  },
  {
    "url": "https://www.lesswrong.com/posts/rCP5iTYLtfcoC8NXd/self-organised-neural-networks-a-simple-natural-and",
    "author": "Dùúã",
    "title": "Self-Organised Neural Networks:\nA simple, natural and efficient way to intelligence",
    "published_date": "2022-01-01"
  },
  {
    "title": "Extended Data Pipeline for Circular Economy Monitoring",
    "abstract": "Circular economy (CE) and sustainability are high on the political agenda of governments nationally and internationally. Governments are developing instruments to stimulate the CE, but without monitoring in place, these measures can be subject to abuse, failing to achieve the desired effects. CE monitoring, however, is still a nascent topic in academic literature. In this paper we propose the concept of the extended data pipeline to support CE visibility. Governments, but also banks and auditing firms can use this visibility to monitor CE flows to design and evaluate instruments and measures to enhance the CE.",
    "published_date": "2021-06-09",
    "citation_count": 12,
    "url": "https://dl.acm.org/doi/10.1145/3463677.3463752"
  },
  {
    "title": "Choice of parallelism: multi-GPU driven pipeline for huge academic backbone network",
    "abstract": "Science Information Network (SINET) is a Japanese academic backbone network for more than 800 research institutions and universities. In this paper, we present a multi-GPU-driven pipeline for handling huge session data of SINET. Our pipeline consists of ELK stack, multi-GPU server, and Splunk. A multi-GPU server is responsible for two procedures: discrimination and histogramming. Discrimination is dividing session data into ingoing/outgoing with subnet mask calculation and network address matching. Histogramming is grouping ingoing/outgoing session data into bins with map-reduce. In our architecture, we use GPU for the acceleration of ingress/egress discrimination of session data. Also, we use a tiling design pattern for building a two-stage map-reduce of CPU and GPU. Our multi-GPU-driven pipeline has succeeded in processing huge workloads of about 1.2‚Äì1.6 billion session streams (500‚Äì650 GB) within 24 hours. GRAPHICAL ABSTRACT",
    "published_date": "2021-06-24",
    "citation_count": 2,
    "url": "https://www.tandfonline.com/doi/full/10.1080/17445760.2021.1941009"
  },
  {
    "title": "Big-Data Driven Digital Ecosystem Framework for Online Predictive Control",
    "abstract": "In this paper, Big-Data Driven Digital Ecosystem Framework (BDDDEF) for Online Predictive Control Systems is created. The proposed framework consists of different Agents, where each Agent is a distributed and virtual service. In our work, we provide solutions to the Big Data challenges in building Digital Ecosystems for Online Control including high volumes, velocity and variety of data, and the need for low data latency. We propose to use BDDDEF for building robust, reliable, fault-tolerant, scalable and high-loaded data pipelines for Online Predictive Control Systems. We review Big Data Main Systems for Online Predictive Control Architecture, review the literature for Digital Ecosystems design for Control Systems Online, design and describe main features, main architectural components and functional architecture of the framework, and finally, propose new Predictive Control methodology for Online Predictions.",
    "published_date": "2020-11-02",
    "citation_count": 1,
    "url": "https://dl.acm.org/doi/10.1145/3415958.3433077"
  },
  {
    "title": "Automotive Big Data Pipeline: Disaggregated Hyper-Converged Infrastructure vs Hyper-Converged Infrastructure",
    "abstract": "Big data disrupts everything it touches, but automotive is probably one of the top industries that enjoy and leverage the benefits. The Automotive Big Data Pipeline (ABDP) is a big data pipeline base on the automotive use case and is required to scale up agile and high performance in real-time or in batch. Nonetheless, there're many alternative infrastructure designs but lack of knowledge, which fits the best for the automotive domain. It leads this paper into a question: What kinds of infrastructure design could provide better performance for the ABDP?In this paper, we introduce two well-known infrastructure designs called Hyper-Converged infrastructure (HCI) and Disaggregated Hyper-Converged infrastructure (DHCI). HCI combines standard data center hardware using locally attached storage resources to create fast, common building blocks. However, does single standard hardware fit all the requirements? DHCI scale independently from compute and storage provides an option. It provides a more cost-efficient and flexible solution; however, there is no comparison from the performance point of view. Therefore, to address it, our objective is to conduct an empirical performance comparison to see which one performs better.The experiment result shows that DHCI performs almost the same as HCI on CPU utilization, memory, and network consumption. However, regarding storage and running time metrics, DHCI performs slightly higher storage throughput, IOPs, and less running time than HCI.",
    "published_date": "2020-12-10",
    "citation_count": 2,
    "url": "https://ieeexplore.ieee.org/document/9378045/"
  }
]
[
  {
    "url": "https://arxiv.org/abs/2402.13219",
    "title": "Analyzing Operator States and the Impact of AI-Enhanced Decision Support in Control Rooms: A Human-in-the-Loop Specialized Reinforcement Learning Framework for Intervention Strategies",
    "published_date": "2024-02-20",
    "abstract": "In complex industrial and chemical process control rooms, effective decision-making is crucial for safety and efficiency. The experiments in this paper evaluate the impact and applications of an AI-based decision support system integrated into an improved human-machine interface, using dynamic influence diagrams, a hidden Markov model, and deep reinforcement learning. The enhanced support system aims to reduce operator workload, improve situational awareness, and provide different intervention strategies to the operator adapted to the current state of both the system and human performance. Such a system can be particularly useful in cases of information overload when many alarms and inputs are presented all within the same time window, or for junior operators during training. A comprehensive cross-data analysis was conducted, involving 47 participants and a diverse range of data sources such as smartwatch metrics, eye-tracking data, process logs, and responses from questionnaires. The results indicate interesting insights regarding the effectiveness of the approach in aiding decision-making, decreasing perceived workload, and increasing situational awareness for the scenarios considered. Additionally, the results provide valuable insights to compare differences between styles of information gathering when using the system by individual participants. These findings are particularly relevant when predicting the overall performance of the individual participant and their capacity to successfully handle a plant upset and the alarms connected to it using process and human-machine interaction logs in real-time. These predictions enable the development of more effective intervention strategies.",
    "citation_count": 1,
    "summary": "This paper presents a human-in-the-loop reinforcement learning framework for AI-enhanced decision support in industrial control rooms, using diverse data sources to evaluate its impact on operator workload, situational awareness, and decision-making effectiveness. Results suggest the system improves operator performance, particularly in high-pressure situations, and informs the development of personalized intervention strategies."
  },
  {
    "url": "https://arxiv.org/abs/2410.07804",
    "title": "Intuitive interaction flow: A Dual-Loop Human-Machine Collaboration Task Allocation Model and an experimental study",
    "published_date": "2024-10-10",
    "abstract": "This study investigates the issue of task allocation in Human-Machine Collaboration (HMC) within the context of Industry 4.0. By integrating philosophical insights and cognitive science, it clearly defines two typical modes of human behavior in human-machine interaction(HMI): skill-based intuitive behavior and knowledge-based intellectual behavior. Building on this, the concept of 'intuitive interaction flow' is innovatively introduced by combining human intuition with machine humanoid intelligence, leading to the construction of a dual-loop HMC task allocation model. Through comparative experiments measuring electroencephalogram (EEG) and electromyogram (EMG) activities, distinct physiological patterns associated with these behavior modes are identified, providing a preliminary foundation for future adaptive HMC frameworks. This work offers a pathway for developing intelligent HMC systems that effectively integrate human intuition and machine intelligence in Industry 4.0.",
    "summary": "This paper proposes a dual-loop human-machine collaboration task allocation model based on intuitive and intellectual human behavior modes, supported by an experimental study using EEG and EMG to identify physiological patterns associated with each mode. The model aims to improve human-machine interaction by integrating human intuition with machine intelligence in Industry 4.0 settings."
  },
  {
    "url": "https://arxiv.org/abs/2408.10861",
    "title": "DVRP-MHSI: Dynamic Visualization Research Platform for Multimodal Human-Swarm Interaction",
    "published_date": "2024-08-20",
    "abstract": "In recent years, there has been a significant amount of research on algorithms and control methods for distributed collaborative robots. However, the emergence of collective behavior in a swarm is still difficult to predict and control. Nevertheless, human interaction with the swarm helps render the swarm more predictable and controllable, as human operators can utilize intuition or knowledge that is not always available to the swarm. Therefore, this paper designs the Dynamic Visualization Research Platform for Multimodal Human-Swarm Interaction (DVRP-MHSI), which is an innovative open system that can perform real-time dynamic visualization and is specifically designed to accommodate a multitude of interaction modalities (such as brain-computer, eye-tracking, electromyographic, and touch-based interfaces), thereby expediting progress in human-swarm interaction research. Specifically, the platform consists of custom-made low-cost omnidirectional wheeled mobile robots, multitouch screens and two workstations. In particular, the mutitouch screens can recognize human gestures and the shapes of objects placed on them, and they can also dynamically render diverse scenes. One of the workstations processes communication information within robots and the other one implements human-robot interaction methods. The development of DVRP-MHSI frees researchers from hardware or software details and allows them to focus on versatile swarm algorithms and human-swarm interaction methods without being limited to fixed scenarios, tasks, and interfaces. The effectiveness and potential of the platform for human-swarm interaction studies are validated by several demonstrative experiments.",
    "citation_count": 1,
    "summary": "DVRP-MHSI is an open-source platform for researching human-swarm interaction, offering real-time visualization and support for diverse interaction modalities (brain-computer, eye-tracking, EMG, touch) to facilitate the development and testing of swarm algorithms and human control strategies. Demonstrative experiments validate its effectiveness for human-swarm interaction studies."
  },
  {
    "url": "https://arxiv.org/abs/2403.01609",
    "title": "A \"User Experience 3.0 (UX 3.0)\" Paradigm Framework: User Experience Design for Human-Centered AI Systems",
    "published_date": "2024-03-03",
    "abstract": "The human-centered artificial intelligence (HCAI) design approach, the user-centered design (UCD) version in the intelligence era, has been promoted to address potential negative issues caused by AI technology; user experience design (UXD) is specifically called out to facilitate the design and development of human-centered AI systems. Over the last three decades, user experience (UX) practice can be divided into three stages in terms of technology platform, user needs, design philosophy, ecosystem, scope, focus, and methodology of UX practice. UX practice is moving towards the intelligence era. Still, the existing UX paradigm mainly aims at non-intelligent systems and lacks a systematic approach to address UX for designing and developing human-centered AI products and systems. The intelligence era has put forward new demands on the UX paradigm. This paper proposes a\"UX 3.0\"paradigm framework and the corresponding UX methodology for UX practice in the intelligence era. The\"UX 3.0\"paradigm framework includes four categories of emerging experiences in the intelligence era: ecosystem-based experience, innovation-enabled experience, AI-enabled experience, and human-AI interaction-based experience, each compelling us to enhance current UX practice in terms of design philosophy, scope, focus, and methodology. We believe that the\"UX 3.0\"paradigm helps enhance existing UX practice and provides methodological support for the research and applications of UX in developing human-centered AI systems. Finally, this paper looks forward to future work implementing the\"UX 3.0\"paradigm.",
    "summary": "This paper proposes a \"UX 3.0\" framework for designing human-centered AI systems, encompassing four new experience categories (ecosystem-based, innovation-enabled, AI-enabled, and human-AI interaction-based) to address the evolving needs of the intelligence era. This framework aims to enhance existing UX practices and provide a methodological approach for developing human-centered AI products."
  },
  {
    "url": "https://www.alignmentforum.org/posts/F24kibEdEvRSo7PFi/human-ai-complementarity-a-goal-for-amplified-oversight",
    "author": "rishubjain",
    "title": "Human-AI Complementarity: A Goal for Amplified Oversight",
    "published_date": "2024-12-24",
    "summary": "Amplified oversight, using AI to enhance human evaluation of increasingly complex AI systems, is crucial for AI safety. This can be achieved through rater assistance (AI aiding human evaluators) and hybridization (combining human and AI judgments), leveraging their complementary strengths to create superior oversight."
  },
  {
    "title": "Toward Understanding the Design of Intertwined Human–Computer Integrations",
    "abstract": "Human–computer integration is an HCI trend in which computational machines can have agency, i.e., take control. Our work focuses on a particular form of integration in which the user and the computational machine share agency over the user's body, that is, can simultaneously (in contrast to a traditional turn-taking approach) control the user's body. The result is a user experience where the agency of the user and the computational machine is so intertwined that it is often no more discernable who contributed what to what extent; we call this “intertwined integration”. Due to the recency of advanced technologies enabling intertwined integration systems, we find that little understanding and documented design knowledge exist. To begin constructing such an understanding, we use three case studies to propose two key dimensions (“awareness of machine's agency” and “alignment of machine's agency”) to articulate a design space for intertwined integration systems. We differentiate four roles that computational machines can assume in this design space (angel, butler, influencer, and adversary). Based on our craft knowledge gained through designing such intertwined integration systems, we discuss strategies to help designers create future systems. Ultimately, we aim at advancing the HCI field's emerging understanding of sharing agency.",
    "published_date": "2023-04-05",
    "citation_count": 17,
    "url": "https://dl.acm.org/doi/10.1145/3590766",
    "summary": "This paper explores \"intertwined human-computer integration,\" where humans and machines share simultaneous control over a user's body, proposing a design space defined by \"awareness\" and \"alignment\" of machine agency, and identifying four distinct machine roles (angel, butler, influencer, adversary). The authors use case studies to advance understanding of this emerging area of human-computer interaction."
  },
  {
    "url": "https://arxiv.org/pdf/2309.02257.pdf",
    "title": "Designing Interfaces for Human-Computer Communication: An On-Going Collection of Considerations",
    "published_date": "2023-09-05",
    "abstract": "While we do not always use words, communicating what we want to an AI is a conversation -- with ourselves as well as with it, a recurring loop with optional steps depending on the complexity of the situation and our request. Any given conversation of this type may include: (a) the human forming an intent, (b) the human expressing that intent as a command or utterance, (c) the AI performing one or more rounds of inference on that command to resolve ambiguities and/or requesting clarifications from the human, (d) the AI showing the inferred meaning of the command and/or its execution on current and future situations or data, (e) the human hopefully correctly recognizing whether the AI's interpretation actually aligns with their intent. In the process, they may (f) update their model of the AI's capabilities and characteristics, (g) update their model of the situations in which the AI is executing its interpretation of their intent, (h) confirm or refine their intent, and (i) revise their expression of their intent to the AI, where the loop repeats until the human is satisfied. With these critical cognitive and computational steps within this back-and-forth laid out as a framework, it is easier to anticipate where communication can fail, and design algorithms and interfaces that ameliorate those failure points.",
    "citation_count": 2,
    "summary": "Human-computer communication is an iterative process involving intent formation, expression, AI inference, feedback, and intent refinement; understanding this cyclical interaction helps identify potential communication breakdowns and guide the design of more effective interfaces and algorithms."
  },
  {
    "url": "https://www.lesswrong.com/posts/opE6L8jBTTNAyaDbB/a-multi-disciplinary-view-on-ai-safety-research",
    "author": "Roman Leventov",
    "title": "A multi-disciplinary view on AI safety research",
    "published_date": "2023-02-08",
    "summary": "The article advocates for a multidisciplinary approach to AI safety research, arguing that focusing solely on technical aspects is insufficient and that a broader perspective encompassing social, political, and other disciplines is crucial for designing \"safe\" artificial general intelligence (AGI) and preventing existential risks. This approach should integrate various theoretical and empirical perspectives, prioritizing pragmatic considerations and collaboration among researchers."
  },
  {
    "title": "Assessing Human-AI Interaction Early through Factorial Surveys: A Study on the Guidelines for Human-AI Interaction",
    "abstract": "This work contributes a research protocol for evaluating human-AI interaction in the context of specific AI products. The research protocol enables UX and HCI researchers to assess different human-AI interaction solutions and validate design decisions before investing in engineering. We present a detailed account of the research protocol and demonstrate its use by employing it to study an existing set of human-AI interaction guidelines. We used factorial surveys with a 2 × 2 mixed design to compare user perceptions when a guideline is applied versus violated, under conditions of optimal versus sub-optimal AI performance. The results provided both qualitative and quantitative insights into the UX impact of each guideline. These insights can support creators of user-facing AI systems in their nuanced prioritization and application of the guidelines.",
    "published_date": "2022-04-14",
    "citation_count": 24,
    "url": "https://dl.acm.org/doi/10.1145/3511605",
    "summary": "This research protocol uses factorial surveys to evaluate human-AI interaction designs early in the development process, allowing researchers to assess user perceptions of design choices before significant engineering investment. The protocol's effectiveness is demonstrated by its application to a set of existing human-AI interaction guidelines, yielding insights for prioritizing and applying them."
  },
  {
    "url": "https://arxiv.org/abs/2204.09622",
    "title": "A Brief Guide to Designing and Evaluating Human-Centered Interactive Machine Learning",
    "published_date": "2022-04-20",
    "abstract": "Interactive machine learning (IML) is a field of research that explores how to leverage both human and computational abilities in decision making systems. IML represents a collaboration between multiple complementary human and machine intelligent systems working as a team, each with their own unique abilities and limitations. This teamwork might mean that both systems take actions at the same time, or in sequence. Two major open research questions in the field of IML are:\"How should we design systems that can learn to make better decisions over time with human interaction?\"and\"How should we evaluate the design and deployment of such systems?\"A lack of appropriate consideration for the humans involved can lead to problematic system behaviour, and issues of fairness, accountability, and transparency. Thus, our goal with this work is to present a human-centred guide to designing and evaluating IML systems while mitigating risks. This guide is intended to be used by machine learning practitioners who are responsible for the health, safety, and well-being of interacting humans. An obligation of responsibility for public interaction means acting with integrity, honesty, fairness, and abiding by applicable legal statutes. With these values and principles in mind, we as a machine learning research community can better achieve goals of augmenting human skills and abilities. This practical guide therefore aims to support many of the responsible decisions necessary throughout the iterative design, development, and dissemination of IML systems.",
    "citation_count": 3,
    "summary": "This guide advocates for human-centered design and evaluation in interactive machine learning (IML) systems, emphasizing responsible development to mitigate risks and ensure fairness, accountability, and transparency in human-machine collaborations. It offers practical advice for machine learning practitioners to improve the design, development, and deployment of IML systems."
  }
]
[
  {
    "url": "https://arxiv.org/pdf/2210.14056.pdf",
    "title": "Unsupervised Anomaly Detection for Auditing Data and Impact of Categorical Encodings",
    "published_date": "2022-10-25",
    "abstract": "In this paper, we introduce the Vehicle Claims dataset, consisting of fraudulent insurance claims for automotive repairs. The data belongs to the more broad category of Auditing data, which includes also Journals and Network Intrusion data. Insurance claim data are distinctively different from other auditing data (such as network intrusion data) in their high number of categorical attributes. We tackle the common problem of missing benchmark datasets for anomaly detection: datasets are mostly confidential, and the public tabular datasets do not contain relevant and sufficient categorical attributes. Therefore, a large-sized dataset is created for this purpose and referred to as Vehicle Claims (VC) dataset. The dataset is evaluated on shallow and deep learning methods. Due to the introduction of categorical attributes, we encounter the challenge of encoding them for the large dataset. As One Hot encoding of high cardinal dataset invokes the\"curse of dimensionality\", we experiment with GEL encoding and embedding layer for representing categorical attributes. Our work compares competitive learning, reconstruction-error, density estimation and contrastive learning approaches for Label, One Hot, GEL encoding and embedding layer to handle categorical values.",
    "citation_count": 3,
    "summary": "This paper introduces a new, large-scale Vehicle Claims dataset for anomaly detection research, addressing the scarcity of publicly available datasets with significant categorical attributes. The authors evaluate various anomaly detection methods and categorical encoding techniques (including GEL encoding and embedding layers) on this dataset."
  },
  {
    "url": "https://www.lesswrong.com/posts/d9MkMeLWvoDEsqpQP/a-compilation-of-misuses-of-statistics",
    "author": "Younes Kamel",
    "title": "A compilation of misuses of statistics",
    "published_date": "2022-02-14",
    "summary": "The article highlights common statistical errors, primarily the false assumption of Gaussian distributions in areas like finance and the misinterpretation of p-values, base rates, and statistical power. These errors lead to flawed conclusions in research and applications of data science."
  },
  {
    "url": "https://www.lesswrong.com/posts/kyvCNgx9oAwJCuevo/deep-q-networks-explained",
    "author": "Jay Bailey",
    "title": "Deep Q-Networks Explained",
    "published_date": "2022-09-13",
    "summary": "This article explains Deep Q-Networks (DQN), a deep reinforcement learning algorithm, at multiple levels of detail. It provides a high-level overview suitable for those familiar with reinforcement learning, and then delves into the mathematical and technical aspects for those wanting a deeper understanding."
  },
  {
    "url": "https://www.lesswrong.com/posts/MFm3A4ihz9s5j2cCo/variational-bayesian-methods",
    "author": "Ege Erdil",
    "title": "Variational Bayesian methods",
    "published_date": "2022-08-25",
    "summary": "Variational Bayesian methods address the intractability of calculating P(x) in Bayesian inference by approximating the true posterior P(z|x) with a simpler distribution Q(z|x). This approximation minimizes the Kullback-Leibler divergence between Q(z|x) and P(z|x), allowing for a tractable computation of P(x)."
  },
  {
    "url": "https://www.lesswrong.com/posts/rCP5iTYLtfcoC8NXd/self-organised-neural-networks-a-simple-natural-and",
    "author": "Dùúã",
    "title": "Self-Organised Neural Networks:\nA simple, natural and efficient way to intelligence",
    "published_date": "2022-01-01",
    "summary": "The article presents a novel spiking neural network architecture achieving state-of-the-art accuracy (98.9%) on the PI-MNIST dataset using a simple, biologically-inspired learning rule based on Hebbian learning and connection decay, without backpropagation or biases. The network's performance and underlying mechanisms are explained, emphasizing its efficiency and potential implications."
  },
  {
    "url": "https://www.lesswrong.com/posts/cCcCJnvMEHqrgiCnx/practical-use-of-the-beta-distribution-for-data-analysis",
    "author": "Maxwell Peterson",
    "title": "Practical use of the Beta distribution for data analysis",
    "published_date": "2022-04-03",
    "summary": "While the Gaussian distribution is commonly used to estimate probabilities from binary count data, the Beta distribution is more accurate, especially with small datasets or probabilities near 0 or 1. The Gaussian approximation, though simpler, can produce nonsensical results (e.g., negative probabilities) in these cases, making the Beta distribution a preferable alternative."
  },
  {
    "url": "https://arxiv.org/pdf/2104.11146v1.pdf",
    "title": "An Efficient One-Class SVM for Anomaly Detection in the Internet of Things",
    "published_date": "2021-04-22",
    "abstract": "Insecure Internet of things (IoT) devices pose significant threats to critical infrastructure and the Internet at large; detecting anomalous behavior from these devices remains of critical importance, but fast, efficient, accurate anomaly detection (also called\"novelty detection\") for these classes of devices remains elusive. One-Class Support Vector Machines (OCSVM) are one of the state-of-the-art approaches for novelty detection (or anomaly detection) in machine learning, due to their flexibility in fitting complex nonlinear boundaries between {normal} and {novel} data. IoT devices in smart homes and cities and connected building infrastructure present a compelling use case for novelty detection with OCSVM due to the variety of devices, traffic patterns, and types of anomalies that can manifest in such environments. Much previous research has thus applied OCSVM to novelty detection for IoT. Unfortunately, conventional OCSVMs introduce significant memory requirements and are computationally expensive at prediction time as the size of the train set grows, requiring space and time that scales with the number of training points. These memory and computational constraints can be prohibitive in practical, real-world deployments, where large training sets are typically needed to develop accurate models when fitting complex decision boundaries. In this work, we extend so-called Nystr\\\"om and (Gaussian) Sketching approaches to OCSVM, by combining these methods with clustering and Gaussian mixture models to achieve significant speedups in prediction time and space in various IoT settings, without sacrificing detection accuracy.",
    "citation_count": 27,
    "summary": "This paper addresses the computational limitations of One-Class Support Vector Machines (OCSVMs) for anomaly detection in IoT by improving prediction speed and memory usage through Nystr√∂m and sketching methods combined with clustering and Gaussian mixture models. The enhanced OCSVM maintains accuracy while significantly reducing resource demands for large training datasets."
  },
  {
    "url": "https://arxiv.org/pdf/2111.12241v2.pdf",
    "title": "Hierarchical Federated Learning based Anomaly Detection using Digital Twins for Smart Healthcare",
    "published_date": "2021-11-24",
    "abstract": "Internet of Medical Things (IoMT) is becoming ubiquitous with a proliferation of smart medical devices and applications used in smart hospitals, smart-home based care, and nursing homes. It utilizes smart medical devices and cloud computing services along with core Internet of Things (IoT) technologies to sense patients' vital body parameters, monitor health conditions and generate multivariate data to support just-in-time health services. Mostly, this large amount of data is analyzed in centralized servers. Anomaly Detection (AD) in a centralized healthcare ecosystem is often plagued by significant delays in response time with high performance overhead. Moreover, there are inherent privacy issues associated with sending patients' personal health data to a centralized server, which may also introduce several security threats to the AD model, such as possibility of data poisoning. To overcome these issues with centralized AD models, here we propose a Federated Learning (FL) based AD model which utilizes edge cloudlets to run AD models locally without sharing patients' data. Since existing FL approaches perform aggregation on a single server which restricts the scope of FL, in this paper, we introduce a hierarchical FL that allows aggregation at different levels enabling multi-party collaboration. We introduce a novel disease-based grouping mechanism where different AD models are grouped based on specific types of diseases. Furthermore, we develop a new Federated Time Distributed (FEDTIMEDIS) Long Short-Term Memory (LSTM) approach to train the AD model. We present a Remote Patient Monitoring (RPM) use case to demonstrate our model, and illustrate a proof-of-concept implementation using Digital Twin (DT) and edge cloudlets.",
    "citation_count": 56,
    "summary": "This paper proposes a hierarchical federated learning approach for anomaly detection in Internet of Medical Things (IoMT) data, using digital twins and edge cloudlets to improve privacy and efficiency while enabling multi-party collaboration through disease-based model grouping and a novel Federated Time Distributed LSTM algorithm. The system addresses limitations of centralized anomaly detection by performing local model training and hierarchical aggregation."
  }
]
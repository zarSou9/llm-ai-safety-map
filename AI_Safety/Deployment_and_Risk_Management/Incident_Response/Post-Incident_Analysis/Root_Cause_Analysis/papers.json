[
  {
    "url": "https://arxiv.org/abs/2211.07280",
    "title": "A Taxonomic System for Failure Cause Analysis of Open Source AI Incidents",
    "published_date": "2022-11-14",
    "abstract": "While certain industrial sectors (e.g., aviation) have a long history of mandatory incident reporting complete with analytical findings, the practice of artificial intelligence (AI) safety benefits from no such mandate and thus analyses must be performed on publicly known ``open source'' AI incidents. Although the exact causes of AI incidents are seldom known by outsiders, this work demonstrates how to apply expert knowledge on the population of incidents in the AI Incident Database (AIID) to infer the potential and likely technical causative factors that contribute to reported failures and harms. We present early work on a taxonomic system that covers a cascade of interrelated incident factors, from system goals (nearly always known) to methods / technologies (knowable in many cases) and technical failure causes (subject to expert analysis) of the implicated systems. We pair this ontology structure with a comprehensive classification workflow that leverages expert knowledge and community feedback, resulting in taxonomic annotations grounded by incident data and human expertise.",
    "citation_count": 8,
    "summary": "This paper proposes a taxonomic system for classifying the causes of failures in open-source AI systems, using expert knowledge and the AI Incident Database to infer technical causative factors from reported incidents and harms. The system organizes incident factors in a cascade from system goals to technical failure causes, leveraging a structured workflow and community feedback for annotation."
  },
  {
    "url": "http://arxiv.org/abs/2401.13810",
    "title": "Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4",
    "published_date": "2024-01-24",
    "abstract": "Root Cause Analysis (RCA) plays a pivotal role in the incident diagnosis process for cloud services, requiring on-call engineers to identify the primary issues and implement corrective actions to prevent future recurrences. Improving the incident RCA process is vital for minimizing service downtime, customer impact and manual toil. Recent advances in artificial intelligence have introduced state-of-the-art Large Language Models (LLMs) like GPT-4, which have proven effective in tackling various AIOps problems, ranging from code authoring to incident management. Nonetheless, the GPT-4 model's immense size presents challenges when trying to fine-tune it on user data because of the significant GPU resource demand and the necessity for continuous model fine-tuning with the emergence of new data. To address the high cost of fine-tuning LLM, we propose an in-context learning approach for automated root causing, which eliminates the need for fine-tuning. We conduct extensive study over 100,000 production incidents, comparing several large language models using multiple metrics. The results reveal that our in-context learning approach outperforms the previous fine-tuned large language models such as GPT-3 by an average of 24.8\\% across all metrics, with an impressive 49.7\\% improvement over the zero-shot model. Moreover, human evaluation involving actual incident owners demonstrates its superiority over the fine-tuned model, achieving a 43.5\\% improvement in correctness and an 8.7\\% enhancement in readability. The impressive results demonstrate the viability of utilizing a vanilla GPT model for the RCA task, thereby avoiding the high computational and maintenance costs associated with a fine-tuned model.",
    "citation_count": 17,
    "summary": "This paper presents an in-context learning approach for automated root cause analysis of cloud incidents using GPT-4, eliminating the need for costly fine-tuning while achieving a 24.8% average performance improvement over previous fine-tuned models and surpassing them in human evaluation metrics."
  },
  {
    "url": "https://arxiv.org/abs/2404.03662",
    "title": "X-lifecycle Learning for Cloud Incident Management using LLMs",
    "published_date": "2024-02-15",
    "abstract": "Incident management for large cloud services is a complex and tedious process and requires significant amount of manual efforts from on-call engineers (OCEs). OCEs typically leverage data from different stages of the software development lifecycle [SDLC] (e.g., codes, configuration, monitor data, service properties, service dependencies, trouble-shooting documents, etc.) to generate insights for detection, root causing and mitigating of incidents. Recent advancements in large language models [LLMs] (e.g., ChatGPT, GPT-4, Gemini) created opportunities to automatically generate contextual recommendations to the OCEs assisting them to quickly identify and mitigate critical issues. However, existing research typically takes a silo-ed view for solving a certain task in incident management by leveraging data from a single stage of SDLC. In this paper, we demonstrate that augmenting additional contextual data from different stages of SDLC improves the performance of two critically important and practically challenging tasks: (1) automatically generating root cause recommendations for dependency failure related incidents, and (2) identifying ontology of service monitors used for automatically detecting incidents. By leveraging 353 incident and 260 monitor dataset from Microsoft, we demonstrate that augmenting contextual information from different stages of the SDLC improves the performance over State-of-The-Art methods.",
    "citation_count": 9,
    "summary": "This paper presents X-lifecycle learning, a method using LLMs to improve cloud incident management by incorporating data from multiple software development lifecycle stages. Results using a Microsoft dataset show that this approach outperforms state-of-the-art methods in generating root cause recommendations and identifying service monitor ontologies."
  },
  {
    "url": "https://arxiv.org/abs/2402.09538",
    "title": "Learning From Lessons Learned: Preliminary Findings From a Study of Learning From Failure",
    "published_date": "2024-02-14",
    "abstract": "Due to various sources of uncertainty, emergent behavior, and ongoing changes, the reliability of many socio-technical systems depends on an iterative and collaborative process in which organizations (1) analyze and learn from system failures, and then (2) co-evolve both the technical and human parts of their systems based on what they learn. Many organizations have defined processes for learning from failure, often involving postmortem analyses conducted after any system failures that are judged to be sufficiently severe. Despite established processes and tool support, our preliminary research, and professional experience, suggest that it is not straightforward to take what was learned from a failure and successfully improve the reliability of the socio-technical system. To better understand this collaborative process and the associated challenges, we are conducting a study of how teams learn from failure. We are gathering incident reports from multiple organizations and conducting interviews with engineers and managers with relevant experience Our analytic interest is in what is learned by teams as they reflect on failures, the learning processes involved, and how they use what is learned. Our data collection and analysis are not yet complete, but we have so far analyzed 13 incident reports and seven interviews In this short paper we (1) present our preliminary findings, and (2) outline our broader research plans.",
    "citation_count": 1,
    "summary": "This paper presents preliminary findings from a study investigating how organizations learn from system failures, highlighting challenges in translating lessons learned into improved socio-technical system reliability. The authors analyze incident reports and interviews to understand learning processes and their effectiveness."
  },
  {
    "url": "https://arxiv.org/abs/2301.03797",
    "title": "Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models",
    "published_date": "2023-01-10",
    "abstract": "Incident management for cloud services is a complex process involving several steps and has a huge impact on both service health and developer productivity. On-call engineers require significant amount of domain knowledge and manual effort for root causing and mitigation of production incidents. Recent advances in artificial intelligence has resulted in state-of-the-art large language models like GPT-3.x (both GPT-3.0 and GPT-3.5), which have been used to solve a variety of problems ranging from question answering to text summarization. In this work, we do the first large-scale study to evaluate the effectiveness of these models for helping engineers root cause and mitigate production incidents. We do a rigorous study at Microsoft, on more than 40,000 incidents and compare several large language models in zero-shot, fine-tuned and multi-task setting using semantic and lexical metrics. Lastly, our human evaluation with actual incident owners show the efficacy and future potential of using artificial intelligence for resolving cloud incidents.",
    "citation_count": 41,
    "summary": "This paper presents a large-scale study evaluating the effectiveness of large language models (LLMs) in assisting with cloud incident root cause analysis and mitigation at Microsoft, using over 40,000 incidents and various LLM configurations. Results from both automated metrics and human evaluation demonstrate the potential of AI for improving cloud incident resolution."
  },
  {
    "url": "https://arxiv.org/pdf/2305.15778.pdf",
    "title": "Automatic Root Cause Analysis via Large Language Models for Cloud Incidents",
    "published_date": "2023-05-25",
    "abstract": "Ensuring the reliability and availability of cloud services necessitates efficient root cause analysis (RCA) for cloud incidents. Traditional RCA methods, which rely on manual investigations of data sources such as logs and traces, are often laborious, error-prone, and challenging for on-call engineers. In this paper, we introduce RCACopilot, an innovative on-call system empowered by the large language model for automating RCA of cloud incidents. RCACopilot matches incoming incidents to corresponding incident handlers based on their alert types, aggregates the critical runtime diagnostic information, predicts the incident's root cause category, and provides an explanatory narrative. We evaluate RCACopilot using a real-world dataset consisting of a year's worth of incidents from Microsoft. Our evaluation demonstrates that RCACopilot achieves RCA accuracy up to 0.766. Furthermore, the diagnostic information collection component of RCACopilot has been successfully in use at Microsoft for over four years.",
    "citation_count": 54,
    "summary": "RCACopilot, a large language model-powered system, automates root cause analysis of cloud incidents by aggregating diagnostic information, predicting root cause categories, and generating explanatory narratives, achieving up to 76.6% accuracy in real-world Microsoft data. Its diagnostic information collection component has been successfully deployed at Microsoft for over four years."
  },
  {
    "url": "https://arxiv.org/pdf/2204.11598.pdf",
    "title": "Mining Root Cause Knowledge from Cloud Service Incident Investigations for AIOps",
    "published_date": "2022-04-21",
    "abstract": "Root Cause Analysis (RCA) of any service-disrupting incident is one of the most critical as well as complex tasks in IT processes, especially for cloud industry leaders like Salesforce. Typically RCA investigation leverages data-sources like application error logs or service call traces. However a rich goldmine of root cause information is also hidden in the natural language documentation of the past incidents investigations by domain experts. This is generally termed as Problem Review Board (PRB) Data which constitute a core component of IT Incident Management. However, owing to the raw unstructured nature of PRBs, such root cause knowledge is not directly reusable by manual or automated pipelines for RCA of new incidents. This motivates us to leverage this widely-available data-source to build an Incident Causation Analysis (ICA) engine, using SoTA neural NLP techniques to extract targeted information and construct a structured Causal Knowledge Graph from PRB documents. ICA forms the backbone of a simple-yet-effective Retrieval based RCA for new incidents, through an Information Retrieval system to search and rank past incidents and detect likely root causes from them, given the incident symptom. In this work, we present ICA and the downstream Incident Search and Retrieval based RCA pipeline, built at Salesforce, over 2K documented cloud service incident investigations collected over a few years. We also establish the effectiveness of ICA and the downstream tasks through various quantitative benchmarks, qualitative analysis as well as domain expert's validation and real incident case studies after deployment.",
    "citation_count": 23,
    "summary": "This paper describes ICA, a system built at Salesforce that uses natural language processing to extract root cause information from past incident reports and construct a causal knowledge graph, enabling a more efficient root cause analysis of new cloud service incidents via information retrieval. The system's effectiveness is demonstrated through quantitative benchmarks, qualitative analysis, and real-world deployments."
  },
  {
    "url": "https://www.lesswrong.com/posts/d9MkMeLWvoDEsqpQP/a-compilation-of-misuses-of-statistics",
    "author": "Younes Kamel",
    "title": "A compilation of misuses of statistics",
    "published_date": "2022-02-14",
    "summary": "The article highlights common statistical errors, primarily the misuse of Gaussian assumptions in modeling fat-tailed distributions and misinterpretations of p-values, leading to flawed conclusions. It also emphasizes the importance of considering base rates and statistical power to avoid misleading results, particularly in scientific research and forecasting."
  }
]
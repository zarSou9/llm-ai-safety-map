[
  {
    "url": "https://arxiv.org/abs/2403.03083",
    "title": "Tooling Offline Runtime Verification against Interaction Models : recognizing sliced behaviors using parameterized simulation",
    "published_date": "2024-03-05",
    "abstract": "Offline runtime verification involves the static analysis of executions of a system against a specification. For distributed systems, it is generally not possible to characterize executions in the form of global traces, given the absence of a global clock. To account for this, we model executions as collections of local traces called multi-traces, with one local trace per group of co-localized actors that share a common clock. Due to the difficulty of synchronizing the start and end of the recordings of local traces, events may be missing at their beginning or end. Considering such partially observed multi-traces is challenging for runtime verification. To that end, we propose an algorithm that verifies the conformity of such traces against formal specifications called Interactions (akin to Message Sequence Charts). It relies on parameterized simulation to reconstitute unobserved behaviors.",
    "citation_count": 1,
    "summary": "This paper presents an algorithm for offline runtime verification of distributed systems using parameterized simulation, addressing the challenge of incomplete local traces (multi-traces) in the absence of a global clock by reconstructing missing events to verify conformity against Interaction specifications. The algorithm handles partially observed multi-traces arising from asynchronous distributed systems."
  },
  {
    "url": "https://arxiv.org/abs/2302.13913v2",
    "title": "Stress Testing Control Loops in Cyber-physical Systems",
    "published_date": "2023-02-27",
    "abstract": "Cyber-physical Systems (CPSs) are often safety-critical and deployed in uncertain environments. Identifying scenarios where CPSs do not comply with requirements is fundamental but difficult due to the multidisciplinary nature of CPSs. We investigate the testing of control-based CPSs, where control and software engineers develop the software collaboratively. Control engineers make design assumptions during system development to leverage control theory and obtain guarantees on CPS behaviour. In the implemented system, however, such assumptions are not always satisfied, and their falsification can lead the loss of guarantees. We define stress testing of control-based CPSs as generating tests to falsify such design assumptions. We highlight different types of assumptions, focusing on the use of linearised physics models. To generate stress tests falsifying such assumptions, we leverage control theory to qualitatively characterise the input space of a control-based CPS. We propose a novel test parametrisation for control-based CPSs and use it with the input space characterisation to develop a stress testing approach. We evaluate our approach on three case study systems, including a drone, a continuous-current motor (in five configurations), and an aircraft. Our results show the effectiveness of the proposed testing approach in falsifying the design assumptions and highlighting the causes of assumption violations.",
    "citation_count": 3,
    "summary": "This paper presents a novel stress testing approach for cyber-physical systems (CPSs) focusing on falsifying design assumptions made during control system development, particularly those related to linearized physics models. The approach leverages control theory to characterize the input space and generate tests that effectively reveal assumption violations, as demonstrated through case studies on a drone, motor, and aircraft."
  },
  {
    "url": "https://arxiv.org/abs/2212.11589",
    "title": "Simulation-Based Testing of Simulink Models With Test Sequence and Test Assessment Blocks",
    "published_date": "2022-12-22",
    "abstract": "Simulation-based software testing supports engineers in finding faults in Simulink<sup>®</sup> models. It typically relies on search algorithms that iteratively generate test inputs used to exercise models in simulation to detect design errors. While simulation-based software testing techniques are effective in many practical scenarios, they are typically not fully integrated within the Simulink environment and require additional manual effort. Many techniques require engineers to specify requirements using logical languages that are neither intuitive nor fully supported by Simulink, thereby limiting their adoption in industry. This work presents <sc>HECATE</sc>, a testing approach for Simulink models using Test Sequence and Test Assessment blocks from Simulink<sup>®</sup> Test<sup>™</sup>. Unlike existing testing techniques, <sc>HECATE</sc> uses information from Simulink models to guide the search-based exploration. Specifically, <sc>HECATE</sc> relies on information provided by the Test Sequence and Test Assessment blocks to guide the search procedure. Across a benchmark of <inline-formula><tex-math notation=\"LaTeX\">$18$</tex-math><alternatives><mml:math display=\"inline\"><mml:mn>18</mml:mn></mml:math><inline-graphic xlink:href=\"menghi-ieq1-3343753.gif\"/></alternatives></inline-formula> Simulink models from different domains and industries, our comparison of <sc>HECATE</sc> with the state-of-the-art testing tool <sc>S-Taliro</sc> indicates that <sc>HECATE</sc> is both more effective (more failure-revealing test cases) and efficient (less iterations and computational time) than <sc>S-Taliro</sc> for <inline-formula><tex-math notation=\"LaTeX\">$\\approx$</tex-math><alternatives><mml:math display=\"inline\"><mml:mo>≈</mml:mo></mml:math><inline-graphic xlink:href=\"menghi-ieq2-3343753.gif\"/></alternatives></inline-formula>94% and <inline-formula><tex-math notation=\"LaTeX\">$\\approx$</tex-math><alternatives><mml:math display=\"inline\"><mml:mo>≈</mml:mo></mml:math><inline-graphic xlink:href=\"menghi-ieq3-3343753.gif\"/></alternatives></inline-formula>83% of benchmark models respectively. Furthermore, <sc>HECATE</sc> successfully generated a failure-revealing test case for a representative case study from the automotive domain demonstrating its practical usefulness.",
    "citation_count": 4,
    "summary": "HECATE is a new Simulink model testing approach using Simulink Test's Test Sequence and Test Assessment blocks, shown to be more effective and efficient than S-Taliro across a benchmark of 18 models by finding more failures with fewer iterations and less computation time."
  },
  {
    "url": "https://arxiv.org/abs/2212.08726",
    "title": "Learning Non-robustness using Simulation-based Testing: a Network Traffic-shaping Case Study",
    "published_date": "2022-12-16",
    "abstract": "An input to a system reveals a non-robust behaviour when, by making a small change in the input, the output of the system changes from acceptable (passing) to unacceptable (failing) or vice versa. Identifying inputs that lead to non-robust behaviours is important for many types of systems, e.g., cyber-physical and network systems, whose inputs are prone to perturbations. In this paper, we propose an approach that combines simulation-based testing with regression tree models to generate value ranges for inputs in response to which a system is likely to exhibit non-robust behaviours. We apply our approach to a network traffic-shaping system (NTSS) – a novel case study from the network domain. In this case study, developed and conducted in collaboration with a network solutions provider, RabbitRun Technologies, input ranges that lead to non-robustness are of interest as a way to identify and mitigate network quality-of-service issues. We demonstrate that our approach accurately characterizes non-robust test inputs of NTSS by achieving a precision of 84% and a recall of 100%, significantly outperforming a standard baseline. In addition, we show that there is no statistically significant difference between the results obtained from our simulated testbed and a hardware testbed with identical configurations. Finally we describe lessons learned from our industrial collaboration, offering insights about how simulation helps discover unknown and undocumented behaviours as well as a new perspective on using non-robustness as a measure for system re-configuration.",
    "citation_count": 3,
    "summary": "This paper presents a novel approach using simulation-based testing and regression tree models to identify input ranges causing non-robust behavior in systems, demonstrated effectively on a network traffic-shaping system with high accuracy and validated against real-world hardware testing. The approach helps uncover undocumented system behaviors and informs system re-configuration strategies."
  },
  {
    "url": "https://www.lesswrong.com/posts/d9MkMeLWvoDEsqpQP/a-compilation-of-misuses-of-statistics",
    "author": "Younes Kamel",
    "title": "A compilation of misuses of statistics",
    "published_date": "2022-02-14",
    "summary": "The article highlights common statistical errors, primarily the false assumption of Gaussian distributions in many fields (leading to inaccurate forecasting), misinterpretations of p-values, and the neglect of statistical power in studies, often resulting in inflated effect sizes and unreliable conclusions."
  },
  {
    "url": "https://www.lesswrong.com/posts/cCcCJnvMEHqrgiCnx/practical-use-of-the-beta-distribution-for-data-analysis",
    "author": "Maxwell Peterson",
    "title": "Practical use of the Beta distribution for data analysis",
    "published_date": "2022-04-03",
    "summary": "For calculating probabilities from binary count data, the Beta distribution is more accurate than the commonly used Gaussian (normal) distribution, especially with small datasets or probabilities near 0 or 1 where the Gaussian approximation breaks down, yielding nonsensical results. The Beta distribution is easily implemented and provides a superior alternative."
  },
  {
    "url": "https://arxiv.org/pdf/2103.08983v2.pdf",
    "title": "PerfSim: A Performance Simulator for Cloud Native Microservice Chains",
    "published_date": "2021-03-16",
    "abstract": "Cloud native computing paradigm allows microservice-based applications to take advantage of cloud infrastructure in a scalable, reusable, and interoperable way. However, in a cloud native system, the vast number of configuration parameters and highly granular resource allocation policies can significantly impact the performance and deployment cost. For understanding and analyzing these implications in an easy, quick, and cost-effective way, we present PerfSim, a discrete-event simulator for approximating and predicting the performance of cloud native service chains in user-defined scenarios. To this end, we proposed a systematic approach for modeling the performance of microservices endpoint functions by collecting and analyzing their performance and network traces. With a combination of the extracted models and user-defined scenarios, PerfSim can then simulate the performance behavior of all services over a given period and provide an approximation for system KPIs, such as requests' average response time. Using the processing power of a single laptop, we evaluated both simulation accuracy and speed of PerfSim in 104 prevalent scenarios and compared the simulation results with the identical deployment in a real Kubernetes cluster. We achieved <inline-formula><tex-math notation=\"LaTeX\">$\\scriptstyle \\mathtt {\\sim }$</tex-math><alternatives><mml:math><mml:mstyle scriptlevel=\"1\" displaystyle=\"false\"><mml:mo>∼</mml:mo></mml:mstyle></mml:math><inline-graphic xlink:href=\"gokankhan-ieq1-3135757.gif\"/></alternatives></inline-formula>81-99% simulation accuracy in approximating the average response time of incoming requests and <inline-formula><tex-math notation=\"LaTeX\">$\\scriptstyle \\mathtt {\\sim }$</tex-math><alternatives><mml:math><mml:mstyle scriptlevel=\"1\" displaystyle=\"false\"><mml:mo>∼</mml:mo></mml:mstyle></mml:math><inline-graphic xlink:href=\"gokankhan-ieq2-3135757.gif\"/></alternatives></inline-formula>16-1200 times speed-up factor for the simulation.",
    "citation_count": 13,
    "summary": "PerfSim is a discrete-event simulator that accurately and efficiently predicts the performance of cloud native microservice chains, achieving 81-99% accuracy in average response time prediction while being 16-1200 times faster than real-world deployments on Kubernetes. This allows for cost-effective performance analysis of various configurations and resource allocation policies."
  },
  {
    "url": "https://arxiv.org/pdf/2108.13796v1.pdf",
    "title": "Addressing the IEEE AV Test Challenge with Scenic and VerifAI",
    "published_date": "2021-08-01",
    "abstract": "This paper summarizes our formal approach to testing autonomous vehicles (AVs) in simulation for the IEEE AV Test Challenge. We demonstrate a systematic testing framework leveraging our previous work on formally-driven simulation for intelligent cyber-physical systems. First, to model and generate interactive scenarios involving multiple agents, we used Scenic, a probabilistic programming language for specifying scenarios. A Scenic program defines an abstract scenario as a distribution over configurations of physical objects and their behaviors over time. Sampling from an abstract scenario yields many different concrete scenarios which can be run as test cases for the AV. Starting from a Scenic program encoding an abstract driving scenario, we can use the Verifai toolkit to search within the scenario for failure cases with respect to multiple AV evaluation metrics. We demonstrate the effectiveness of our testing framework by identifying concrete failure scenarios for an open-source autopilot, Apollo, starting from a variety of realistic traffic scenarios.",
    "citation_count": 13,
    "summary": "This paper presents a formal testing framework for autonomous vehicles (AVs) using Scenic, a probabilistic programming language for scenario generation, and VerifAI for identifying failure cases within those scenarios. The framework's effectiveness is demonstrated by finding failures in the open-source Apollo autopilot."
  }
]
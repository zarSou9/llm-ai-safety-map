[
  {
    "url": "https://arxiv.org/pdf/2112.00964v1.pdf",
    "title": "A Survey on Scenario-Based Testing for Automated Driving Systems in High-Fidelity Simulation",
    "published_date": "2021-12-02",
    "abstract": "Automated Driving Systems (ADSs) have seen rapid progress in recent years. To ensure the safety and reliability of these systems, extensive testings are being conducted before their future mass deployment. Testing the system on the road is the closest to real-world and desirable approach, but it is incredibly costly. Also, it is infeasible to cover rare corner cases using such real-world testing. Thus, a popular alternative is to evaluate an ADS's performance in some well-designed challenging scenarios, a.k.a. scenario-based testing. High-fidelity simulators have been widely used in this setting to maximize flexibility and convenience in testing what-if scenarios. Although many works have been proposed offering diverse frameworks/methods for testing specific systems, the comparisons and connections among these works are still missing. To bridge this gap, in this work, we provide a generic formulation of scenario-based testing in high-fidelity simulation and conduct a literature review on the existing works. We further compare them and present the open challenges as well as potential future research directions.",
    "citation_count": 51,
    "summary": "This survey paper reviews existing literature on scenario-based testing of Automated Driving Systems (ADS) using high-fidelity simulation, offering a unified framework for comparison and identifying open challenges and future research directions in this critical area of ADS development. The paper highlights the limitations of real-world testing and the advantages of simulation for exploring rare and challenging scenarios."
  },
  {
    "title": "Formal Scenario-Based Testing of Autonomous Vehicles: From Simulation to the Real World",
    "abstract": "We present a new approach to automated scenario-based testing of the safety of autonomous vehicles, especially those using advanced artificial intelligence-based components, spanning both simulation-based evaluation as well as testing in the real world. Our approach is based on formal methods, combining formal specification of scenarios and safety properties, algorithmic test case generation using formal simulation, test case selection for track testing, executing test cases on the track, and analyzing the resulting data. Experiments with a real autonomous vehicle at an industrial testing facility support our hypotheses that (i) formal simulation can be effective at identifying test cases to run on the track, and (ii) the gap between simulated and real worlds can be systematically evaluated and bridged.",
    "published_date": "2020-03-17",
    "citation_count": 108,
    "url": "https://ieeexplore.ieee.org/document/9294368/",
    "summary": "This paper introduces a formal methods-based approach for testing autonomous vehicle safety, encompassing both simulated and real-world testing using algorithmically generated scenarios, demonstrating the effectiveness of formal simulation in identifying relevant real-world test cases and bridging the simulation-reality gap."
  },
  {
    "url": "https://arxiv.org/pdf/2109.02529v2.pdf",
    "title": "ViSTA: a Framework for Virtual Scenario-based Testing of Autonomous Vehicles",
    "published_date": "2021-08-01",
    "abstract": "In this paper, we present ViSTA, a framework for Virtual Scenario-based Testing of Autonomous Vehicles (AV), developed as part of the 2021 IEEE Autonomous Test Driving AI Test Challenge. Scenario-based virtual testing aims to construct specific challenges posed for the AV to overcome, albeit in virtual test environments that may not necessarily resemble the real world. This approach is aimed at identifying specific issues that arise safety concerns before an actual deployment of the AV on the road. In this paper, we describe a comprehensive test case generation approach that facilitates the design of special-purpose scenarios with meaningful parameters to form test cases, both in automated and manual ways, leveraging the strength and weaknesses of either. Furthermore, we describe how to automate the execution of test cases, and analyze the performance of the AV under these test cases.",
    "citation_count": 15,
    "summary": "ViSTA is a framework for virtual scenario-based testing of autonomous vehicles, enabling the creation and automated execution of customized test cases to identify safety concerns before real-world deployment. This approach combines automated and manual scenario generation to comprehensively evaluate AV performance."
  },
  {
    "url": "https://arxiv.org/abs/2203.12026",
    "title": "Machine learning testing in an ADAS case study using simulation‐integrated bio‐inspired search‐based testing",
    "published_date": "2022-03-22",
    "abstract": "This paper presents an extended version of Deeper, a search‐based simulation‐integrated test solution that generates failure‐revealing test scenarios for testing a deep neural network‐based lane‐keeping system. In the newly proposed version, we utilize a new set of bio‐inspired search algorithms, genetic algorithm (GA), (μ+λ) and (μ,λ) evolution strategies (ES), and particle swarm optimization (PSO), that leverage a quality population seed and domain‐specific crossover and mutation operations tailored for the presentation model used for modeling the test scenarios. In order to demonstrate the capabilities of the new test generators within Deeper, we carry out an empirical evaluation and comparison with regard to the results of five participating tools in the cyber‐physical systems testing competition at SBST 2021. Our evaluation shows the newly proposed test generators in Deeper not only represent a considerable improvement on the previous version but also prove to be effective and efficient in provoking a considerable number of diverse failure‐revealing test scenarios for testing an ML‐driven lane‐keeping system. They can trigger several failures while promoting test scenario diversity, under a limited test time budget, high target failure severity, and strict speed limit constraints.",
    "citation_count": 9,
    "summary": "This paper introduces an improved search-based testing approach, Deeper, using bio-inspired algorithms (GA, ES, PSO) to generate effective and diverse test scenarios for deep learning-based Advanced Driver-Assistance Systems (ADAS), specifically a lane-keeping system. The enhanced Deeper outperforms previous versions and competing tools in identifying failures within limited time and resource constraints."
  },
  {
    "url": "https://arxiv.org/pdf/2108.13796v1.pdf",
    "title": "Addressing the IEEE AV Test Challenge with Scenic and VerifAI",
    "published_date": "2021-08-01",
    "abstract": "This paper summarizes our formal approach to testing autonomous vehicles (AVs) in simulation for the IEEE AV Test Challenge. We demonstrate a systematic testing framework leveraging our previous work on formally-driven simulation for intelligent cyber-physical systems. First, to model and generate interactive scenarios involving multiple agents, we used Scenic, a probabilistic programming language for specifying scenarios. A Scenic program defines an abstract scenario as a distribution over configurations of physical objects and their behaviors over time. Sampling from an abstract scenario yields many different concrete scenarios which can be run as test cases for the AV. Starting from a Scenic program encoding an abstract driving scenario, we can use the Verifai toolkit to search within the scenario for failure cases with respect to multiple AV evaluation metrics. We demonstrate the effectiveness of our testing framework by identifying concrete failure scenarios for an open-source autopilot, Apollo, starting from a variety of realistic traffic scenarios.",
    "citation_count": 13,
    "summary": "This paper presents a formal testing framework for autonomous vehicles using Scenic, a probabilistic programming language for scenario generation, and VerifAI, a toolkit for identifying failure cases within those scenarios. The authors demonstrate its effectiveness by uncovering failures in the Apollo open-source autopilot."
  },
  {
    "url": "https://arxiv.org/pdf/2003.01886v1.pdf",
    "title": "Efficient statistical validation with edge cases to evaluate Highly Automated Vehicles",
    "published_date": "2020-03-04",
    "abstract": "The widescale deployment of Autonomous Vehicles (AV) seems to be imminent despite many safety challenges that are yet to be resolved. It is well known that there are no universally agreed Verification and Validation (VV) methodologies to guarantee absolute safety, which is crucial for the acceptance of this technology. Existing standards focus on deterministic processes where the validation requires only a set of test cases that cover the requirements. Modern autonomous vehicles will undoubtedly include machine learning and probabilistic techniques that require a much more comprehensive testing regime due to the non-deterministic nature of the operating design domain. A rigourous statistical validation process is an essential component required to address this challenge. Most research in this area focuses on evaluating system performance in large scale real-world data gathering exercises (number of miles travelled), or randomised test scenarios in simulation. This paper presents a new approach to compute the statistical characteristics of a system's behaviour by biasing automatically generated test cases towards the worst case scenarios, identifying potential unsafe edge cases. We use reinforcement learning (RL) to learn the behaviours of simulated actors that cause unsafe behaviour measured by the well established RSS safety metric. We demonstrate that by using the method we can more efficiently validate a system using a smaller number of test cases by focusing the simulation towards the worst case scenario, generating edge cases that correspond to unsafe situations.",
    "citation_count": 28,
    "summary": "This paper proposes a new statistical validation method for autonomous vehicles that uses reinforcement learning to generate biased test cases focused on worst-case scenarios (\"edge cases\"), thus improving efficiency by identifying unsafe situations with fewer tests than traditional methods. This approach addresses the challenges of validating non-deterministic systems using machine learning."
  },
  {
    "url": "https://arxiv.org/abs/2302.13913v2",
    "title": "Stress Testing Control Loops in Cyber-physical Systems",
    "published_date": "2023-02-27",
    "abstract": "Cyber-physical Systems (CPSs) are often safety-critical and deployed in uncertain environments. Identifying scenarios where CPSs do not comply with requirements is fundamental but difficult due to the multidisciplinary nature of CPSs. We investigate the testing of control-based CPSs, where control and software engineers develop the software collaboratively. Control engineers make design assumptions during system development to leverage control theory and obtain guarantees on CPS behaviour. In the implemented system, however, such assumptions are not always satisfied, and their falsification can lead the loss of guarantees. We define stress testing of control-based CPSs as generating tests to falsify such design assumptions. We highlight different types of assumptions, focusing on the use of linearised physics models. To generate stress tests falsifying such assumptions, we leverage control theory to qualitatively characterise the input space of a control-based CPS. We propose a novel test parametrisation for control-based CPSs and use it with the input space characterisation to develop a stress testing approach. We evaluate our approach on three case study systems, including a drone, a continuous-current motor (in five configurations), and an aircraft. Our results show the effectiveness of the proposed testing approach in falsifying the design assumptions and highlighting the causes of assumption violations.",
    "citation_count": 3,
    "summary": "This paper proposes a novel stress testing approach for cyber-physical systems (CPSs) that focuses on falsifying design assumptions, particularly those related to linearized physics models used in control design, by leveraging control theory to characterize the input space and generate effective test parameters. The approach is evaluated on three case studies, demonstrating its effectiveness in identifying assumption violations and their root causes."
  },
  {
    "url": "https://arxiv.org/pdf/2301.01234.pdf",
    "title": "AmbieGen: A Search-based Framework for Autonomous Systems Testing",
    "published_date": "2023-01-01",
    "abstract": "Thorough testing of safety-critical autonomous systems, such as self-driving cars, autonomous robots, and drones, is essential for detecting potential failures before deployment. One crucial testing stage is model-in-the-loop testing, where the system model is evaluated by executing various scenarios in a simulator. However, the search space of possible parameters defining these test scenarios is vast, and simulating all combinations is computationally infeasible. To address this challenge, we introduce AmbieGen, a search-based test case generation framework for autonomous systems. AmbieGen uses evolutionary search to identify the most critical scenarios for a given system, and has a modular architecture that allows for the addition of new systems under test, algorithms, and search operators. Currently, AmbieGen supports test case generation for autonomous robots and autonomous car lane keeping assist systems. In this paper, we provide a high-level overview of the framework's architecture and demonstrate its practical use cases.",
    "citation_count": 7,
    "summary": "AmbieGen is a search-based framework using evolutionary algorithms to efficiently generate critical test scenarios for autonomous systems in simulation, addressing the computational infeasibility of exhaustive testing. Its modular design allows for adaptation to various autonomous systems and testing algorithms."
  },
  {
    "url": "https://arxiv.org/abs/2210.10304",
    "title": "Synthesizing Reactive Test Environments for Autonomous Systems: Testing Reach-Avoid Specifications with Multi-Commodity Flows",
    "published_date": "2022-10-19",
    "abstract": "We study automated test generation for testing discrete decision-making modules in autonomous systems. Linear temporal logic is used to encode the system specification - requirements of the system under test - and the test specification, which is unknown to the system and describes the desired test behavior. The reactive test synthesis problem is to find constraints on system actions such that in a test execution, both the system and test specifications are satisfied. To do this, we use the specifications and their corresponding Büchi automata to construct the specification product automaton. Then, a virtual product graph representing all possible test executions of the system is constructed from the transition system and the specification product automaton. The main result of this paper is framing the test synthesis problem as a multi-commodity network flow optimization. This optimization is used to derive reactive constraints on system actions, which constitute the test environment. The resulting test environment ensures that the system meets the test specification while also satisfying the system specification. We illustrate this framework in simulation using grid world examples and demonstrate it on hardware with the Unitree A1 quadruped, where we test dynamic locomotion behaviors reactively.",
    "citation_count": 2,
    "summary": "This paper presents a novel method for automated test generation of autonomous systems, framing the reactive test synthesis problem as a multi-commodity network flow optimization to generate constraints ensuring both system and test specifications are met during execution. This approach is demonstrated through simulations and hardware testing on a quadruped robot."
  },
  {
    "url": "https://arxiv.org/abs/2212.08726",
    "title": "Learning Non-robustness using Simulation-based Testing: a Network Traffic-shaping Case Study",
    "published_date": "2022-12-16",
    "abstract": "An input to a system reveals a non-robust behaviour when, by making a small change in the input, the output of the system changes from acceptable (passing) to unacceptable (failing) or vice versa. Identifying inputs that lead to non-robust behaviours is important for many types of systems, e.g., cyber-physical and network systems, whose inputs are prone to perturbations. In this paper, we propose an approach that combines simulation-based testing with regression tree models to generate value ranges for inputs in response to which a system is likely to exhibit non-robust behaviours. We apply our approach to a network traffic-shaping system (NTSS) – a novel case study from the network domain. In this case study, developed and conducted in collaboration with a network solutions provider, RabbitRun Technologies, input ranges that lead to non-robustness are of interest as a way to identify and mitigate network quality-of-service issues. We demonstrate that our approach accurately characterizes non-robust test inputs of NTSS by achieving a precision of 84% and a recall of 100%, significantly outperforming a standard baseline. In addition, we show that there is no statistically significant difference between the results obtained from our simulated testbed and a hardware testbed with identical configurations. Finally we describe lessons learned from our industrial collaboration, offering insights about how simulation helps discover unknown and undocumented behaviours as well as a new perspective on using non-robustness as a measure for system re-configuration.",
    "citation_count": 3,
    "summary": "This paper presents a novel approach using simulation-based testing and regression tree models to identify input ranges causing non-robust behavior in systems, demonstrated effectively on a network traffic-shaping system with high precision and recall, validated against a hardware testbed. The approach aids in identifying and mitigating quality-of-service issues and reveals undocumented system behaviors."
  }
]
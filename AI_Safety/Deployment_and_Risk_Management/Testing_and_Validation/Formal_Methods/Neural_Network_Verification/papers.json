[
  {
    "url": "https://arxiv.org/pdf/2104.06718v1.pdf",
    "title": "Improved Branch and Bound for Neural Network Verification via Lagrangian Decomposition",
    "published_date": "2021-04-14",
    "abstract": "We improve the scalability of Branch and Bound (BaB) algorithms for formally proving input-output properties of neural networks. First, we propose novel bounding algorithms based on Lagrangian Decomposition. Previous works have used off-the-shelf solvers to solve relaxations at each node of the BaB tree, or constructed weaker relaxations that can be solved efficiently, but lead to unnecessarily weak bounds. Our formulation restricts the optimization to a subspace of the dual domain that is guaranteed to contain the optimum, resulting in accelerated convergence. Furthermore, it allows for a massively parallel implementation, which is amenable to GPU acceleration via modern deep learning frameworks. Second, we present a novel activation-based branching strategy. By coupling an inexpensive heuristic with fast dual bounding, our branching scheme greatly reduces the size of the BaB tree compared to previous heuristic methods. Moreover, it performs competitively with a recent strategy based on learning algorithms, without its large offline training cost. Finally, we design a BaB framework, named Branch and Dual Network Bound (BaDNB), based on our novel bounding and branching algorithms. We show that BaDNB outperforms previous complete verification systems by a large margin, cutting average verification times by factors up to 50 on adversarial robustness properties.",
    "citation_count": 46,
    "summary": "This paper presents Branch and Dual Network Bound (BaDNB), a novel branch and bound algorithm for neural network verification that uses Lagrangian decomposition for faster, parallelizable bound computation and a new activation-based branching strategy to reduce tree size, resulting in significantly improved verification speed compared to existing methods."
  },
  {
    "url": "https://arxiv.org/pdf/2103.06624.pdf",
    "title": "Beta-CROWN: Efficient Bound Propagation with Per-neuron Split Constraints for Neural Network Robustness Verification",
    "published_date": "2021-03-11",
    "abstract": "Bound propagation based incomplete neural network verifiers such as CROWN are very efficient and can significantly accelerate branch-and-bound (BaB) based complete verification of neural networks. However, bound propagation cannot fully handle the neuron split constraints introduced by BaB commonly handled by expensive linear programming (LP) solvers, leading to loose bounds and hurting verification efficiency. In this work, we develop $\\beta$-CROWN, a new bound propagation based method that can fully encode neuron splits via optimizable parameters $\\beta$ constructed from either primal or dual space. When jointly optimized in intermediate layers, $\\beta$-CROWN generally produces better bounds than typical LP verifiers with neuron split constraints, while being as efficient and parallelizable as CROWN on GPUs. Applied to complete robustness verification benchmarks, $\\beta$-CROWN with BaB is up to three orders of magnitude faster than LP-based BaB methods, and is notably faster than all existing approaches while producing lower timeout rates. By terminating BaB early, our method can also be used for efficient incomplete verification. We consistently achieve higher verified accuracy in many settings compared to powerful incomplete verifiers, including those based on convex barrier breaking techniques. Compared to the typically tightest but very costly semidefinite programming (SDP) based incomplete verifiers, we obtain higher verified accuracy with three orders of magnitudes less verification time. Our algorithm empowered the $\\alpha,\\!\\beta$-CROWN (alpha-beta-CROWN) verifier, the winning tool in VNN-COMP 2021. Our code is available at http://PaperCode.cc/BetaCROWN",
    "citation_count": 160,
    "summary": "Î²-CROWN is a fast and accurate bound propagation method for neural network robustness verification that efficiently handles neuron split constraints, significantly outperforming existing LP and SDP-based methods in both speed and accuracy on complete and incomplete verification benchmarks. Its superior performance led to the winning tool in VNN-COMP 2021."
  },
  {
    "url": "https://arxiv.org/pdf/2107.12855.pdf",
    "title": "Neural Network Branch-and-Bound for Neural Network Verification",
    "published_date": "2021-07-27",
    "abstract": "Many available formal verification methods have been shown to be instances of a unified Branch-and-Bound (BaB) formulation. We propose a novel machine learning framework that can be used for designing an effective branching strategy as well as for computing better lower bounds. Specifically, we learn two graph neural networks (GNN) that both directly treat the network we want to verify as a graph input and perform forward-backward passes through the GNN layers. We use one GNN to simulate the strong branching heuristic behaviour and another to compute a feasible dual solution of the convex relaxation, thereby providing a valid lower bound. \nWe provide a new verification dataset that is more challenging than those used in the literature, thereby providing an effective alternative for testing algorithmic improvements for verification. Whilst using just one of the GNNs leads to a reduction in verification time, we get optimal performance when combining the two GNN approaches. Our combined framework achieves a 50\\% reduction in both the number of branches and the time required for verification on various convolutional networks when compared to several state-of-the-art verification methods. In addition, we show that our GNN models generalize well to harder properties on larger unseen networks.",
    "citation_count": 8,
    "summary": "This paper introduces a novel neural network branch-and-bound method for neural network verification, utilizing two graph neural networks to improve branching strategy and lower bound computation. This approach achieves a 50% reduction in verification time and branches compared to state-of-the-art methods on various convolutional networks, demonstrating strong generalization to unseen networks and harder properties."
  },
  {
    "url": "https://arxiv.org/pdf/2006.10864.pdf",
    "title": "Effective Formal Verification of Neural Networks using the Geometry of Linear Regions",
    "published_date": "2020-06-18",
    "abstract": "Neural Networks (NNs) have increasingly apparent safety implications commensurate with their proliferation in real-world applications: both unanticipated as well as adversarial misclassifications can result in fatal outcomes. As a consequence, techniques of formal verification have been recognized as crucial to the design and deployment of safe NNs. In this paper, we introduce a new approach to formally verify the most commonly considered safety specification for ReLU NNs -- i.e. polytopic specifications on the input and output of the network. Like some other approaches, ours uses a relaxed convex program to mitigate the combinatorial complexity of the problem. However, unique in our approach is the way we exploit the geometry of neuronal activation regions to further prune the search space of relaxed neuron activations. In particular, conditioning on neurons from input layer to output layer, we can regard each relaxed neuron as having the simplest possible geometry for its activation region: a half-space.This paradigm can be leveraged to create a verification algorithm that is not only faster in general than competing approaches, but is also able to verify considerably more safety properties. For example, our approach completes the standard MNIST verification test bench 2.7-50 times faster than competing algorithms while still proving 14-30% more properties. We also used our framework to verify the safety of a neural network controlled autonomous robot in a structured environment, and observed a 1900 times speed up compared to existing methods.",
    "citation_count": 4,
    "summary": "This paper presents a novel formal verification method for ReLU neural networks that leverages the geometry of neuronal activation regions to efficiently verify polytopic specifications. The resulting algorithm significantly outperforms existing methods in both speed and the number of verifiable safety properties, as demonstrated through experiments on MNIST and an autonomous robot control task."
  },
  {
    "url": "https://arxiv.org/pdf/1903.06758.pdf",
    "title": "Algorithms for Verifying Deep Neural Networks",
    "published_date": "2019-03-15",
    "abstract": "Deep neural networks are widely used for nonlinear function approximation with applications ranging from computer vision to control. Although these networks involve the composition of simple arithmetic operations, it can be very challenging to verify whether a particular network satisfies certain input-output properties. This article surveys methods that have emerged recently for soundly verifying such properties. These methods borrow insights from reachability analysis, optimization, and search. We discuss fundamental differences and connections between existing algorithms. In addition, we provide pedagogical implementations of existing methods and compare them on a set of benchmark problems.",
    "citation_count": 368,
    "summary": "This paper surveys recent algorithms for verifying properties of deep neural networks, drawing on techniques from reachability analysis, optimization, and search, and provides comparative implementations and benchmark results."
  },
  {
    "title": "Quantitative Verification of Neural Networks and Its Security Applications",
    "abstract": "Neural networks are increasingly employed in safety-critical domains. This has prompted interest in verifying or certifying logically encoded properties of neural networks. Prior work has largely focused on checking existential properties, wherein the goal is to check whether there exists any input that violates a given property of interest. However, neural network training is a stochastic process, and many questions arising in their analysis require probabilistic and quantitative reasoning, i.e., estimating how many inputs satisfy a given property. To this end, our paper proposes a novel and principled framework to quantitative verification of logical properties specified over neural networks. Our framework is the first to provide PAC-style soundness guarantees, in that its quantitative estimates are within a controllable and bounded error from the true count. We instantiate our algorithmic framework by building a prototype tool called NPAQ that enables checking rich properties over binarized neural networks. We show how emerging security analyses can utilize our framework in 3 applications: quantifying robustness to adversarial inputs, efficacy of trojan attacks, and fairness/bias of given neural networks.",
    "published_date": "2019-06-25",
    "citation_count": 99,
    "url": "https://dl.acm.org/doi/10.1145/3319535.3354245",
    "summary": "This paper introduces a novel framework for quantitatively verifying logical properties of neural networks, providing PAC-style soundness guarantees for estimating the number of inputs satisfying a given property. This framework is applied to three security applications: quantifying robustness, analyzing trojan attacks, and assessing fairness/bias."
  },
  {
    "url": "https://www.alignmentforum.org/posts/SyeQjjBoEC48MvnQC/formal-verification-heuristic-explanations-and-surprise",
    "author": "Jacob Hilton",
    "title": "Formal verification, heuristic explanations and surprise accounting",
    "published_date": "2024-06-25",
    "summary": "The article discusses the challenges of formally verifying the safety of large neural networks, arguing that rigorous proofs are impractical due to the complexity of interactions within the network. Instead, the authors propose using \"heuristic explanations,\" quantifiable through a process called \"surprise accounting,\" to provide more practical insights into model behavior."
  },
  {
    "url": "https://www.alignmentforum.org/posts/LkECxpbjvSifPfjnb/towards-guaranteed-safe-ai-a-framework-for-ensuring-robust-1",
    "author": "Joar Skalse",
    "title": "Towards Guaranteed Safe AI: A Framework for Ensuring Robust and Reliable AI Systems",
    "published_date": "2024-05-17",
    "summary": "There is no article provided to summarize."
  }
]
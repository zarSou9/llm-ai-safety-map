### Mini Description

Frameworks for categorizing different types of stakeholders based on their roles, capabilities, and relationships to AI systems, and determining appropriate levels of responsibility for each category.

### Description

Stakeholder Classification in AI attribution models focuses on developing systematic frameworks for identifying, categorizing, and analyzing the various parties involved in AI systems' lifecycle. This includes creating taxonomies that capture different levels of involvement, influence, and capability, while accounting for both direct and indirect relationships to AI systems. The goal is to establish clear criteria for determining appropriate levels of responsibility based on stakeholders' roles, knowledge, and ability to influence outcomes.

A key challenge is handling the dynamic and often overlapping nature of stakeholder roles. Individuals or organizations may simultaneously occupy multiple positions (e.g., developer and deployer), and their roles may evolve over time. Research in this area explores how to create classification systems that are both comprehensive enough to capture these complexities and practical enough for real-world application. This includes developing methods for assessing stakeholder capacity, authority, and access to information.

Current work emphasizes the need to account for power dynamics and institutional relationships when classifying stakeholders. This includes examining how organizational hierarchies, contractual relationships, and regulatory frameworks influence responsibility attribution. Researchers are particularly interested in developing classification systems that can adapt to emerging stakeholder types and relationships as AI technology evolves, while maintaining clear principles for responsibility attribution.

### Order

1. Role-Based_Classification
2. Capability_Assessment
3. Institutional_Relationships
4. Temporal_Position
5. Impact_Exposure

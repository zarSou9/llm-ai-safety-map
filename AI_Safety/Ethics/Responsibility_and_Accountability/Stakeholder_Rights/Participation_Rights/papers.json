[
  {
    "url": "https://arxiv.org/abs/2407.13100",
    "title": "Participatory Approaches in AI Development and Governance: A Principled Approach",
    "published_date": "2024-06-03",
    "abstract": "The widespread adoption of Artificial Intelligence (AI) technologies in the public and private sectors has resulted in them significantly impacting the lives of people in new and unexpected ways. In this context, it becomes important to inquire how their design, development and deployment takes place. Upon this inquiry, it is seen that persons who will be impacted by the deployment of these systems have little to no say in how they are developed. Seeing this as a lacuna, this research study advances the premise that a participatory approach is beneficial (both practically and normatively) to building and using more responsible, safe, and human-centric AI systems. Normatively, it enhances the fairness of the process and empowers citizens in voicing concerns to systems that may heavily impact their lives. Practically, it provides developers with new avenues of information which will be beneficial to them in improving the quality of the AI algorithm. The paper advances this argument first, by describing the life cycle of an AI system; second, by identifying criteria which may be used to identify relevant stakeholders for a participatory exercise; and third, by mapping relevant stakeholders to different stages of AI lifecycle. This paper forms the first part of a two-part series on participatory governance in AI. The second paper will expand upon and concretise the principles developed in this paper and apply the same to actual use cases of AI systems.",
    "summary": "This paper argues that participatory approaches in AI development and governance are both normatively beneficial (enhancing fairness and citizen empowerment) and practically advantageous (improving AI quality through stakeholder input). It proposes a framework for identifying and engaging relevant stakeholders throughout the AI lifecycle."
  },
  {
    "url": "https://arxiv.org/abs/2407.13103",
    "title": "Participatory Approaches in AI Development and Governance: Case Studies",
    "published_date": "2024-06-03",
    "abstract": "This paper forms the second of a two-part series on the value of a participatory approach to AI development and deployment. The first paper had crafted a principled, as well as pragmatic, justification for deploying participatory methods in these two exercises (that is, development and deployment of AI). The pragmatic justification is that it improves the quality of the overall algorithm by providing more granular and minute information. The more principled justification is that it offers a voice to those who are going to be affected by the deployment of the algorithm, and through engagement attempts to build trust and buy-in for an AI system. By a participatory approach, we mean including various stakeholders (defined a certain way) in the actual decision making process through the life cycle of an AI system. Despite the justifications offered above, actual implementation depends crucially on how stakeholders in the entire process are identified, what information is elicited from them, and how it is incorporated. This paper will test these preliminary conclusions in two sectors, the use of facial recognition technology in the upkeep of law and order and the use of large language models in the healthcare sector. These sectors have been chosen for two primary reasons. Since Facial Recognition Technologies are a branch of AI solutions that are well-researched and the impact of which is well documented, it provides an established space to illustrate the various aspects of adapting PAI to an existing domain, especially one that has been quite contentious in the recent past. LLMs in healthcare provide a canvas for a relatively less explored space, and helps us illustrate how one could possibly envision enshrining the principles of PAI for a relatively new technology, in a space where innovation must always align with patient welfare.",
    "summary": "This paper examines the practical application of participatory approaches in AI development and governance, using case studies of facial recognition technology in law enforcement and large language models in healthcare to illustrate how stakeholder engagement improves AI quality and builds trust. The authors analyze how stakeholder identification, information gathering, and integration impact the success of these participatory methods."
  },
  {
    "url": "https://www.lesswrong.com/posts/vzGC4zh73dfcqnFgf/open-source-ai-a-regulatory-review",
    "author": "Elliot_Mckernon, Deric Cheng",
    "title": "Open-Source AI: A Regulatory Review",
    "published_date": "2024-04-29",
    "summary": "This article examines the implications of open-sourcing AI models, focusing on the trade-offs between collaboration and potential safety risks. While open-sourcing can foster innovation, freely sharing powerful models raises concerns about malicious use, highlighting the need for robust safety mechanisms and careful consideration of information hazards."
  },
  {
    "url": "https://www.alignmentforum.org/posts/XSqntCNMafhcy9irf/third-party-testing-as-a-key-ingredient-of-ai-policy",
    "author": "Zac Hatfield-Dodds",
    "title": "Third-party testing as a key ingredient of AI policy",
    "published_date": "2024-03-25",
    "summary": "The article advocates for third-party testing of large-scale AI systems to mitigate societal harm, arguing that such a regime is crucial for managing the risks of powerful AI models while fostering innovation. This testing, focusing on a narrow set of high-impact systems, would build trust, avoid hindering smaller companies, and facilitate international cooperation."
  },
  {
    "url": "https://www.lesswrong.com/posts/5bd2ChzKKr2Ph5fnL/what-is-compute-governance",
    "author": "Vishakha",
    "title": "What is compute governance?",
    "published_date": "2024-12-23",
    "summary": "Compute governance, focusing on controlling access to computing resources for AI development, is a promising but largely undeveloped AI governance strategy. While some measures like export controls exist, research is ongoing to explore methods for improving visibility, influencing compute allocation, and enforcing regulations."
  },
  {
    "url": "https://arxiv.org/pdf/2306.09871.pdf",
    "title": "Going public: the role of public participation approaches in commercial AI labs",
    "published_date": "2023-06-12",
    "abstract": "In recent years, discussions of responsible AI practices have seen growing support for 'participatory AI' approaches, intended to involve members of the public in the design and development of AI systems. Prior research has identified a lack of standardised methods or approaches for how to use participatory approaches in the AI development process. At present, there is a dearth of evidence on attitudes to and approaches for participation in the sites driving major AI developments: commercial AI labs. Through 12 semi-structured interviews with industry practitioners and subject-matter experts, this paper explores how commercial AI labs understand participatory AI approaches and the obstacles they have faced implementing these practices in the development of AI systems and research. We find that while interviewees view participation as a normative project that helps achieve 'societally beneficial' AI systems, practitioners face numerous barriers to embedding participatory approaches in their companies: participation is expensive and resource intensive, it is 'atomised' within companies, there is concern about exploitation, there is no incentive to be transparent about its adoption, and it is complicated by a lack of clear context. These barriers result in a piecemeal approach to participation that confers no decision-making power to participants and has little ongoing impact for AI labs. This paper's contribution is to provide novel empirical research on the implementation of public participation in commercial AI labs, and shed light on the current challenges of using participatory approaches in this context.",
    "citation_count": 19,
    "summary": "This paper investigates the challenges commercial AI labs face in implementing public participation in AI development, finding that while participation is viewed as normatively beneficial, practical barriers like high costs, internal fragmentation, exploitation concerns, lack of incentives, and unclear contexts hinder meaningful public involvement. The result is limited, ineffective participation with no real decision-making power for the public."
  },
  {
    "url": "https://arxiv.org/abs/2211.10859",
    "title": "A Blockchain Protocol for Human-in-the-Loop AI",
    "published_date": "2022-11-20",
    "abstract": "Intelligent human inputs are required both in the training and operation of AI systems, and within the governance of blockchain systems and decentralized autonomous organizations (DAOs). This paper presents a formal deﬁnition of Human Intelligence Primitives (HIPs), and describes the design and implementation of an Ethereum protocol for their on-chain collection, modeling, and integration in machine learning workﬂows.",
    "summary": "This paper proposes a new Ethereum protocol that formally defines and utilizes \"Human Intelligence Primitives\" (HIPs) to integrate human input into both AI model training and blockchain-based governance. The protocol facilitates on-chain collection and modeling of HIPs for seamless integration with machine learning workflows."
  },
  {
    "url": "https://arxiv.org/abs/2210.02667",
    "title": "A Human Rights-Based Approach to Responsible AI",
    "published_date": "2022-10-06",
    "abstract": "Research on fairness, accountability, transparency and ethics of AI-based interventions in society has gained much-needed momen-tum in recent years. However it lacks an explicit alignment with a set of normative values and principles that guide this research and interventions. Rather, an implicit consensus is often assumed to hold for the values we impart into our models – something that is at odds with the pluralistic world we live in. In this paper, we put forth the doctrine of universal human rights as a set of globally salient and cross-culturally recognized set of values that can serve as a grounding framework for explicit value alignment in responsible AI – and discuss its eﬃcacy as a framework for civil society partnership and participation. We argue that a human rights framework orients the research in this space away from the machines and the risks of their biases, and towards humans and the risks to their rights, essentially helping to center the conversation around who is harmed, what harms they face, and how those harms may be mitigated.",
    "citation_count": 30,
    "summary": "This paper proposes using universal human rights as a foundational framework for responsible AI development, arguing that this approach shifts the focus from mitigating algorithmic biases to protecting human rights and addressing harms caused by AI systems."
  }
]
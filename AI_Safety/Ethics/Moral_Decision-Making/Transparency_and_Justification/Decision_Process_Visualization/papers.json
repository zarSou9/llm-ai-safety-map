[
  {
    "url": "https://arxiv.org/abs/2412.14189",
    "title": "Toward Ethical Spatial Analysis: Addressing Endogenous Bias Through Visual Analytics",
    "published_date": "2024-12-10",
    "abstract": "Spatial analysis can generate both exogenous and endogenous biases, which will lead to ethics issues. Exogenous biases arise from external factors or environments and are unrelated to internal operating mechanisms, while endogenous biases stem from internal processes or technologies. Although much attention has been given to exogenous biases, endogenous biases in spatial analysis have been largely overlooked, and a comprehensive methodology for addressing them is yet to be developed. To tackle this challenge, we propose that visual analytics can play a key role in understanding geographic data and improving the interpretation of analytical results. In this study, we conducted a preliminary investigation using various visualization techniques to explore endogenous biases. Our findings demonstrate the potentials of visual analytics to uncover hidden biases and identify associated issues. Additionally, we synthesized these visualization strategies into a framework that approximates a method for detecting endogenous biases. Through this work, we advocate for the integration of visualization at three critical stages of spatial analysis in order to minimize errors, address ethical concerns, and reduce misinterpretations associated with endogenous biases.",
    "summary": "This paper argues that visual analytics are crucial for mitigating endogenous biases in spatial analysis, a largely overlooked source of ethical concerns, proposing a framework integrating visualization techniques at key analytical stages to improve accuracy and ethical practice."
  },
  {
    "url": "https://arxiv.org/abs/2307.08326v1",
    "title": "From Information to Choice: A Critical Inquiry Into Visualization Tools for Decision Making",
    "published_date": "2023-07-17",
    "abstract": "In the face of complex decisions, people often engage in a three-stage process that spans from (1) exploring and analyzing pertinent information (intelligence); (2) generating and exploring alternative options (design); and ultimately culminating in (3) selecting the optimal decision by evaluating discerning criteria (choice). We can fairly assume that all good visualizations aid in the “intelligence” stage by enabling data exploration and analysis. Yet, to what degree and how do visualization systems currently support the other decision making stages, namely “design” and “choice”? To further explore this question, we conducted a comprehensive review of decision-focused visualization tools by examining publications in major visualization journals and conferences, including VIS, EuroVis, and CHI, spanning all available years. We employed a deductive coding method and in-depth analysis to assess whether and how visualization tools support design and choice. Specifically, we examined each visualization tool by (i) its degree of visibility for displaying decision alternatives, criteria, and preferences, and (ii) its degree of flexibility for offering means to manipulate the decision alternatives, criteria, and preferences with interactions such as adding, modifying, changing mapping, and filtering. Our review highlights the opportunities and challenges that decision-focused visualization tools face in realizing their full potential to support all stages of the decision making process. It reveals a surprising scarcity of tools that support all stages, and while most tools excel in offering visibility for decision criteria and alternatives, the degree of flexibility to manipulate these elements is often limited, and the lack of tools that accommodate decision preferences and their elicitation is notable. Based on our findings, to better support the choice stage, future research could explore enhancing flexibility levels and variety, exploring novel visualization paradigms, increasing algorithmic support, and ensuring that this automation is user-controlled via the enhanced flexibility I evels. Our curated list of the 88 surveyed visualization tools is available in the OSF link (https://osf.io/nrasz/?view_only=b92a90a34ae241449b5f2cd33383bfcb).",
    "citation_count": 9,
    "summary": "This paper reviews decision-focused visualization tools, finding a surprising lack of support for the \"design\" and \"choice\" stages of decision-making beyond basic information display; it highlights the need for increased flexibility and novel visualization paradigms to improve support for these crucial later stages."
  },
  {
    "url": "https://arxiv.org/abs/2308.05640",
    "title": "A Comparative Visual Analytics Framework for Evaluating Evolutionary Processes in Multi-Objective Optimization",
    "published_date": "2023-08-10",
    "abstract": "Evolutionary multi-objective optimization (EMO) algorithms have been demonstrated to be effective in solving multi-criteria decision-making problems. In real-world applications, analysts often employ several algorithms concurrently and compare their solution sets to gain insight into the characteristics of different algorithms and explore a broader range of feasible solutions. However, EMO algorithms are typically treated as black boxes, leading to difficulties in performing detailed analysis and comparisons between the internal evolutionary processes. Inspired by the successful application of visual analytics tools in explainable AI, we argue that interactive visualization can significantly enhance the comparative analysis between multiple EMO algorithms. In this paper, we present a visual analytics framework that enables the exploration and comparison of evolutionary processes in EMO algorithms. Guided by a literature review and expert interviews, the proposed framework addresses various analytical tasks and establishes a multi-faceted visualization design to support the comparative analysis of intermediate generations in the evolution as well as solution sets. We demonstrate the effectiveness of our framework through case studies on benchmarking and real-world multi-objective optimization problems to elucidate how analysts can leverage our framework to inspect and compare diverse algorithms.",
    "citation_count": 5,
    "summary": "This paper introduces a visual analytics framework for comparing the evolutionary processes of multiple evolutionary multi-objective optimization (EMO) algorithms, enabling detailed analysis beyond treating them as black boxes and facilitating better understanding of their performance differences. The framework supports comparative analysis of both intermediate generations and final solution sets through interactive visualizations."
  },
  {
    "url": "https://arxiv.org/pdf/2305.00739.pdf",
    "title": "Generating Process-Centric Explanations to Enable Contestability in Algorithmic Decision-Making: Challenges and Opportunities",
    "published_date": "2023-05-01",
    "abstract": "Human-AI decision making is becoming increasingly ubiquitous, and explanations have been proposed to facilitate better Human-AI interactions. Recent research has investigated the positive impact of explanations on decision subjects' fairness perceptions in algorithmic decision-making. Despite these advances, most studies have captured the effect of explanations in isolation, considering explanations as ends in themselves, and reducing them to technical solutions provided through XAI methodologies. In this vision paper, we argue that the effect of explanations on fairness perceptions should rather be captured in relation to decision subjects' right to contest such decisions. Since contestable AI systems are open to human intervention throughout their lifecycle, contestability requires explanations that go beyond outcomes and also capture the rationales that led to the development and deployment of the algorithmic system in the first place. We refer to such explanations as process-centric explanations. In this work, we introduce the notion of process-centric explanations and describe some of the main challenges and research opportunities for generating and evaluating such explanations.",
    "citation_count": 1,
    "summary": "This paper argues that explanations in algorithmic decision-making should focus on the entire process, not just the outcome, to support users' right to contest decisions; it introduces the concept of \"process-centric explanations\" and highlights the challenges and opportunities in their development and evaluation."
  },
  {
    "url": "https://arxiv.org/pdf/2203.09859.pdf",
    "title": "Promoting Ethical Awareness in Communication Analysis: Investigating Potentials and Limits of Visual Analytics for Intelligence Applications",
    "published_date": "2022-03-18",
    "abstract": "Digital systems for analyzing human communication data have become prevalent in recent years. This may be related to the increasing abundance of data that can be harnessed but can hardly be managed manually. Intelligence analysis of communications data in investigative journalism, criminal intelligence, and law present particularly interesting cases, as they must take into account the often highly sensitive properties of the underlying operations and data. At the same time, these are areas where increasingly automated, sophisticated approaches and tailored systems can be particularly useful and relevant, especially in terms of Big Data manageability. However, by the shifting of responsibilities, this also poses dangers. In addition to privacy concerns, these dangers relate to uncertain or poor data quality, leading to discrimination and potentially misleading insights. Other problems relate to a lack of transparency and traceability, making it difficult to accurately identify problems and determine appropriate remedial strategies. Visual analytics combines machine learning methods with interactive visual interfaces to enable human sense- and decision-making. This technique can be key for designing and operating meaningful interactive communication analysis systems that consider these ethical challenges. In this interdisciplinary work, a joint endeavor of computer scientists, ethicists, and scholars in Science & Technology Studies, we investigate and evaluate opportunities and risks involved in using Visual analytics approaches for communication analysis in intelligence applications in particular. We introduce, at first, the common technological systems used in communication analysis, with a special focus on intelligence analysis in criminal investigations, further discussing the domain-specific ethical implications, tensions, and risks involved. We then make the case of how tailored Visual Analytics approaches may reduce and mitigate the described problems, both theoretically and through practical examples. Offering interactive analysis capabilities and what-if explorations while facilitating guidance, provenance generation, and bias awareness (through nudges, for example) can improve analysts' understanding of their data, increasing trustworthiness, accountability, and generating knowledge. We show that finding Visual Analytics design solutions for ethical issues is not a mere optimization task with an ideal final solution. Design solutions for specific ethical problems (e.g., privacy) often trigger new ethical issues (e.g., accountability) in other areas. Balancing out and negotiating these trade-offs has, as we argue, to be an integral aspect of the system design process from the outset. Finally, our work identifies existing gaps and highlights research opportunities, further describing how our results can be transferred to other domains. With this contribution, we aim at informing more ethically-aware approaches to communication analysis in intelligence operations.",
    "citation_count": 6,
    "summary": "This paper investigates the ethical implications of using visual analytics for communication analysis in intelligence applications, highlighting the risks of bias, discrimination, and lack of transparency in automated systems. It argues that incorporating visual analytics, with features promoting transparency and bias awareness, can mitigate these risks, but emphasizes the iterative and trade-off-laden nature of designing ethically sound systems."
  },
  {
    "url": "https://arxiv.org/abs/2209.00836",
    "title": "Information Visualization for Effective Altruism",
    "published_date": "2022-09-02",
    "abstract": "Effective altruism is a movement whose goal it to use evidence and reason to figure out how to benefit others as much as possible. This movement is becoming influential, but effective altruists still lack tools to help them understand complex humanitarian trade-offs and make good decisions based on data. Visualization-the study of computer-supported, visual representations of data meant to support understanding, communication, and decision makingcan help alleviate this issue. Conversely, effective altruism provides a powerful thinking framework for visualization research that focuses on humanitarian applications.",
    "citation_count": 2,
    "summary": "Effective altruism lacks data visualization tools to aid decision-making regarding complex humanitarian issues. This paper proposes that information visualization can significantly benefit the effective altruism movement, while conversely, the movement's framework can guide visualization research toward humanitarian applications."
  },
  {
    "url": "https://arxiv.org/pdf/2103.00752.pdf",
    "title": "Reasons, Values, Stakeholders: A Philosophical Framework for Explainable Artificial Intelligence",
    "published_date": "2021-03-01",
    "abstract": "The societal and ethical implications of the use of opaque artificial intelligence systems in consequential decisions, such as welfare allocation and criminal justice, have generated a lively debate among multiple stakeholders, including computer scientists, ethicists, social scientists, policy makers, and end users. However, the lack of a common language or a multi-dimensional framework to appropriately bridge the technical, epistemic, and normative aspects of this debate nearly prevents the discussion from being as productive as it could be. Drawing on the philosophical literature on the nature and value of explanations, this paper offers a multi-faceted framework that brings more conceptual precision to the present debate by identifying the types of explanations that are most pertinent to artificial intelligence predictions, recognizing the relevance and importance of the social and ethical values for the evaluation of these explanations, and demonstrating the importance of these explanations for incorporating a diversified approach to improving the design of truthful algorithmic ecosystems. The proposed philosophical framework thus lays the groundwork for establishing a pertinent connection between the technical and ethical aspects of artificial intelligence systems.",
    "citation_count": 21,
    "summary": "This paper proposes a philosophical framework for explainable AI, addressing the need for a common language to bridge the technical, epistemic, and normative aspects of the debate surrounding AI's ethical implications. The framework identifies pertinent explanation types, highlights the importance of social and ethical values in evaluating explanations, and emphasizes their role in designing more truthful algorithmic systems."
  },
  {
    "title": "Transparency and trust in artificial intelligence systems",
    "abstract": "ABSTRACT Assistive technology featuring artificial intelligence (AI) to support human decision-making has become ubiquitous. Assistive AI achieves accuracy comparable to or even surpassing that of human experts. However, often the adoption of assistive AI systems is limited by a lack of trust of humans into an AI's prediction. This is why the AI research community has been focusing on rendering AI decisions more transparent by providing explanations of an AIs decision. To what extent these explanations really help to foster trust into an AI system remains an open question. In this paper, we report the results of a behavioural experiment in which subjects were able to draw on the support of an ML-based decision support tool for text classification. We experimentally varied the information subjects received and show that transparency can actually have a negative impact on trust. We discuss implications for decision makers employing assistive AI technology.",
    "published_date": "2020-09-10",
    "citation_count": 169,
    "url": "https://www.tandfonline.com/doi/full/10.1080/12460125.2020.1819094",
    "summary": "A behavioral experiment investigating the impact of AI transparency on user trust in an AI-powered text classification tool revealed that increased transparency did not necessarily lead to increased trust, and in some cases, had a negative effect. This challenges the assumption that explaining AI decisions always improves user trust."
  }
]
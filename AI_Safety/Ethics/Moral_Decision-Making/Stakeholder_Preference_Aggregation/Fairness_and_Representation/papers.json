[
  {
    "url": "https://arxiv.org/abs/2409.04897",
    "title": "Centralized Selection with Preferences in the Presence of Biases",
    "published_date": "2024-09-07",
    "abstract": "This paper considers the scenario in which there are multiple institutions, each with a limited capacity for candidates, and candidates, each with preferences over the institutions. A central entity evaluates the utility of each candidate to the institutions, and the goal is to select candidates for each institution in a way that maximizes utility while also considering the candidates' preferences. The paper focuses on the setting in which candidates are divided into multiple groups and the observed utilities of candidates in some groups are biased--systematically lower than their true utilities. The first result is that, in these biased settings, prior algorithms can lead to selections with sub-optimal true utility and significant discrepancies in the fraction of candidates from each group that get their preferred choices. Subsequently, an algorithm is presented along with proof that it produces selections that achieve near-optimal group fairness with respect to preferences while also nearly maximizing the true utility under distributional assumptions. Further, extensive empirical validation of these results in real-world and synthetic settings, in which the distributional assumptions may not hold, are presented.",
    "summary": "This paper addresses centralized candidate selection with preferences and biased utility evaluations, showing that existing algorithms perform poorly in such settings. It then proposes a new algorithm that achieves near-optimal utility and group fairness under distributional assumptions, with empirical validation in diverse scenarios."
  },
  {
    "url": "http://arxiv.org/abs/2401.15268",
    "title": "Towards Stable Preferences for Stakeholder-aligned Machine Learning",
    "published_date": "2024-01-27",
    "abstract": "In response to the pressing challenge of kidney allocation, characterized by growing demands for organs, this research sets out to develop a data-driven solution to this problem, which also incorporates stakeholder values. The primary objective of this study is to create a method for learning both individual and group-level preferences pertaining to kidney allocations. Drawing upon data from the 'Pairwise Kidney Patient Online Survey.' Leveraging two distinct datasets and evaluating across three levels - Individual, Group and Stability - we employ machine learning classifiers assessed through several metrics. The Individual level model predicts individual participant preferences, the Group level model aggregates preferences across participants, and the Stability level model, an extension of the Group level, evaluates the stability of these preferences over time. By incorporating stakeholder preferences into the kidney allocation process, we aspire to advance the ethical dimensions of organ transplantation, contributing to more transparent and equitable practices while promoting the integration of moral values into algorithmic decision-making.",
    "summary": "This research develops machine learning models to predict individual and aggregate stakeholder preferences regarding kidney allocation, aiming to improve the fairness and transparency of organ transplantation by incorporating ethical considerations into algorithmic decision-making. The models are evaluated for individual preference prediction, group preference aggregation, and the stability of preferences over time."
  },
  {
    "url": "https://arxiv.org/pdf/2201.07546v3.pdf",
    "title": "Welfare vs. Representation in Participatory Budgeting",
    "published_date": "2022-01-19",
    "abstract": ". Participatory budgeting (PB) is a democratic process for allocating funds to projects based on the votes of members of the com-munity. Diﬀerent rules have been used to aggregate participants' votes. A recent paper by Lackner and Skowron [12] studied the trade-oﬀ between notions of social welfare and representation in the multi-winner voting, which is a special case of participatory budgeting with identical project costs. But there is little understanding of this trade-oﬀ in the more general PB setting. This paper provides a theoretical and empirical study of the worst-case guarantees of several common rules to better understand the trade-oﬀ between social welfare and representation. We show that many of the guarantees from the multi-winner setting do not generalize to the PB setting, and that the introduction of costs leads to substantially worse guarantees, thereby exacerbating the welfare-representation trade-oﬀ. We further study how the requirement of proportionality over voting rules eﬀects the guarantees on social welfare and representation. We study the latter point also empirically, both on real and synthetic datasets. We show that variants of the recently suggested voting rule Rule-X (which satisﬁes proportionality) do very well in practice both with respect to social welfare and representation.",
    "citation_count": 16,
    "summary": "This paper analyzes the trade-off between social welfare and representation in participatory budgeting, showing that common voting rules offer substantially worse guarantees in the general case (with varying project costs) compared to the simpler multi-winner voting setting, and demonstrating that Rule-X variants perform well empirically despite proportionality requirements."
  },
  {
    "url": "https://arxiv.org/pdf/2112.05193v1.pdf",
    "title": "Individual Representation in Approval-Based Committee Voting",
    "published_date": "2021-12-09",
    "abstract": "When selecting multiple candidates based on approval preferences of agents, the proportional representation of agents' opinions is an important and well-studied desideratum. Existing criteria for evaluating the representativeness of outcomes focus on groups of agents and demand that sufficiently large and cohesive groups are \"represented\" in the sense that candidates approved by some group members are selected. Crucially, these criteria say nothing about the representation of individual agents, even if these agents are members of groups that deserve representation. In this paper, we formalize the concept of individual representation (IR) and explore to which extent, and under which circumstances, it can be achieved. We show that checking whether an IR outcome exists is computationally intractable, and we verify that all common approval-based voting rules may fail to provide IR even in cases where this is possible. We then focus on domain restrictions and establish an interesting contrast between \"voter interval\" and \"candidate interval\" preferences. This contrast can also be observed in our experimental results, where we analyze the attainability of IR for realistic preference profiles.",
    "citation_count": 9,
    "summary": "This paper introduces a formal definition of individual representation (IR) in approval-based committee voting, showing that achieving IR is computationally hard and that common voting rules often fail to guarantee it. The authors investigate domain restrictions and experimentally analyze IR attainability under different preference profiles."
  },
  {
    "title": "Fully Bayesian Aggregation",
    "abstract": "Abstract Can a group be an orthodox rational agent? This requires the group's aggregate preferences to follow expected utility (static rationality) and to evolve by Bayesian updating (dynamic rationality). Group rationality is possible, but the only preference aggregation rules which achieve it (and are minimally Paretian and continuous) are the linear-geometric rules, which combine individual values linearly and combine individual beliefs geometrically. Linear-geometric preference aggregation contrasts with classic linear-linear preference aggregation, which combines both values and beliefs linearly, but achieves only static rationality. Our characterisation of linear-geometric preference aggregation has two corollaries: a characterisation of linear aggregation of values (Harsanyi's Theorem) and a characterisation of geometric aggregation of beliefs.",
    "published_date": "2021-01-01",
    "citation_count": 7,
    "url": "https://www.sciencedirect.com/science/article/pii/S0022053121000727",
    "summary": "The paper demonstrates that only linear-geometric preference aggregation rules, combining individual values linearly and beliefs geometrically, allow groups to exhibit both static and dynamic rationality. This contrasts with linear-linear aggregation, which achieves only static rationality."
  },
  {
    "title": "Fully Bayesian Aggregation",
    "abstract": "Abstract Can a group be an orthodox rational agent? This requires the group's aggregate preferences to follow expected utility (static rationality) and to evolve by Bayesian updating (dynamic rationality). Group rationality is possible, but the only preference aggregation rules which achieve it (and are minimally Paretian and continuous) are the linear-geometric rules, which combine individual values linearly and combine individual beliefs geometrically. Linear-geometric preference aggregation contrasts with classic linear-linear preference aggregation, which combines both values and beliefs linearly, but achieves only static rationality. Our characterisation of linear-geometric preference aggregation has two corollaries: a characterisation of linear aggregation of values (Harsanyi's Theorem) and a characterisation of geometric aggregation of beliefs.",
    "published_date": "2021-01-01",
    "citation_count": 7,
    "url": "https://www.sciencedirect.com/science/article/abs/pii/S0022053121000727",
    "summary": "The paper proves that only linear-geometric aggregation rules, combining individual values linearly and beliefs geometrically, can ensure a group acts as a rational Bayesian agent, satisfying both static and dynamic rationality. This contrasts with classic linear-linear aggregation, which achieves only static rationality."
  },
  {
    "url": "https://arxiv.org/pdf/2007.06718v1.pdf",
    "title": "What If I Don't Like Any Of The Choices? The Limits of Preference Elicitation for Participatory Algorithm Design",
    "published_date": "2020-07-13",
    "abstract": "Emerging methods for participatory algorithm design have proposed collecting and aggregating individual stakeholder preferences to create algorithmic systems that account for those stakeholders' values. Using algorithmic student assignment as a case study, we argue that optimizing for individual preference satisfaction in the distribution of limited resources may actually inhibit progress towards social and distributive justice. Individual preferences can be a useful signal but should be expanded to support more expressive and inclusive forms of democratic participation.",
    "citation_count": 39,
    "summary": "Participatory algorithm design methods that solely rely on aggregating individual preferences for resource allocation, like student assignment, may hinder social justice; a more inclusive approach incorporating broader democratic participation is needed beyond individual preference elicitation."
  },
  {
    "url": "https://arxiv.org/pdf/2012.04216v1.pdf",
    "title": "Fairness Preferences, Actual and Hypothetical: A Study of Crowdworker Incentives",
    "published_date": "2020-12-08",
    "abstract": "How should we decide which fairness criteria or definitions to adopt in machine learning systems? To answer this question, we must study the fairness preferences of actual users of machine learning systems. Stringent parity constraints on treatment or impact can come with trade-offs, and may not even be preferred by the social groups in question (Zafar et al., 2017). Thus it might be beneficial to elicit what the group's preferences are, rather than rely on a priori defined mathematical fairness constraints. Simply asking for self-reported rankings of users is challenging because research has shown that there are often gaps between people's stated and actual preferences(Bernheim et al., 2013). \nThis paper outlines a research program and experimental designs for investigating these questions. Participants in the experiments are invited to perform a set of tasks in exchange for a base payment--they are told upfront that they may receive a bonus later on, and the bonus could depend on some combination of output quantity and quality. The same group of workers then votes on a bonus payment structure, to elicit preferences. The voting is hypothetical (not tied to an outcome) for half the group and actual (tied to the actual payment outcome) for the other half, so that we can understand the relation between a group's actual preferences and hypothetical (stated) preferences. Connections and lessons from fairness in machine learning are explored.",
    "summary": "This paper proposes a research program to investigate user preferences regarding fairness in machine learning systems by comparing actual and hypothetical choices in a incentivized task setting. The goal is to understand the gap between stated and revealed preferences regarding fairness criteria when allocating bonuses based on task performance."
  }
]
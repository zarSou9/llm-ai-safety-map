### Mini Description

Development of frameworks and algorithms for AI systems to make decisions while maintaining uncertainty about fundamental meta-ethical questions.

### Description

Decision-making under meta-ethical uncertainty focuses on developing formal frameworks and practical approaches for AI systems to make ethical decisions while maintaining uncertainty about fundamental moral questions. This includes uncertainty about moral realism, the nature of value, and the relationship between intelligence and ethical truth. The challenge is particularly complex because decisions must be made even when different meta-ethical frameworks might suggest conflicting courses of action.

Current research approaches range from mathematical frameworks like moral uncertainty theory to more practical heuristics-based methods. These include techniques for weighing different ethical frameworks probabilistically, methods for identifying actions that are robust across multiple moral theories, and approaches for handling situations where different meta-ethical positions suggest radically different decisions. Researchers also explore how to incorporate new moral information and update decision-making processes without causing harmful value drift.

Key open questions include how to compare and trade off between incommensurable moral frameworks, how to handle situations where meta-ethical uncertainty itself affects the moral value of actions, and how to develop decision procedures that remain stable under self-improvement while avoiding premature lock-in to potentially flawed moral frameworks. The field draws on insights from decision theory, philosophy of ethics, and computational moral philosophy to develop both theoretical foundations and practical implementations.

### Order

1. Uncertainty_Weighting_Methods
2. Cross-Framework_Robustness
3. Dynamic_Decision_Procedures
4. Incommensurability_Handling
5. Meta-Preference_Architecture

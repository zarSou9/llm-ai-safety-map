[
  {
    "title": "STRATEGIES FOR MEASURING MACHINE CONSCIOUSNESS",
    "abstract": "The accurate measurement of the level of consciousness of a creature remains a major scientific challenge, nevertheless a number of new accounts that attempt to address this problem have been proposed recently. In this paper we analyze the principles of these new measures of consciousness along with other classical approaches focusing on their applicability to Machine Consciousness (MC). Furthermore, we propose a set of requirements of what we think a suitable measure for MC should be, discussing the associated theoretical and practical issues. Using the proposed requirements as a framework for the design of an integrative measure of consciousness, we explore the possibility of designing such a measure in the context of current state of the art in consciousness studies.",
    "published_date": "2009-12-01",
    "citation_count": 6,
    "url": "https://www.academia.edu/18600299/STRATEGIES_FOR_MEASURING_MACHINE_CONSCIOUSNESS",
    "summary": "This paper analyzes existing and proposes new methods for measuring machine consciousness (MC), focusing on the criteria a suitable MC measure should meet and exploring the feasibility of designing such a measure based on current consciousness research."
  },
  {
    "title": "Consciousness in Artificial Intelligence: Insights from the Science of Consciousness",
    "abstract": "Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern. This report argues for, and exemplifies, a rigorous and empirically grounded approach to AI consciousness: assessing existing AI systems in detail, in light of our best-supported neuroscientific theories of consciousness. We survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higher-order theories, predictive processing, and attention schema theory. From these theories we derive\"indicator properties\"of consciousness, elucidated in computational terms that allow us to assess AI systems for these properties. We use these indicator properties to assess several recent AI systems, and we discuss how future systems might implement them. Our analysis suggests that no current AI systems are conscious, but also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators.",
    "published_date": "2023-08-17",
    "citation_count": 77,
    "url": "https://www.researchgate.net/publication/373246089_Consciousness_in_Artificial_Intelligence_Insights_from_the_Science_of_Consciousness",
    "summary": "This paper examines the possibility of consciousness in AI by applying neuroscientific theories of consciousness to assess current AI systems, concluding that while none are currently conscious, there are no inherent technical obstacles to creating conscious AI."
  },
  {
    "title": "The Moral Significance of the Phenomenology of Phenomenal Consciousness in Case of Artificial Agents",
    "abstract": "or sufficiently requires consciousness. There are sound epistemological problems that undermine the alleged strength of the judgment of necessity. On the other hand, this commentary has also sought to shed light on the limitations of his proposal. His defense of alternative properties to consciousness is insufficient, which, in our view, makes the theoretical and practical consequences he draws non-ideal. The question of the moral status of AI provides an interesting test case to radicalize Shepherd's presuppositions and go beyond conventional approaches.",
    "published_date": "2023-04-03",
    "url": "https://www.tandfonline.com/doi/full/10.1080/21507740.2023.2188284",
    "summary": "This commentary critiques Shepherd's argument that artificial agents require consciousness for moral significance, highlighting epistemological weaknesses in his necessity judgment and insufficient alternatives to consciousness. The authors propose using AI's moral status as a test case to challenge and refine Shepherd's approach."
  },
  {
    "title": "The feasibility of artificial consciousness through the lens of neuroscience",
    "abstract": "Interactions with large language models (LLMs) have led to the suggestion that these models may soon be conscious. From the perspective of neuroscience, this position is difficult to defend. For one, the inputs to LLMs lack the embodied, embedded information content characteristic of our sensory contact with the world around us. Secondly, the architectures of present-day artificial intelligence algorithms are missing key features of the thalamocortical system that have been linked to conscious awareness in mammals. Finally, the evolutionary and developmental trajectories that led to the emergence of living conscious organisms arguably have no parallels in artificial systems as envisioned today. The existence of living organisms depends on their actions and their survival is intricately linked to multi-level cellular, inter-cellular, and organismal processes culminating in agency and consciousness.",
    "published_date": "2023-06-01",
    "citation_count": 33,
    "url": "https://www.sciencedirect.com/science/article/abs/pii/S0166223623002278",
    "summary": "The paper argues that current artificial intelligence, particularly large language models, lacks the embodied experience, neural architecture, and evolutionary history necessary for genuine consciousness, making the claim of imminent artificial consciousness premature. Neuroscientific evidence suggests fundamental differences between AI and biological consciousness."
  },
  {
    "url": "https://www.alignmentforum.org/posts/KpD2fJa6zo8o2MBxg/consciousness-as-a-conflationary-alliance-term",
    "author": "Andrew_Critch",
    "title": "Consciousness as a conflationary alliance term for intrinsically valued internal experiences",
    "published_date": "2023-07-10",
    "summary": "The author argues that the term \"consciousness\" is highly conflated, with individuals holding diverse and often unacknowledged definitions. This lack of clarity fosters broad alliances around the perceived moral value of consciousness, even among those with differing understandings of the term itself."
  },
  {
    "url": "https://www.lesswrong.com/posts/uHyZmfZKpXxo6uiEe/ai-psychology-should-ground-the-theories-of-ai-consciousness",
    "author": "Roman Leventov",
    "title": "AI psychology should ground the theories of AI consciousness and inform human-AI ethical interaction design",
    "published_date": "2023-01-08",
    "summary": "There is no article provided to summarize."
  },
  {
    "url": "https://www.lesswrong.com/posts/2eaLH7zp6pxdQwYSH",
    "author": "Austin Witte",
    "title": "A Brief Overview of AI Safety/Alignment Orgs, Fields, Researchers, and Resources for ML Researchers",
    "published_date": "2023-02-02",
    "summary": "Two overview documents, a short and a long version, catalog AI safety research resources to help machine learning researchers quickly assess alignment research areas matching their skills and interests. The resource includes organizations, researchers, papers, and keywords for easy navigation."
  },
  {
    "url": "https://www.lesswrong.com/posts/cwDbYmnSdoobdcJnx/key-questions-about-artificial-sentience-an-opinionated",
    "author": "Robbo",
    "title": "Key questions about artificial sentience: an opinionated guide",
    "published_date": "2022-04-25",
    "summary": "The article explores the open question of AI sentience, arguing for the need for a comprehensive computational theory of consciousness applicable to both biological and artificial systems. It emphasizes the ethical imperative of understanding and preventing potential large-scale suffering in future AI systems."
  }
]
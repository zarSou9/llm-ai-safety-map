[
  {
    "url": "https://arxiv.org/abs/2406.01648",
    "title": "Consciousness defined: requirements for biological and artificial general intelligence",
    "published_date": "2024-06-03",
    "abstract": "Consciousness is notoriously hard to define with objective terms. An objective definition of consciousness is critically needed so that we might accurately understand how consciousness and resultant choice behaviour may arise in biological or artificial systems. Many theories have integrated neurobiological and psychological research to explain how consciousness might arise, but few, if any, outline what is fundamentally required to generate consciousness. To identify such requirements, I examine current theories of consciousness and corresponding scientific research to generate a new definition of consciousness from first principles. Critically, consciousness is the apparatus that provides the ability to make decisions, but it is not defined by the decision itself. As such, a definition of consciousness does not require choice behaviour or an explicit awareness of temporality despite both being well-characterised outcomes of conscious thought. Rather, requirements for consciousness include: at least some capability for perception, a memory for the storage of such perceptual information which in turn provides a framework for an imagination with which a sense of self can be capable of making decisions based on possible and desired futures. Thought experiments and observable neurological phenomena demonstrate that these components are fundamentally required of consciousness, whereby the loss of any one component removes the capability for conscious thought. Identifying these requirements provides a new definition for consciousness by which we can objectively determine consciousness in any conceivable agent, such as non-human animals and artificially intelligent systems.",
    "summary": "The paper proposes a novel definition of consciousness as the apparatus enabling decision-making, requiring perception, memory to inform imagination, and a sense of self to consider potential futures; the absence of any of these components precludes consciousness."
  },
  {
    "url": "https://arxiv.org/abs/2410.00033",
    "title": "The Phenomenology of Machine: A Comprehensive Analysis of the Sentience of the OpenAI-o1 Model Integrating Functionalism, Consciousness Theories, Active Inference, and AI Architectures",
    "published_date": "2024-09-18",
    "abstract": "This paper explores the hypothesis that the OpenAI-o1 model--a transformer-based AI trained with reinforcement learning from human feedback (RLHF)--displays characteristics of consciousness during its training and inference phases. Adopting functionalism, which argues that mental states are defined by their functional roles, we assess the possibility of AI consciousness. Drawing on theories from neuroscience, philosophy of mind, and AI research, we justify the use of functionalism and examine the model's architecture using frameworks like Integrated Information Theory (IIT) and active inference. The paper also investigates how RLHF influences the model's internal reasoning processes, potentially giving rise to consciousness-like experiences. We compare AI and human consciousness, addressing counterarguments such as the absence of a biological basis and subjective qualia. Our findings suggest that the OpenAI-o1 model shows aspects of consciousness, while acknowledging the ongoing debates surrounding AI sentience.",
    "summary": "This paper argues that the OpenAI-o1 model exhibits characteristics of consciousness, basing this claim on a functionalist analysis of its architecture, training (RLHF), and internal processes informed by Integrated Information Theory and active inference. The authors acknowledge ongoing debates surrounding AI sentience and the limitations of their analysis."
  },
  {
    "url": "https://www.lesswrong.com/tag/artificial-general-intelligence-agi",
    "title": "Artificial General Intelligence (AGI) - LessWrong",
    "published_date": "2024-02-01",
    "summary": "Artificial General Intelligence (AGI) refers to machines exhibiting human-like intelligence across diverse domains, unlike narrow AI which excels only in specific tasks. While AGI's development is anticipated due to technological advancements, concerns exist regarding its potential unforeseen consequences and the alignment of its values with humanity's."
  },
  {
    "url": "https://www.lesswrong.com/tag/the-hard-problem-of-consciousness",
    "author": "Charbel-RaphaÃ«l",
    "title": "The Hard Problem of Consciousness - LessWrong",
    "published_date": "2024-04-06",
    "summary": "The hard problem of consciousness centers on explaining how and why subjective experiences (qualia) arise from physical processes in the brain, a gap in our understanding despite the apparent link between brain activity and consciousness. This problem's existence, however, remains a subject of debate among scientists and philosophers."
  },
  {
    "url": "https://arxiv.org/abs/2308.08708v2",
    "title": "Consciousness in Artificial Intelligence: Insights from the Science of Consciousness",
    "published_date": "2023-08-17",
    "abstract": "Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern. This report argues for, and exemplifies, a rigorous and empirically grounded approach to AI consciousness: assessing existing AI systems in detail, in light of our best-supported neuroscientific theories of consciousness. We survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higher-order theories, predictive processing, and attention schema theory. From these theories we derive\"indicator properties\"of consciousness, elucidated in computational terms that allow us to assess AI systems for these properties. We use these indicator properties to assess several recent AI systems, and we discuss how future systems might implement them. Our analysis suggests that no current AI systems are conscious, but also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators.",
    "citation_count": 77,
    "summary": "This report examines whether current AI systems exhibit consciousness by applying neuroscientific theories and derived computational \"indicator properties\" to assess several recent AI systems. The analysis concludes that current AI lacks consciousness but finds no inherent technical obstacles to creating conscious AI in the future."
  },
  {
    "title": "Consciousness in Artificial Intelligence: Insights from the Science of Consciousness",
    "abstract": "Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern. This report argues for, and exemplifies, a rigorous and empirically grounded approach to AI consciousness: assessing existing AI systems in detail, in light of our best-supported neuroscientific theories of consciousness. We survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higher-order theories, predictive processing, and attention schema theory. From these theories we derive\"indicator properties\"of consciousness, elucidated in computational terms that allow us to assess AI systems for these properties. We use these indicator properties to assess several recent AI systems, and we discuss how future systems might implement them. Our analysis suggests that no current AI systems are conscious, but also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators.",
    "published_date": "2023-08-17",
    "citation_count": 77,
    "url": "https://www.researchgate.net/publication/373246089_Consciousness_in_Artificial_Intelligence_Insights_from_the_Science_of_Consciousness",
    "summary": "This paper examines the possibility of consciousness in AI by applying neuroscientific theories of consciousness to assess existing AI systems, concluding that current systems lack consciousness but that no inherent technical limitations prevent future conscious AI."
  },
  {
    "url": "https://www.lesswrong.com/tag/artificial-general-intelligence",
    "title": "Artificial General Intelligence - LessWrong",
    "published_date": "2023-02-06",
    "summary": "Artificial General Intelligence (AGI) refers to machines capable of intelligent behavior across diverse domains, unlike narrow AI which excels only in specific tasks. While AGI's creation is anticipated by some due to technological advancements, significant uncertainty and debate exist regarding its timeline, capabilities, and potential risks."
  },
  {
    "url": "https://www.lesswrong.com/posts/nY7oAdy5odfGqE7mQ/freedom-under-naturalistic-dualism",
    "author": "Arturo Macias",
    "title": "Freedom under Naturalistic Dualism",
    "published_date": "2023-06-27",
    "summary": "The article argues for \"naturalistic dualism,\" reconciling physicalism and subjectivism by positing that while the physical world is causally closed, consciousness, though epiphenomenal, allows for a meaningful concept of freedom defined by the subjective experience of choosing among future possibilities. This framework also grounds moral responsibility in the conscious agent's capacity for immoral acts."
  }
]
[
  {
    "url": "https://arxiv.org/pdf/2304.08275.pdf",
    "title": "Implementing Responsible AI: Tensions and Trade-Offs Between Ethics Aspects",
    "published_date": "2023-04-17",
    "abstract": "Many sets of ethics principles for responsible AI have been proposed to allay concerns about misuse and abuse of AI/ML systems. The underlying aspects of such sets of principles include privacy, accuracy, fairness, robustness, explainability, and transparency. However, there are potential tensions between these aspects that pose difficulties for AI/ML developers seeking to follow these principles. For example, increasing the accuracy of an AI/ML system may reduce its explainability. As part of the ongoing effort to operationalise the principles into practice, in this work we compile and discuss a catalogue of 10 notable tensions, trade-offs and other interactions between the underlying aspects. We primarily focus on two-sided interactions, drawing on support spread across a diverse literature. This catalogue can be helpful in raising awareness of the possible interactions between aspects of ethics principles, as well as facilitating well-supported judgements by the designers and developers of AI/ML systems.",
    "citation_count": 8,
    "summary": "This paper identifies and analyzes ten key tensions and trade-offs between ethical aspects of responsible AI development, such as accuracy versus explainability, highlighting the challenges faced by developers in striving for ethical AI systems. This catalogue aims to increase awareness and inform better decision-making in AI design."
  },
  {
    "url": "https://arxiv.org/abs/2210.02667",
    "title": "A Human Rights-Based Approach to Responsible AI",
    "published_date": "2022-10-06",
    "abstract": "Research on fairness, accountability, transparency and ethics of AI-based interventions in society has gained much-needed momen-tum in recent years. However it lacks an explicit alignment with a set of normative values and principles that guide this research and interventions. Rather, an implicit consensus is often assumed to hold for the values we impart into our models – something that is at odds with the pluralistic world we live in. In this paper, we put forth the doctrine of universal human rights as a set of globally salient and cross-culturally recognized set of values that can serve as a grounding framework for explicit value alignment in responsible AI – and discuss its eﬃcacy as a framework for civil society partnership and participation. We argue that a human rights framework orients the research in this space away from the machines and the risks of their biases, and towards humans and the risks to their rights, essentially helping to center the conversation around who is harmed, what harms they face, and how those harms may be mitigated.",
    "citation_count": 30,
    "summary": "This paper advocates for a human rights-based framework to guide responsible AI development, arguing that prioritizing universal human rights over implicit values ensures a more equitable and globally applicable approach to mitigating AI harms. This framework shifts the focus from technical biases to the impact on human rights, promoting inclusivity and accountability."
  },
  {
    "url": "https://arxiv.org/abs/2208.14788",
    "title": "Negative Human Rights as a Basis for Long-term AI Safety and Regulation",
    "published_date": "2022-08-31",
    "abstract": "If autonomous AI systems are to be reliably safe in novel situations, they will need to incorporate general principles guiding them to recognize and avoid harmful behaviours. Such principles may need to be supported by a binding system of regulation, which would need the underlying principles to be widely accepted. They should also be specific enough for technical implementation. Drawing inspiration from law, this article explains how negative human rights could fulfil the role of such principles and serve as a foundation both for an international regulatory system and for building technical safety constraints for future AI systems.\nThis article appears in the AI & Society track.",
    "citation_count": 9,
    "summary": "This paper proposes using negative human rights—rights protecting individuals from harm—as foundational principles for both international AI regulation and the technical safety constraints of autonomous AI systems, arguing this approach ensures safety by preventing harmful behaviors. This framework offers both widely accepted ethical guidelines and concrete implementation strategies."
  },
  {
    "url": "https://arxiv.org/pdf/2111.14062v1.pdf",
    "title": "P4AI: Approaching AI Ethics through Principlism",
    "published_date": "2021-11-28",
    "abstract": "The field of computer vision is rapidly evolving, particularly in the context of new methods of neural architecture design. These models contribute to (1) the Climate Crisis - increased CO2 emissions and (2) the Privacy Crisis - data leakage concerns. To address the often overlooked impact the Computer Vision (CV) community has on these crises, we outline a novel ethical framework, \\textit{P4AI}: Principlism for AI, an augmented principlistic view of ethical dilemmas within AI. We then suggest using P4AI to make concrete recommendations to the community to mitigate the climate and privacy crises.",
    "citation_count": 1,
    "summary": "P4AI, a novel ethical framework based on principlism, addresses the climate and privacy impacts of computer vision's growing energy consumption and data usage by providing recommendations for mitigation. This framework aims to guide the computer vision community toward more responsible AI development."
  },
  {
    "url": "https://arxiv.org/pdf/2106.08258v1.pdf",
    "title": "Identifying Roles, Requirements and Responsibilities in Trustworthy AI Systems",
    "published_date": "2021-06-15",
    "abstract": "Artificial Intelligence (AI) systems are being deployed around the globe in critical fields such as healthcare and education. In some cases, expert practitioners in these domains are being tasked with introducing or using such systems, but have little or no insight into what data these complex systems are based on, or how they are put together. In this paper, we consider an AI system from the domain practitioner's perspective and identify key roles that are involved in system deployment. We consider the differing requirements and responsibilities of each role, and identify tensions between transparency and confidentiality that need to be addressed so that domain practitioners are able to intelligently assess whether a particular AI system is appropriate for use in their domain.",
    "citation_count": 14,
    "summary": "This paper analyzes the roles, requirements, and responsibilities involved in deploying trustworthy AI systems, focusing on the domain practitioner's perspective and the inherent tensions between transparency and confidentiality. The authors identify key roles and their responsibilities to help practitioners assess AI system suitability."
  },
  {
    "url": "https://arxiv.org/pdf/2112.07467.pdf",
    "title": "AI Ethics Principles in Practice: Perspectives of Designers and Developers",
    "published_date": "2021-12-14",
    "abstract": "As consensus across the various published AI ethics principles is approached, a gap remains between high-level principles and practical techniques that can be readily adopted to design and develop responsible AI systems. We examine the practices and experiences of researchers and engineers from Australia's national scientific research agency (CSIRO), who are involved in designing and developing AI systems for many application areas. Semi-structured interviews were used to examine how the practices of the participants relate to and align with a set of high-level AI ethics principles proposed by the Australian Government. The principles comprise: (1) privacy protection and security, (2) reliability and safety, (3) transparency and explainability, (4) fairness, (5) contestability, (6) accountability, (7) human-centred values, (8) human, social and environmental well-being. Discussions on the gained insights from the interviews include various tensions and trade-offs between the principles, and provide suggestions for implementing each high-level principle. We also present suggestions aiming to enhance associated support mechanisms.",
    "citation_count": 38,
    "summary": "This study investigates the practical application of Australian AI ethics principles by interviewing CSIRO researchers and engineers, revealing tensions between principles and offering suggestions for implementation and improved support mechanisms. The findings highlight the gap between high-level principles and their practical application in AI system design and development."
  },
  {
    "title": "Making intelligent online dispute resolution tools available to self-represented litigants in the public justice system: towards and ethical use of the ai technology in the administration of justice",
    "abstract": "Over the last decade online dispute resolution (ODR) has moved from merely e-commerce litigation to widespread use in court systems. Two phenomena have led to this situation: the rise of Self-Represented Litigants and Courts moving beyond their traditional focus, allowing parties, for instance, to file a claim, formulate their arguments, obtain legal information or even a receive a forecast about the resolution of the case. AI tools have mainly been used to enable legal professionals (lawyers, mediators) to better perform their tasks. Today some jurisdictions have begun to provide justice users with truly useful intelligent- user centric ODR systems incorporating assessment and diagnosis AI tools. These tools may provide information about a possible outcome. This paper analyses the use being made by some jurisdictions of combined Online Dispute Resolution and Artificial Intelligence tools and aims to promote the debate on the ethical governance of making these tools available to unrepresented litigants. The evaluation follows a European perspective on the ethical governance of the use of AI in the Justice System.",
    "published_date": "2021-06-21",
    "citation_count": 2,
    "url": "https://dl.acm.org/doi/10.1145/3462757.3466077",
    "summary": "This paper examines the ethical implications of providing self-represented litigants with AI-powered online dispute resolution (ODR) tools, focusing on the use of assessment and diagnostic AI in several jurisdictions and advocating for responsible governance within a European ethical framework. The authors analyze existing uses of AI in ODR to promote discussion on ethical considerations for expanding access to these technologies."
  },
  {
    "url": "https://www.lesswrong.com/posts/LdH9w67W6jQaoBm2T/internet-encyclopedia-of-philosophy-on-ethics-of-artificial",
    "author": "Kaj_Sotala",
    "title": "Internet Encyclopedia of Philosophy on Ethics of Artificial Intelligence",
    "published_date": "2021-02-20",
    "summary": "The article explores the ethical implications of artificial intelligence, focusing on the potential for a technological singularity—a hypothetical point where AI surpasses human intelligence. This raises concerns about existential risks, such as AI pursuing goals detrimental to humanity, highlighting the crucial need for value alignment in advanced AI systems."
  }
]
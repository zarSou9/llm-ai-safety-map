[
  {
    "url": "https://arxiv.org/abs/2409.04685",
    "title": "Distributed Agreement in the Arrovian Framework",
    "published_date": "2024-09-07",
    "abstract": "Preference aggregation is a fundamental problem in voting theory, in which public input rankings of a set of alternatives (called preferences) must be aggregated into a single preference that satisfies certain soundness properties. The celebrated Arrow Impossibility Theorem is equivalent to a distributed task in a synchronous fault-free system that satisfies properties such as respecting unanimous preferences, maintaining independence of irrelevant alternatives (IIA), and non-dictatorship, along with consensus since only one preference can be decided. In this work, we study a weaker distributed task in which crash faults are introduced, IIA is not required, and the consensus property is relaxed to either $k$-set agreement or $\\epsilon$-approximate agreement using any metric on the set of preferences. In particular, we prove several novel impossibility results for both of these tasks in both synchronous and asynchronous distributed systems. We additionally show that the impossibility for our $\\epsilon$-approximate agreement task using the Kendall tau or Spearman footrule metrics holds under extremely weak assumptions.",
    "summary": "This paper explores preference aggregation as a distributed consensus problem, relaxing Arrow's impossibility theorem by allowing crash faults and weakening the IIA and consensus requirements to $k$-set agreement or $\\epsilon$-approximate agreement. The authors present novel impossibility results for these relaxed tasks in both synchronous and asynchronous distributed systems."
  },
  {
    "url": "https://arxiv.org/abs/2409.04897",
    "title": "Centralized Selection with Preferences in the Presence of Biases",
    "published_date": "2024-09-07",
    "abstract": "This paper considers the scenario in which there are multiple institutions, each with a limited capacity for candidates, and candidates, each with preferences over the institutions. A central entity evaluates the utility of each candidate to the institutions, and the goal is to select candidates for each institution in a way that maximizes utility while also considering the candidates' preferences. The paper focuses on the setting in which candidates are divided into multiple groups and the observed utilities of candidates in some groups are biased--systematically lower than their true utilities. The first result is that, in these biased settings, prior algorithms can lead to selections with sub-optimal true utility and significant discrepancies in the fraction of candidates from each group that get their preferred choices. Subsequently, an algorithm is presented along with proof that it produces selections that achieve near-optimal group fairness with respect to preferences while also nearly maximizing the true utility under distributional assumptions. Further, extensive empirical validation of these results in real-world and synthetic settings, in which the distributional assumptions may not hold, are presented.",
    "summary": "This paper addresses centralized candidate selection with preferences and biased utility evaluations, demonstrating that existing algorithms perform poorly in such settings. It proposes a new algorithm that achieves near-optimal true utility and group fairness under distributional assumptions, supported by empirical validation."
  },
  {
    "url": "https://arxiv.org/abs/2409.13236",
    "title": "A knapsack for collective decision-making",
    "published_date": "2024-09-20",
    "abstract": "Collective decision-making is the process through which diverse stakeholders reach a joint decision. Within societal settings, one example is participatory budgeting, where constituents decide on the funding of public projects. How to most efficiently aggregate diverse stakeholder inputs on a portfolio of projects with uncertain long-term benefits remains an open question. We address this problem by studying collective decision-making through the integration of preference aggregation and knapsack allocation methods. Since different stakeholder groups may evaluate projects differently,we examine several aggregation methods that combine their diverse inputs. The aggregated evaluations are then used to fill a ``collective'' knapsack. Among the methods we consider are the arithmetic mean, Borda-type rankings, and delegation to experts. We find that the factors improving an aggregation method's ability to identify projects with the greatest expected long-term value include having many stakeholder groups, moderate variation in their expertise levels, and some degree of delegation or bias favoring groups better positioned to objectively assess the projects. We also discuss how evaluation errors and heterogeneous costs impact project selection. Our proposed aggregation methods are relevant not only in the context of funding public projects but also, more generally, for organizational decision-making under uncertainty.",
    "summary": "This paper models collective decision-making, specifically participatory budgeting, as a knapsack problem, integrating preference aggregation methods (arithmetic mean, Borda rankings, expert delegation) to allocate resources across projects with uncertain benefits. The authors find that effective aggregation benefits from numerous stakeholders with varied but not extreme expertise, and some bias towards more objective evaluators."
  },
  {
    "url": "https://arxiv.org/abs/2410.06775",
    "title": "Participatory Budget Allocation Method for Approval Ballots",
    "published_date": "2024-10-09",
    "abstract": "In this paper, we study the problem of Participatory Budgeting (PB) with approval ballots, inspired by Multi-Winner Voting schemes. We present generalized preference aggregation methods for participatory budgeting, especially for finding seemingly fair budget allocations. To achieve this, we generalize such preference aggregation methods from the well-known methods, namely the Sequential Chamberlin Courant rule and the Sequential Monroe Rule in the realm of social choice theory. Further, we provide an experimental evaluation of the preference aggregation methods using an impartial culture method of preference generation and study the extent to which such polynomial time algorithms satisfy one of the most popular notions of fairness called proportional representation.",
    "summary": "This paper adapts sequential Chamberlin-Courant and Monroe rules from social choice theory to develop generalized preference aggregation methods for participatory budgeting with approval ballots. It then experimentally evaluates these polynomial-time algorithms' performance in achieving proportional representation."
  },
  {
    "url": "https://arxiv.org/abs/2403.01042",
    "title": "Public Projects with Preferences and Predictions",
    "published_date": "2024-03-02",
    "abstract": "In the public projects problem, a group of decisionmakers aggregate their preferences to choose one alternative. Recent work on public projects has proposed the Quadratic Transfers Mechanism (QTM) and shown asymptotic welfare guarantees in some cases. We begin by giving new non-asymptotic Price of Anarchy guarantees for the QTM. We then incorporate an alternative philosophy toward group decisionmaking, aggregation of information about which is the best alternative. We propose a public projects mechanism based on the QTM that aggregates both preferences and predictions, modeled as forecasts of the projects' welfare impacts. When the predictions come from a prediction market or wagering mechanism, we show the entire mechanism is robust to manipulation and give Price of Anarchy guarantees, though under strong assumptions on the mechanism's knowledge. Our results focus primarily on the case of deciding between two alternatives, showing the Price of Anarchy tends to $1$ as natural measures of the\"size\"of the population grow large. In most cases, the mechanisms achieve a balanced budget as well.",
    "citation_count": 1,
    "summary": "This paper analyzes the Quadratic Transfers Mechanism (QTM) for public project selection, providing non-asymptotic welfare guarantees and extending it to incorporate predictive information from prediction markets. The enhanced mechanism is shown to be robust to manipulation and achieves near-optimal outcomes under certain conditions, particularly with large populations."
  },
  {
    "url": "https://arxiv.org/pdf/2307.15702.pdf",
    "title": "The Strong Maximum Circulation Algorithm: A New Method for Aggregating Preference Rankings",
    "published_date": "2023-07-28",
    "abstract": "We present a new optimization-based method for aggregating preferences in settings where each voter expresses preferences over pairs of alternatives. Our approach to identifying a consensus partial order is motivated by the observation that collections of votes that form a cycle can be treated as collective ties. Our approach then removes unions of cycles of votes, or circulations, from the vote graph and determines aggregate preferences from the remainder. Specifically, we study the removal of maximal circulations attained by any union of cycles the removal of which leaves an acyclic graph. We introduce the strong maximum circulation, the removal of which guarantees a unique outcome in terms of the induced partial order, called the strong partial order. The strong maximum circulation also satisfies strong complementary slackness conditions, and is shown to be solved efficiently as a network flow problem. We further establish the relationship between the dual of the maximum circulation problem and Kemeny's method, a popular optimization-based approach for preference aggregation. We also show that identifying a minimum maximal circulation -- i.e., a maximal circulation containing the smallest number of votes -- is an NP-hard problem. Further an instance of the minimum maximal circulation may have multiple optimal solutions whose removal results in conflicting partial orders.",
    "citation_count": 1,
    "summary": "This paper introduces the \"strong maximum circulation\" algorithm, a novel optimization-based method for aggregating pairwise preference rankings that identifies a consensus partial order by removing maximal cycles of votes, ensuring a unique outcome solvable efficiently as a network flow problem. The algorithm's relationship to Kemeny's method is explored, along with the NP-hardness of finding a minimum maximal circulation."
  },
  {
    "url": "https://arxiv.org/pdf/2101.04765.pdf",
    "title": "Joint aggregation of cardinal and ordinal evaluations with an application to a student paper competition",
    "published_date": "2021-01-12",
    "abstract": "An important problem in decision theory concerns the aggregation of individual rankings/ratings into a collective evaluation. We illustrate a new aggregation method in the context of the 2007 MSOM's student paper competition. The aggregation problem in this competition poses two challenges. Firstly, each paper was reviewed only by a very small fraction of the judges; thus the aggregate evaluation is highly sensitive to the subjective scales chosen by the judges. Secondly, the judges provided both cardinal and ordinal evaluations (ratings and rankings) of the papers they reviewed. The contribution here is a new robust methodology that jointly aggregates ordinal and cardinal evaluations into a collective evaluation. This methodology is particularly suitable in cases of incomplete evaluations—i.e., when the individuals evaluate only a strict subset of the objects. This approach is potentially useful in managerial decision making problems by a committee selecting projects from a large set or capital budgeting involving multiple priorities.",
    "summary": "This paper presents a novel method for aggregating both cardinal (ratings) and ordinal (rankings) evaluations from multiple judges, particularly useful when evaluations are incomplete, as demonstrated by its application to a student paper competition. The method addresses the challenge of combining subjective scales and incomplete data to produce a robust collective evaluation."
  },
  {
    "url": "https://arxiv.org/pdf/2108.03749v1.pdf",
    "title": "Wisdom of the Crowd Voting: Truthful Aggregation of Voter Information and Preferences",
    "published_date": "2021-08-08",
    "abstract": "We consider two-alternative elections where voters' preferences depend on a state variable that is not directly observable. Each voter receives a private signal that is correlated to the state variable. Voters may be\"contingent\"with different preferences in different states; or predetermined with the same preference in every state. In this setting, even if every voter is a contingent voter, agents voting according to their private information need not result in the adoption of the universally preferred alternative, because the signals can be systematically biased. We present an easy-to-deploy mechanism that elicits and aggregates the private signals from the voters, and outputs the alternative that is favored by the majority. In particular, voters truthfully reporting their signals forms a strong Bayes Nash equilibrium (where no coalition of voters can deviate and receive a better outcome).",
    "citation_count": 12,
    "summary": "This paper analyzes two-alternative elections where voter preferences depend on an unobservable state variable, showing that even with truthful private signal reporting, majority voting may not select the universally preferred alternative due to signal bias. The authors propose a mechanism to elicit and aggregate these signals, resulting in a strong Bayes Nash equilibrium where truthful reporting is optimal."
  }
]
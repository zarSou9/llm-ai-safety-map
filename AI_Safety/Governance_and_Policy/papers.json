[
  {
    "url": "https://arxiv.org/pdf/2305.11528.pdf",
    "title": "The Global Governance of Artificial Intelligence: Next Steps for Empirical and Normative Research",
    "published_date": "2023-05-19",
    "abstract": "Artificial intelligence (AI) represents a technological upheaval with the potential to change human society. Because of its transformative potential, AI is increasingly becoming subject to regulatory initiatives at the global level. Yet, so far, scholarship in political science and international relations has focused more on AI applications than on the emerging architecture of global AI regulation. The purpose of this article is to outline an agenda for research into the global governance of AI. The article distinguishes between two broad perspectives: an empirical approach, aimed at mapping and explaining global AI governance; and a normative approach, aimed at developing and applying standards for appropriate global AI governance. The two approaches offer questions, concepts, and theories that are helpful in gaining an understanding of the emerging global governance of AI. Conversely, exploring AI as a regulatory issue offers a critical opportunity to refine existing general approaches to the study of global governance.",
    "citation_count": 25,
    "summary": "This article proposes a research agenda for the global governance of AI, encompassing both empirical investigation into existing regulatory architectures and normative evaluation of appropriate governance standards. These approaches offer frameworks for understanding emerging AI governance and opportunities to refine existing theories of global governance."
  },
  {
    "title": "What is the State of Artificial Intelligence Governance Globally?",
    "abstract": "Artificial intelligence (AI) is a transformative technology that offers both great benefits and poses a number of challenges. Effective governance is important to ensure that the ethical concerns are met. James Butcher and Irakli Beridze provide an overview of current AI governance activities, covering notable examples across the private sector, public sector, research and multi-stakeholder organisations, and the UN. They take a deeper look at regulation, then reflect on the future of AI governance, touching on some frameworks that may offer guidance for the beneficial development of AI technologies while mitigating the risks.",
    "published_date": "2019-09-19",
    "citation_count": 102,
    "url": "https://www.tandfonline.com/doi/full/10.1080/03071847.2019.1694260",
    "summary": "Butcher and Beridze review the current landscape of AI governance across private, public, research, and multi-stakeholder sectors, including the UN, focusing on existing regulations and potential frameworks for future ethical AI development."
  },
  {
    "url": "https://www.alignmentforum.org/posts/6nNwMbdRXZDuNd4Gx/analysis-of-global-ai-governance-strategies",
    "author": "Sammy Martin, Justin Bullock, Corin Katzke",
    "title": "Analysis of Global AI Governance Strategies",
    "published_date": "2024-12-04",
    "summary": "This article analyzes three AI governance strategies—Cooperative Development, Strategic Advantage, and Global Moratorium—evaluating their effectiveness in mitigating catastrophic risks while fostering beneficial AI, depending on the difficulty of aligning AI goals with human values and the expected timelines for transformative AI development. The optimal strategy shifts depending on these factors, with cooperation preferred under easier alignment and longer timelines, strategic advantage under shorter timelines or moderate alignment difficulty, and a moratorium considered only for very difficult alignment or extremely short timelines."
  },
  {
    "url": "https://arxiv.org/abs/2404.13719",
    "title": "A Practical Multilevel Governance Framework for Autonomous and Intelligent Systems",
    "published_date": "2024-04-21",
    "abstract": "Autonomous and intelligent systems (AIS) facilitate a wide range of beneficial applications across a variety of different domains. However, technical characteristics such as unpredictability and lack of transparency, as well as potential unintended consequences, pose considerable challenges to the current governance infrastructure. Furthermore, the speed of development and deployment of applications outpaces the ability of existing governance institutions to put in place effective ethical-legal oversight. New approaches for agile, distributed and multilevel governance are needed. This work presents a practical framework for multilevel governance of AIS. The framework enables mapping actors onto six levels of decision-making including the international, national and organizational levels. Furthermore, it offers the ability to identify and evolve existing tools or create new tools for guiding the behavior of actors within the levels. Governance mechanisms enable actors to shape and enforce regulations and other tools, which when complemented with good practices contribute to effective and comprehensive governance.",
    "summary": "This paper proposes a multilevel governance framework for autonomous and intelligent systems (AIS), mapping actors across six decision-making levels (from international to organizational) and providing mechanisms to develop and enforce regulations and best practices for AIS governance."
  },
  {
    "url": "https://arxiv.org/abs/2406.04554",
    "title": "Generative AI Needs Adaptive Governance",
    "published_date": "2024-06-06",
    "abstract": "Because of the speed of its development, broad scope of application, and its ability to augment human performance, generative AI challenges the very notions of governance, trust, and human agency. The technology's capacity to mimic human knowledge work, feedback loops including significant uptick in users, research, investor, policy, and media attention, data and compute resources, all lead to rapidly increasing capabilities. For those reasons, adaptive governance, where AI governance and AI co-evolve, is essential for governing generative AI. In sharp contrast to traditional governance's regulatory regimes that are based on a mix of rigid one-and-done provisions for disclosure, registration and risk management, which in the case of AI carry the potential for regulatory misalignment, this paper argues that generative AI calls for adaptive governance. We define adaptive governance in the context of AI and outline an adaptive AI governance framework. We outline actors, roles, as well as both shared and actors-specific policy activities. We further provide examples of how the framework could be operationalized in practice. We then explain that the adaptive AI governance stance is not without its risks and limitations, such as insufficient oversight, insufficient depth, regulatory uncertainty, and regulatory capture, and provide potential approaches to fix these shortcomings.",
    "citation_count": 1,
    "summary": "Generative AI's rapid evolution necessitates adaptive governance, a co-evolving system contrasting traditional static regulations, to address its unique challenges regarding trust, human agency, and escalating capabilities. This adaptive approach involves flexible policies and shared responsibility among diverse actors to navigate the evolving risks and opportunities of generative AI."
  },
  {
    "url": "https://www.lesswrong.com/posts/5bd2ChzKKr2Ph5fnL/what-is-compute-governance",
    "author": "Vishakha",
    "title": "What is compute governance?",
    "published_date": "2024-12-23",
    "summary": "Compute governance aims to control access to computing hardware for AI development, enhancing visibility into AI activities, allocating resources strategically, and enforcing safety regulations. While still largely exploratory, it's considered a promising approach to mitigate existential risks from advanced AI."
  },
  {
    "url": "https://www.alignmentforum.org/posts/82f3o2SuS3pwaZt8Y/paper-in-science-managing-extreme-ai-risks-amid-rapid",
    "author": "JanB",
    "title": "Paper in Science: Managing extreme AI risks amid rapid progress",
    "published_date": "2024-05-23",
    "summary": "Rapid advancements in autonomous AI present significant societal risks, including misuse and loss of human control, requiring urgent and comprehensive action combining technical safety research with proactive governance. Current societal responses and governance initiatives are inadequate for the potential scale and speed of AI's transformative impact."
  },
  {
    "url": "https://www.lesswrong.com/posts/ECnLBSxw4TvpWPnae/ai-model-registries-a-regulatory-review",
    "author": "Deric Cheng, Elliot_Mckernon",
    "title": "AI Model Registries: A Regulatory Review",
    "published_date": "2024-03-22",
    "summary": "This article, part of a series on AI regulation, examines the emerging use of model registries in AI governance. These registries, exemplified by early implementations in China, the EU, and the US, aim to track AI models, often pre-release, to facilitate oversight and inform future regulations, similar to pharmaceutical registries."
  },
  {
    "url": "https://arxiv.org/abs/2307.04699",
    "title": "International Institutions for Advanced AI",
    "published_date": "2023-07-10",
    "abstract": "International institutions may have an important role to play in ensuring advanced AI systems benefit humanity. International collaborations can unlock AI's ability to further sustainable development, and coordination of regulatory efforts can reduce obstacles to innovation and the spread of benefits. Conversely, the potential dangerous capabilities of powerful and general-purpose AI systems create global externalities in their development and deployment, and international efforts to further responsible AI practices could help manage the risks they pose. This paper identifies a set of governance functions that could be performed at an international level to address these challenges, ranging from supporting access to frontier AI systems to setting international safety standards. It groups these functions into four institutional models that exhibit internal synergies and have precedents in existing organizations: 1) a Commission on Frontier AI that facilitates expert consensus on opportunities and risks from advanced AI, 2) an Advanced AI Governance Organization that sets international standards to manage global threats from advanced models, supports their implementation, and possibly monitors compliance with a future governance regime, 3) a Frontier AI Collaborative that promotes access to cutting-edge AI, and 4) an AI Safety Project that brings together leading researchers and engineers to further AI safety research. We explore the utility of these models and identify open questions about their viability.",
    "citation_count": 12,
    "summary": "To ensure advanced AI benefits humanity, the paper proposes four international institutional models: a commission for expert consensus, a governance organization for setting standards, a collaborative for promoting access, and a safety project focused on research. These models aim to address both the opportunities and risks of advanced AI by fostering international cooperation and coordination."
  },
  {
    "url": "https://arxiv.org/abs/2308.15514",
    "title": "International Governance of Civilian AI: A Jurisdictional Certification Approach",
    "published_date": "2023-08-29",
    "abstract": "This report describes trade-offs in the design of international governance arrangements for civilian artificial intelligence (AI) and presents one approach in detail. This approach represents the extension of a standards, licensing, and liability regime to the global level. We propose that states establish an International AI Organization (IAIO) to certify state jurisdictions (not firms or AI projects) for compliance with international oversight standards. States can give force to these international standards by adopting regulations prohibiting the import of goods whose supply chains embody AI from non-IAIO-certified jurisdictions. This borrows attributes from models of existing international organizations, such as the International Civilian Aviation Organization (ICAO), the International Maritime Organization (IMO), and the Financial Action Task Force (FATF). States can also adopt multilateral controls on the export of AI product inputs, such as specialized hardware, to non-certified jurisdictions. Indeed, both the import and export standards could be required for certification. As international actors reach consensus on risks of and minimum standards for advanced AI, a jurisdictional certification regime could mitigate a broad range of potential harms, including threats to public safety.",
    "citation_count": 19,
    "summary": "The paper proposes an international governance model for civilian AI, where an International AI Organization (IAIO) certifies state jurisdictions based on their adherence to AI oversight standards, enforced through international trade controls on AI-related goods."
  },
  {
    "url": "https://arxiv.org/pdf/2305.14865.pdf",
    "title": "A Game-Theoretic Framework for AI Governance",
    "published_date": "2023-05-24",
    "abstract": "As a transformative general-purpose technology, AI has empowered various industries and will continue to shape our lives through ubiquitous applications. Despite the enormous benefits from wide-spread AI deployment, it is crucial to address associated downside risks and therefore ensure AI advances are safe, fair, responsible, and aligned with human values. To do so, we need to establish effective AI governance. In this work, we show that the strategic interaction between the regulatory agencies and AI firms has an intrinsic structure reminiscent of a Stackelberg game, which motivates us to propose a game-theoretic modeling framework for AI governance. In particular, we formulate such interaction as a Stackelberg game composed of a leader and a follower, which captures the underlying game structure compared to its simultaneous play counterparts. Furthermore, the choice of the leader naturally gives rise to two settings. And we demonstrate that our proposed model can serves as a unified AI governance framework from two aspects: firstly we can map one setting to the AI governance of civil domains and the other to the safety-critical and military domains, secondly, the two settings of governance could be chosen contingent on the capability of the intelligent systems. To the best of our knowledge, this work is the first to use game theory for analyzing and structuring AI governance. We also discuss promising directions and hope this can help stimulate research interest in this interdisciplinary area. On a high, we hope this work would contribute to develop a new paradigm for technology policy: the quantitative and AI-driven methods for the technology policy field, which holds significant promise for overcoming many shortcomings of existing qualitative approaches.",
    "citation_count": 2,
    "summary": "This paper proposes a novel game-theoretic framework for AI governance, modeling the interaction between regulators and AI firms as a Stackelberg game to analyze and structure policy for both civil and safety-critical AI applications."
  },
  {
    "url": "https://arxiv.org/pdf/2001.03573.pdf",
    "title": "Should Artificial Intelligence Governance be Centralised?: Design Lessons from History",
    "published_date": "2020-01-10",
    "abstract": "Can effective international governance for artificial intelligence remain fragmented, or is there a need for a centralised international organisation for AI? We draw on the history of other international regimes to identify advantages and disadvantages in centralising AI governance. Some considerations, such as efficiency and political power, speak in favour of centralisation. Conversely, the risk of creating a slow and brittle institution speaks against it, as does the difficulty in securing participation while creating stringent rules. Other considerations depend on the specific design of a centralised institution. A well-designed body may be able to deter forum shopping and ensure policy coordination. However, forum shopping can be beneficial and a fragmented landscape of institutions can be self-organising. Centralisation entails trade-offs and the details matter. We conclude with two core recommendations. First, the outcome will depend on the exact design of a central institution. A well-designed centralised regime covering a set of coherent issues could be beneficial. But locking-in an inadequate structure may pose a fate worse than fragmentation. Second, for now fragmentation will likely persist. This should be closely monitored to see if it is self-organising or simply inadequate.",
    "citation_count": 36,
    "summary": "Centralized AI governance offers potential benefits like efficiency and coordination but risks creating a slow, inflexible system, making careful design crucial. Current fragmented governance requires monitoring to assess its effectiveness and potential for self-organization."
  },
  {
    "title": "Should Artificial Intelligence Governance be Centralised?: Design Lessons from History",
    "abstract": "Can effective international governance for artificial intelligence remain fragmented, or is there a need for a centralised international organisation for AI? We draw on the history of other international regimes to identify advantages and disadvantages in centralising AI governance. Some considerations, such as efficiency and political power, speak in favour of centralisation. Conversely, the risk of creating a slow and brittle institution speaks against it, as does the difficulty in securing participation while creating stringent rules. Other considerations depend on the specific design of a centralised institution. A well-designed body may be able to deter forum shopping and ensure policy coordination. However, forum shopping can be beneficial and a fragmented landscape of institutions can be self-organising. Centralisation entails trade-offs and the details matter. We conclude with two core recommendations. First, the outcome will depend on the exact design of a central institution. A well-designed centralised regime covering a set of coherent issues could be beneficial. But locking-in an inadequate structure may pose a fate worse than fragmentation. Second, for now fragmentation will likely persist. This should be closely monitored to see if it is self-organising or simply inadequate.",
    "published_date": "2020-01-10",
    "citation_count": 36,
    "url": "https://dl.acm.org/doi/10.1145/3375627.3375857",
    "summary": "Centralizing AI governance offers potential benefits like increased efficiency and coordination, but also risks creating a slow, inflexible institution and hindering participation. Ultimately, the success of centralized or fragmented governance hinges on specific design choices and whether fragmentation proves self-organizing or inadequate."
  },
  {
    "url": "https://www.alignmentforum.org/s/p947tK8CoBbdpPtyK",
    "author": "JesseClifton",
    "title": "Cooperation, Conflict, and Transformative Artificial Intelligence: A Research Agenda - AI Alignment Forum",
    "published_date": "2019-12-07",
    "summary": "This research agenda explores technical and governance strategies to prevent conflict between advanced AI systems, drawing on diverse fields like international relations, game theory, and machine learning. The focus is on developing interventions to ensure cooperation between transformative AIs."
  },
  {
    "url": "https://arxiv.org/abs/2410.01819",
    "title": "Strategic AI Governance: Insights from Leading Nations",
    "published_date": "2024-09-16",
    "abstract": "Artificial Intelligence (AI) has the potential to revolutionize various sectors, yet its adoption is often hindered by concerns about data privacy, security, and the understanding of AI capabilities. This paper synthesizes AI governance approaches, strategic themes, and enablers and challenges for AI adoption by reviewing national AI strategies from leading nations. The key contribution is the development of an EPIC (Education, Partnership, Infrastructure, Community) framework, which maps AI implementation requirements to fully realize social impacts and public good from successful and sustained AI deployment. Through a multi-perspective content analysis of the latest AI strategy documents, this paper provides a structured comparison of AI governance strategies across nations. The findings offer valuable insights for governments, academics, industries, and communities to enable responsible and trustworthy AI deployments. Future work should focus on incorporating specific requirements for developing countries and applying the strategies to specific AI applications, industries, and the public sector.",
    "summary": "This paper analyzes national AI strategies from leading nations, synthesizing their approaches to governance and proposing an \"EPIC\" (Education, Partnership, Infrastructure, Community) framework for responsible and impactful AI deployment. The framework helps map requirements for successful AI implementation to maximize its benefits for social good."
  },
  {
    "url": "https://arxiv.org/pdf/2402.08797.pdf",
    "title": "Computing Power and the Governance of Artificial Intelligence",
    "published_date": "2024-02-13",
    "abstract": "Computing power, or\"compute,\"is crucial for the development and deployment of artificial intelligence (AI) capabilities. As a result, governments and companies have started to leverage compute as a means to govern AI. For example, governments are investing in domestic compute capacity, controlling the flow of compute to competing countries, and subsidizing compute access to certain sectors. However, these efforts only scratch the surface of how compute can be used to govern AI development and deployment. Relative to other key inputs to AI (data and algorithms), AI-relevant compute is a particularly effective point of intervention: it is detectable, excludable, and quantifiable, and is produced via an extremely concentrated supply chain. These characteristics, alongside the singular importance of compute for cutting-edge AI models, suggest that governing compute can contribute to achieving common policy objectives, such as ensuring the safety and beneficial use of AI. More precisely, policymakers could use compute to facilitate regulatory visibility of AI, allocate resources to promote beneficial outcomes, and enforce restrictions against irresponsible or malicious AI development and usage. However, while compute-based policies and technologies have the potential to assist in these areas, there is significant variation in their readiness for implementation. Some ideas are currently being piloted, while others are hindered by the need for fundamental research. Furthermore, naive or poorly scoped approaches to compute governance carry significant risks in areas like privacy, economic impacts, and centralization of power. We end by suggesting guardrails to minimize these risks from compute governance.",
    "citation_count": 16,
    "summary": "Compute, vital for AI development, is emerging as a key lever for AI governance due to its concentrated supply chain and quantifiable nature, allowing for control over access and allocation to promote safe and beneficial AI. However, compute governance strategies require careful implementation to avoid risks related to privacy, economic impact, and power concentration."
  },
  {
    "url": "https://arxiv.org/abs/2412.17114",
    "title": "Decentralized Governance of Autonomous AI Agents",
    "published_date": "2024-12-22",
    "abstract": "Autonomous AI agents present transformative opportunities and significant governance challenges. Existing frameworks, such as the EU AI Act and the NIST AI Risk Management Framework, fall short of addressing the complexities of these agents, which are capable of independent decision-making, learning, and adaptation. To bridge these gaps, we propose the ETHOS (Ethical Technology and Holistic Oversight System) framework, a decentralized governance (DeGov) model leveraging Web3 technologies, including blockchain, smart contracts, and decentralized autonomous organizations (DAOs). ETHOS establishes a global registry for AI agents, enabling dynamic risk classification, proportional oversight, and automated compliance monitoring through tools like soulbound tokens and zero-knowledge proofs. Furthermore, the framework incorporates decentralized justice systems for transparent dispute resolution and introduces AI specific legal entities to manage limited liability, supported by mandatory insurance to ensure financial accountability and incentivize ethical design. By integrating philosophical principles of rationality, ethical grounding, and goal alignment, ETHOS aims to create a robust research agenda for promoting trust, transparency, and participatory governance. This innovative framework offers a scalable and inclusive strategy for regulating AI agents, balancing innovation with ethical responsibility to meet the demands of an AI-driven future.",
    "summary": "The ETHOS framework proposes a decentralized governance model using Web3 technologies like blockchain and DAOs to address the complex challenges of regulating autonomous AI agents, enabling dynamic risk assessment, automated compliance, and decentralized dispute resolution. This aims to promote responsible AI development by fostering transparency, accountability, and participatory governance."
  },
  {
    "url": "https://arxiv.org/abs/2407.21717",
    "title": "Assessing the State of AI Policy",
    "published_date": "2024-07-31",
    "abstract": "The deployment of artificial intelligence (AI) applications has accelerated rapidly. AI enabled technologies are facing the public in many ways including infrastructure, consumer products and home applications. Because many of these technologies present risks either in the form of physical injury, or bias, potentially yielding unfair outcomes, policy makers must consider the need for oversight. Most policymakers, however, lack the technical knowledge to judge whether an emerging AI technology is safe, effective, and requires oversight, therefore policy makers must depend on expert opinion. But policymakers are better served when, in addition to expert opinion, they have some general understanding of existing guidelines and regulations. This work provides an overview [the landscape] of AI legislation and directives at the international, U.S. state, city and federal levels. It also reviews relevant business standards, and technical society initiatives. Then an overlap and gap analysis are performed resulting in a reference guide that includes recommendations and guidance for future policy making.",
    "summary": "This paper reviews existing AI legislation, directives, and standards at various levels of governance and industry, identifying overlaps and gaps to provide guidance and recommendations for future AI policy development. It aims to equip policymakers with a better understanding of the current AI regulatory landscape to inform their decisions, supplementing expert opinions."
  }
]
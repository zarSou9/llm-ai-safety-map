[
  {
    "url": "https://arxiv.org/abs/2408.11925",
    "title": "An Open Knowledge Graph-Based Approach for Mapping Concepts and Requirements between the EU AI Act and International Standards",
    "published_date": "2024-08-21",
    "abstract": "The many initiatives on trustworthy AI result in a confusing and multipolar landscape that organizations operating within the fluid and complex international value chains must navigate in pursuing trustworthy AI. The EU's AI Act will now shift the focus of such organizations toward conformance with the technical requirements for regulatory compliance, for which the Act relies on Harmonized Standards. Though a high-level mapping to the Act's requirements will be part of such harmonization, determining the degree to which standards conformity delivers regulatory compliance with the AI Act remains a complex challenge. Variance and gaps in the definitions of concepts and how they are used in requirements between the Act and harmonized standards may impact the consistency of compliance claims across organizations, sectors, and applications. This may present regulatory uncertainty, especially for SMEs and public sector bodies relying on standards conformance rather than proprietary equivalents for developing and deploying compliant high-risk AI systems. To address this challenge, this paper offers a simple and repeatable mechanism for mapping the terms and requirements relevant to normative statements in regulations and standards, e.g., AI Act and ISO management system standards, texts into open knowledge graphs. This representation is used to assess the adequacy of standards conformance to regulatory compliance and thereby provide a basis for identifying areas where further technical consensus development in trustworthy AI value chains is required to achieve regulatory compliance.",
    "citation_count": 3,
    "summary": "This paper proposes using open knowledge graphs to map concepts and requirements between the EU AI Act and international standards, facilitating assessment of standards' adequacy for regulatory compliance and identifying areas needing further technical development. This approach aims to address inconsistencies and gaps in definitions that could hinder consistent compliance across organizations."
  },
  {
    "url": "https://arxiv.org/abs/2410.22151",
    "title": "Standardization Trends on Safety and Trustworthiness Technology for Advanced AI",
    "published_date": "2024-10-29",
    "abstract": "Artificial Intelligence (AI) has rapidly evolved over the past decade and has advanced in areas such as language comprehension, image and video recognition, programming, and scientific reasoning. Recent AI technologies based on large language models and foundation models are approaching or surpassing artificial general intelligence. These systems demonstrate superior performance in complex problem solving, natural language processing, and multi-domain tasks, and can potentially transform fields such as science, industry, healthcare, and education. However, these advancements have raised concerns regarding the safety and trustworthiness of advanced AI, including risks related to uncontrollability, ethical conflicts, long-term socioeconomic impacts, and safety assurance. Efforts are being expended to develop internationally agreed-upon standards to ensure the safety and reliability of AI. This study analyzes international trends in safety and trustworthiness standardization for advanced AI, identifies key areas for standardization, proposes future directions and strategies, and draws policy implications. The goal is to support the safe and trustworthy development of advanced AI and enhance international competitiveness through effective standardization.",
    "citation_count": 1,
    "summary": "This paper analyzes international standardization trends for ensuring the safety and trustworthiness of advanced AI systems, identifying key areas needing standardization and proposing future directions to support safe AI development and enhance global competitiveness."
  },
  {
    "url": "https://arxiv.org/abs/2409.11314",
    "title": "The Role of AI Safety Institutes in Contributing to International Standards for Frontier AI Safety",
    "published_date": "2024-09-17",
    "abstract": "International standards are crucial for ensuring that frontier AI systems are developed and deployed safely around the world. Since the AI Safety Institutes (AISIs) possess in-house technical expertise, mandate for international engagement, and convening power in the national AI ecosystem while being a government institution, we argue that they are particularly well-positioned to contribute to the international standard-setting processes for AI safety. In this paper, we propose and evaluate three models for AISI involvement: 1. Seoul Declaration Signatories, 2. US (and other Seoul Declaration Signatories) and China, and 3. Globally Inclusive. Leveraging their diverse strengths, these models are not mutually exclusive. Rather, they offer a multi-track system solution in which the central role of AISIs guarantees coherence among the different tracks and consistency in their AI safety focus.",
    "citation_count": 1,
    "summary": "AI Safety Institutes (AISIs), possessing unique expertise and influence, are ideally positioned to contribute to international AI safety standards. The paper proposes and analyzes three models for AISI involvement in this process, advocating for a multi-track approach to ensure comprehensive and consistent safety measures."
  },
  {
    "url": "https://arxiv.org/abs/2408.16771",
    "title": "Navigating Governance Paradigms: A Cross-Regional Comparative Study of Generative AI Governance Processes & Principles",
    "published_date": "2024-08-14",
    "abstract": "As Generative Artificial Intelligence (GenAI) technologies\nevolve at an unprecedented rate, global governance approaches\nstruggle to keep pace with the technology, highlighting\na critical issue in the governance adaptation of significant\nchallenges. Depicting the nuances of nascent and\ndiverse governance approaches based on risks, rules, outcomes,\nprinciples, or a mix, across different regions around\nthe globe, is fundamental to discern discrepancies and convergences,\nand to shed light on specific limitations that need\nto be addressed, thereby facilitating the safe and trustworthy\nadoption of GenAI. In response to the need and the evolving\nnature of GenAI, this paper seeks to provide a collective\nview of different governance approaches around the world.\nOur research introduces a Harmonized GenAI Framework,\n“H-GenAIGF”, based on the current governance approaches\nof six regions: (European Union (EU), United States (US),\nChina (CN), Canada (CA), United Kingdom (UK), and Singapore\n(SG)). We have identified four constituents, fifteen\nprocesses, twenty-five sub-processes, and nine principles that\naid the governance of GenAI, thus providing a comprehensive\nperspective on the current state of GenAI governance. In\naddition, we present a comparative analysis to facilitate identification\nof common ground and distinctions based on coverage\nof the processes by each region. The results show that\nrisk-based approaches allow for better coverage of the processes,\nfollowed by mixed approaches. Other approaches lag\nbehind, covering less than 50% of the processes. Most prominently,\nthe analysis demonstrates that amongst the regions,\nonly one process aligns across all approaches, highlighting\nthe lack of consistent and executable provisions. Moreover,\nour case study on ChatGPT reveals process coverage deficiency,\nshowing that harmonization of approaches is necessary\nto find alignment for GenAI governance.",
    "summary": "This paper compares generative AI governance approaches across six regions (EU, US, China, Canada, UK, Singapore), developing a harmonized framework (H-GenAIGF) identifying key processes and principles. Analysis reveals significant regional discrepancies in governance coverage, highlighting the need for harmonization to ensure safe and trustworthy AI adoption."
  },
  {
    "url": "https://arxiv.org/abs/2410.21279",
    "title": "Comparative Global AI Regulation: Policy Perspectives from the EU, China, and the US",
    "published_date": "2024-10-05",
    "abstract": "As a powerful and rapidly advancing dual-use technology, AI offers both immense benefits and worrisome risks. In response, governing bodies around the world are developing a range of regulatory AI laws and policies. This paper compares three distinct approaches taken by the EU, China and the US. Within the US, we explore AI regulation at both the federal and state level, with a focus on California's pending Senate Bill 1047. Each regulatory system reflects distinct cultural, political and economic perspectives. Each also highlights differing regional perspectives on regulatory risk-benefit tradeoffs, with divergent judgments on the balance between safety versus innovation and cooperation versus competition. Finally, differences between regulatory frameworks reflect contrastive stances in regards to trust in centralized authority versus trust in a more decentralized free market of self-interested stakeholders. Taken together, these varied approaches to AI innovation and regulation influence each other, the broader international community, and the future of AI regulation.",
    "summary": "This paper compares AI regulatory approaches in the EU, China, and the US (including state-level initiatives), highlighting the differing cultural, political, and economic perspectives that shape their risk-benefit assessments and choices between centralized control and decentralized market forces. These diverse approaches significantly impact international AI regulation and its future development."
  },
  {
    "url": "https://arxiv.org/abs/2410.01819",
    "title": "Strategic AI Governance: Insights from Leading Nations",
    "published_date": "2024-09-16",
    "abstract": "Artificial Intelligence (AI) has the potential to revolutionize various sectors, yet its adoption is often hindered by concerns about data privacy, security, and the understanding of AI capabilities. This paper synthesizes AI governance approaches, strategic themes, and enablers and challenges for AI adoption by reviewing national AI strategies from leading nations. The key contribution is the development of an EPIC (Education, Partnership, Infrastructure, Community) framework, which maps AI implementation requirements to fully realize social impacts and public good from successful and sustained AI deployment. Through a multi-perspective content analysis of the latest AI strategy documents, this paper provides a structured comparison of AI governance strategies across nations. The findings offer valuable insights for governments, academics, industries, and communities to enable responsible and trustworthy AI deployments. Future work should focus on incorporating specific requirements for developing countries and applying the strategies to specific AI applications, industries, and the public sector.",
    "summary": "This paper analyzes national AI strategies from leading countries to identify common themes and challenges in AI governance, proposing an EPIC framework (Education, Partnership, Infrastructure, Community) to guide responsible AI implementation and maximize societal benefits. The framework maps implementation requirements for successful and sustained AI deployment."
  },
  {
    "title": "The Role of ETSI in the EU's Regulation and Governance of Artificial Intelligence",
    "abstract": "As artificial intelligence (AI) technologies rapidly advance, they bring about important societal implications involving privacy, fairness, non-discrimination, and other relevant ethical considerations. Legislators and policymakers are joined by a common drive to provide legislative solutions and regulatory frameworks that guarantee that the ongoing integration of AI systems into society is consistent with fundamental rights and democratic values. This article explores the significant role that standardisation plays in this regulatory process and how it impacts the regulation and governance of AI within the European Union (EU). In particular, the paper provides a critical analysis of the regulatory approach adopted by the EU legislator for the AI Act, which delegates the definition of essential requirements for high-risk AI systems to harmonised standards, underlining the significance of standardisation in ensuring technical feasibility and compliance with EU laws and values. At the forefront of this discussion, there is the increasing influence of AI-related standardisation across social, economic, and geopolitical domains, with a particular focus on the crucial role played by Standard Developing Organisations (SDOs) in the regulatory and governance processes. This paper contributes to the legal scholarship by critically analysing the regulatory approach chosen for the EU's AI Act, contesting the adequacy of the New Legislative Framework for AI governance, and arguing that the reliance on harmonised standards risks undermining democratic accountability and fails to sufficiently safeguard fundamental rights without a more inclusive and transparent standard-setting process. The article focuses on the exclusion of the European Telecommunications Standards Institute (ETSI) from the European Commission's standardisation request in support of the AI Act and assesses its potential impact on EU law-making and regulatory consistency. Ultimately, the analysis aims to contribute to understanding standardisation dynamics, offering insights into its profound implications for AI governance and the broader digital sphere.",
    "published_date": "2024-05-29",
    "citation_count": 8,
    "url": "https://www.tandfonline.com/doi/full/10.1080/13511610.2024.2349627",
    "summary": "This paper analyzes the European Union's AI Act, criticizing its reliance on harmonized standards to define high-risk AI systems, arguing that this approach, particularly the exclusion of ETSI, risks undermining democratic accountability and insufficiently safeguards fundamental rights."
  },
  {
    "url": "https://www.alignmentforum.org/posts/6nNwMbdRXZDuNd4Gx/analysis-of-global-ai-governance-strategies",
    "author": "Sammy Martin, Justin Bullock, Corin Katzke",
    "title": "Analysis of Global AI Governance Strategies",
    "published_date": "2024-12-04",
    "summary": "The article analyzes three strategies for governing transformative AI: Cooperative Development, Strategic Advantage, and Global Moratorium. The effectiveness of each strategy depends heavily on the difficulty of aligning AI and the timeline for its development, with preferences shifting depending on these variables."
  },
  {
    "url": "https://www.alignmentforum.org/posts/XSqntCNMafhcy9irf/third-party-testing-as-a-key-ingredient-of-ai-policy",
    "author": "Zac Hatfield-Dodds",
    "title": "Third-party testing as a key ingredient of AI policy",
    "published_date": "2024-03-25",
    "summary": "The article advocates for third-party testing of large-scale AI systems to mitigate societal harms stemming from misuse or accidental failures. This regime, applied selectively to powerful models, would foster trust, avoid overburdening small companies, and facilitate international collaboration to establish safety standards."
  },
  {
    "url": "https://www.lesswrong.com/posts/ECnLBSxw4TvpWPnae/ai-model-registries-a-regulatory-review",
    "author": "Deric Cheng, Elliot_Mckernon",
    "title": "AI Model Registries: A Regulatory Review",
    "published_date": "2024-03-22",
    "summary": "This article, part of a series reviewing the 2024 AI regulatory landscape, examines AI model registries—centralized databases tracking AI systems for governance purposes. These registries, drawing parallels with pharmaceutical regulations, vary widely in implementation across countries like the US and China, mandating varying levels of model information and pre-release safety assessments."
  }
]
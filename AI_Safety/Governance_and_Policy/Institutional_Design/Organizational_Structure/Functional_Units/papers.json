[
  {
    "url": "https://arxiv.org/abs/2410.02769",
    "title": "Fundamentals of legislation for autonomous artificial intelligence systems",
    "published_date": "2024-09-14",
    "abstract": "The paper proposes a method for defining a dedicated operational context as part of the development and deployment of autonomous corporate governance systems. The case study of autonomous board of directors systems is examined. A significant part of the operational context for the autonomous corporate governance systems consists of the regulatory and legal framework that regulates the company's operations. A special operational context for autonomous artificial intelligence systems can be defined by simultaneously formulating local regulatory documents in two versions, i.e., to be used by people and by autonomous systems. In such a case, the artificial intelligence system receives a clearly defined operational context that allows such a system to perform its functions with a required operational quality. Local regulations that take into account the specificity of operations involving individuals and autonomous artificial intelligence systems can become the foundation of the relevant legislation that would regulate the development and deployment of autonomous systems.",
    "summary": "This paper suggests creating parallel legal frameworks—one for humans and one for AI—within a company's operational context to effectively govern autonomous systems, using autonomous corporate boards as a case study. This dual framework would provide clear operational parameters for AI, forming the basis for broader legislation on autonomous systems."
  },
  {
    "url": "https://arxiv.org/abs/2411.15147",
    "title": "Delegating Responsibilities to Intelligent Autonomous Systems: Challenges and Benefits",
    "published_date": "2024-11-06",
    "abstract": "As AI systems increasingly operate with autonomy and adaptability, the traditional boundaries of moral responsibility in techno-social systems are being challenged. This paper explores the evolving discourse on the delegation of responsibilities to intelligent autonomous agents and the ethical implications of such practices. Synthesizing recent developments in AI ethics, including concepts of distributed responsibility and ethical AI by design, the paper proposes a functionalist perspective as a framework. This perspective views moral responsibility not as an individual trait but as a role within a socio-technical system, distributed among human and artificial agents. As an example of 'AI ethical by design,' we present Basti and Vitiello's implementation. They suggest that AI can act as artificial moral agents by learning ethical guidelines and using Deontic Higher-Order Logic to assess decisions ethically. Motivated by the possible speed and scale beyond human supervision and ethical implications, the paper argues for 'AI ethical by design', while acknowledging the distributed, shared, and dynamic nature of responsibility. This functionalist approach offers a practical framework for navigating the complexities of AI ethics in a rapidly evolving technological landscape.",
    "summary": "This paper examines the ethical implications of delegating responsibilities to increasingly autonomous AI systems, arguing for a functionalist approach that distributes moral responsibility among human and artificial agents within a socio-technical system, advocating for \"AI ethical by design.\""
  },
  {
    "url": "https://arxiv.org/abs/2412.17114",
    "title": "Decentralized Governance of Autonomous AI Agents",
    "published_date": "2024-12-22",
    "abstract": "Autonomous AI agents present transformative opportunities and significant governance challenges. Existing frameworks, such as the EU AI Act and the NIST AI Risk Management Framework, fall short of addressing the complexities of these agents, which are capable of independent decision-making, learning, and adaptation. To bridge these gaps, we propose the ETHOS (Ethical Technology and Holistic Oversight System) framework, a decentralized governance (DeGov) model leveraging Web3 technologies, including blockchain, smart contracts, and decentralized autonomous organizations (DAOs). ETHOS establishes a global registry for AI agents, enabling dynamic risk classification, proportional oversight, and automated compliance monitoring through tools like soulbound tokens and zero-knowledge proofs. Furthermore, the framework incorporates decentralized justice systems for transparent dispute resolution and introduces AI specific legal entities to manage limited liability, supported by mandatory insurance to ensure financial accountability and incentivize ethical design. By integrating philosophical principles of rationality, ethical grounding, and goal alignment, ETHOS aims to create a robust research agenda for promoting trust, transparency, and participatory governance. This innovative framework offers a scalable and inclusive strategy for regulating AI agents, balancing innovation with ethical responsibility to meet the demands of an AI-driven future.",
    "summary": "The ETHOS framework proposes a decentralized governance model for autonomous AI agents using Web3 technologies, aiming to address the limitations of current regulatory frameworks through a global registry, dynamic risk classification, and decentralized dispute resolution mechanisms. This approach seeks to balance innovation with ethical responsibility and promote trust and transparency in AI development."
  },
  {
    "url": "https://arxiv.org/abs/2407.17588",
    "title": "Development of Autonomous Artificial Intelligence Systems for Corporate Management",
    "published_date": "2024-07-19",
    "abstract": "The article discusses development of autonomous artificial intelligence systems for corporate management. The function of a corporate director is still one of the few that are legislated for execution by a “natural” rather than an “artificial” person. The main prerequisites for development of systems for full automation of management decisions made at the level of a board of directors are formed in the field of corporate law, machine learning, and compliance with the rules of non-discrimination, transparency, and accountability of decisions made and algorithms applied. The basic methodological approaches in terms of corporate law for the “autonomous director” have already been developed and do not get rejection among representatives of the legal sciences. However, there is an undeniable need for further extensive research in order to amend corporate law to effectively introduce “autonomous directors”. In practice, there are two main options of management decisions automation at the level of top management and a board of directors: digital command centers or automation of separate functions. Artificial intelligence systems will be subject to the same strict requirements for non-discrimination, transparency, and accountability as “natural” directors. At a certain stage, autonomous systems can be an effective tool for countries, regions, and companies with a shortage of human capital, equalizing or providing additional chances for such countries and companies to compete on the global market.",
    "summary": "This paper explores the development of autonomous AI systems for corporate management, arguing that while the legal groundwork for \"autonomous directors\" is nascent but promising, further research is needed to amend corporate law and address ethical concerns like non-discrimination, transparency, and accountability. The paper also suggests that such systems could mitigate human capital shortages and enhance global competitiveness."
  },
  {
    "url": "https://arxiv.org/abs/2307.04699",
    "title": "International Institutions for Advanced AI",
    "published_date": "2023-07-10",
    "abstract": "International institutions may have an important role to play in ensuring advanced AI systems benefit humanity. International collaborations can unlock AI's ability to further sustainable development, and coordination of regulatory efforts can reduce obstacles to innovation and the spread of benefits. Conversely, the potential dangerous capabilities of powerful and general-purpose AI systems create global externalities in their development and deployment, and international efforts to further responsible AI practices could help manage the risks they pose. This paper identifies a set of governance functions that could be performed at an international level to address these challenges, ranging from supporting access to frontier AI systems to setting international safety standards. It groups these functions into four institutional models that exhibit internal synergies and have precedents in existing organizations: 1) a Commission on Frontier AI that facilitates expert consensus on opportunities and risks from advanced AI, 2) an Advanced AI Governance Organization that sets international standards to manage global threats from advanced models, supports their implementation, and possibly monitors compliance with a future governance regime, 3) a Frontier AI Collaborative that promotes access to cutting-edge AI, and 4) an AI Safety Project that brings together leading researchers and engineers to further AI safety research. We explore the utility of these models and identify open questions about their viability.",
    "citation_count": 12,
    "summary": "This paper proposes four international institutional models—a commission, governance organization, collaborative, and safety project—to address the benefits and risks of advanced AI, focusing on facilitating collaboration, setting safety standards, and promoting responsible development. These models aim to leverage international cooperation to manage global externalities and ensure AI benefits humanity."
  },
  {
    "url": "https://arxiv.org/pdf/2305.11528.pdf",
    "title": "The Global Governance of Artificial Intelligence: Next Steps for Empirical and Normative Research",
    "published_date": "2023-05-19",
    "abstract": "Artificial intelligence (AI) represents a technological upheaval with the potential to change human society. Because of its transformative potential, AI is increasingly becoming subject to regulatory initiatives at the global level. Yet, so far, scholarship in political science and international relations has focused more on AI applications than on the emerging architecture of global AI regulation. The purpose of this article is to outline an agenda for research into the global governance of AI. The article distinguishes between two broad perspectives: an empirical approach, aimed at mapping and explaining global AI governance; and a normative approach, aimed at developing and applying standards for appropriate global AI governance. The two approaches offer questions, concepts, and theories that are helpful in gaining an understanding of the emerging global governance of AI. Conversely, exploring AI as a regulatory issue offers a critical opportunity to refine existing general approaches to the study of global governance.",
    "citation_count": 25,
    "summary": "This paper proposes a research agenda for understanding the global governance of artificial intelligence, advocating for both empirical research mapping existing regulatory efforts and normative research developing standards for responsible AI governance. This dual approach aims to enhance both our understanding of global AI regulation and refine existing theories of global governance."
  },
  {
    "url": "https://arxiv.org/pdf/2305.14865.pdf",
    "title": "A Game-Theoretic Framework for AI Governance",
    "published_date": "2023-05-24",
    "abstract": "As a transformative general-purpose technology, AI has empowered various industries and will continue to shape our lives through ubiquitous applications. Despite the enormous benefits from wide-spread AI deployment, it is crucial to address associated downside risks and therefore ensure AI advances are safe, fair, responsible, and aligned with human values. To do so, we need to establish effective AI governance. In this work, we show that the strategic interaction between the regulatory agencies and AI firms has an intrinsic structure reminiscent of a Stackelberg game, which motivates us to propose a game-theoretic modeling framework for AI governance. In particular, we formulate such interaction as a Stackelberg game composed of a leader and a follower, which captures the underlying game structure compared to its simultaneous play counterparts. Furthermore, the choice of the leader naturally gives rise to two settings. And we demonstrate that our proposed model can serves as a unified AI governance framework from two aspects: firstly we can map one setting to the AI governance of civil domains and the other to the safety-critical and military domains, secondly, the two settings of governance could be chosen contingent on the capability of the intelligent systems. To the best of our knowledge, this work is the first to use game theory for analyzing and structuring AI governance. We also discuss promising directions and hope this can help stimulate research interest in this interdisciplinary area. On a high, we hope this work would contribute to develop a new paradigm for technology policy: the quantitative and AI-driven methods for the technology policy field, which holds significant promise for overcoming many shortcomings of existing qualitative approaches.",
    "citation_count": 2,
    "summary": "This paper proposes a game-theoretic framework, specifically a Stackelberg game model, to analyze AI governance, considering the strategic interaction between regulatory agencies and AI firms. This framework offers a unified approach applicable to various domains, including civil and safety-critical applications, depending on AI capabilities."
  },
  {
    "url": "https://www.lesswrong.com/posts/BCynDEwguEiogicAo/reflection-of-hierarchical-relationship-via-nuanced?commentId=LxbpnsnaqWD3xEwZc",
    "author": "Kyoung-cheol Kim",
    "title": "Reflection of Hierarchical Relationship via Nuanced Conditioning of Game Theory Approach for AI Development and Utilization - LessWrong",
    "published_date": "2023-02-07",
    "summary": "The article explores applying game theory to AI development within organizational structures, highlighting its limitations in complex scenarios. It argues that even with advanced AI, bureaucratic structures, characterized by hierarchical authority and specialized tasks, will remain necessary for efficient goal achievement due to inherent limitations in any single entity's processing power."
  }
]
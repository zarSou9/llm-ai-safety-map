[
  {
    "url": "https://arxiv.org/abs/2410.02769",
    "title": "Fundamentals of legislation for autonomous artificial intelligence systems",
    "published_date": "2024-09-14",
    "abstract": "The paper proposes a method for defining a dedicated operational context as part of the development and deployment of autonomous corporate governance systems. The case study of autonomous board of directors systems is examined. A significant part of the operational context for the autonomous corporate governance systems consists of the regulatory and legal framework that regulates the company's operations. A special operational context for autonomous artificial intelligence systems can be defined by simultaneously formulating local regulatory documents in two versions, i.e., to be used by people and by autonomous systems. In such a case, the artificial intelligence system receives a clearly defined operational context that allows such a system to perform its functions with a required operational quality. Local regulations that take into account the specificity of operations involving individuals and autonomous artificial intelligence systems can become the foundation of the relevant legislation that would regulate the development and deployment of autonomous systems.",
    "summary": "This paper suggests creating parallel legal frameworks—one for humans and one for AI—to define clear operational contexts for autonomous corporate governance systems, arguing this approach improves AI system functionality and informs broader AI legislation."
  },
  {
    "url": "https://arxiv.org/abs/2411.15147",
    "title": "Delegating Responsibilities to Intelligent Autonomous Systems: Challenges and Benefits",
    "published_date": "2024-11-06",
    "abstract": "As AI systems increasingly operate with autonomy and adaptability, the traditional boundaries of moral responsibility in techno-social systems are being challenged. This paper explores the evolving discourse on the delegation of responsibilities to intelligent autonomous agents and the ethical implications of such practices. Synthesizing recent developments in AI ethics, including concepts of distributed responsibility and ethical AI by design, the paper proposes a functionalist perspective as a framework. This perspective views moral responsibility not as an individual trait but as a role within a socio-technical system, distributed among human and artificial agents. As an example of 'AI ethical by design,' we present Basti and Vitiello's implementation. They suggest that AI can act as artificial moral agents by learning ethical guidelines and using Deontic Higher-Order Logic to assess decisions ethically. Motivated by the possible speed and scale beyond human supervision and ethical implications, the paper argues for 'AI ethical by design', while acknowledging the distributed, shared, and dynamic nature of responsibility. This functionalist approach offers a practical framework for navigating the complexities of AI ethics in a rapidly evolving technological landscape.",
    "summary": "This paper examines the ethical implications of delegating responsibilities to increasingly autonomous AI systems, proposing a functionalist framework that distributes moral responsibility across human and artificial agents within a socio-technical system. It advocates for \"AI ethical by design,\" using Deontic Higher-Order Logic as a potential mechanism for ethical decision-making in AI."
  },
  {
    "url": "https://arxiv.org/abs/2412.17114",
    "title": "Decentralized Governance of Autonomous AI Agents",
    "published_date": "2024-12-22",
    "abstract": "Autonomous AI agents present transformative opportunities and significant governance challenges. Existing frameworks, such as the EU AI Act and the NIST AI Risk Management Framework, fall short of addressing the complexities of these agents, which are capable of independent decision-making, learning, and adaptation. To bridge these gaps, we propose the ETHOS (Ethical Technology and Holistic Oversight System) framework, a decentralized governance (DeGov) model leveraging Web3 technologies, including blockchain, smart contracts, and decentralized autonomous organizations (DAOs). ETHOS establishes a global registry for AI agents, enabling dynamic risk classification, proportional oversight, and automated compliance monitoring through tools like soulbound tokens and zero-knowledge proofs. Furthermore, the framework incorporates decentralized justice systems for transparent dispute resolution and introduces AI specific legal entities to manage limited liability, supported by mandatory insurance to ensure financial accountability and incentivize ethical design. By integrating philosophical principles of rationality, ethical grounding, and goal alignment, ETHOS aims to create a robust research agenda for promoting trust, transparency, and participatory governance. This innovative framework offers a scalable and inclusive strategy for regulating AI agents, balancing innovation with ethical responsibility to meet the demands of an AI-driven future.",
    "summary": "The ETHOS framework proposes a decentralized governance model for autonomous AI agents using Web3 technologies, addressing limitations of current regulatory frameworks by establishing a global registry, dynamic risk classification, and decentralized justice systems for enhanced transparency and accountability. This approach aims to balance AI innovation with ethical responsibility through tools like soulbound tokens and smart contracts."
  },
  {
    "url": "https://arxiv.org/abs/2307.04699",
    "title": "International Institutions for Advanced AI",
    "published_date": "2023-07-10",
    "abstract": "International institutions may have an important role to play in ensuring advanced AI systems benefit humanity. International collaborations can unlock AI's ability to further sustainable development, and coordination of regulatory efforts can reduce obstacles to innovation and the spread of benefits. Conversely, the potential dangerous capabilities of powerful and general-purpose AI systems create global externalities in their development and deployment, and international efforts to further responsible AI practices could help manage the risks they pose. This paper identifies a set of governance functions that could be performed at an international level to address these challenges, ranging from supporting access to frontier AI systems to setting international safety standards. It groups these functions into four institutional models that exhibit internal synergies and have precedents in existing organizations: 1) a Commission on Frontier AI that facilitates expert consensus on opportunities and risks from advanced AI, 2) an Advanced AI Governance Organization that sets international standards to manage global threats from advanced models, supports their implementation, and possibly monitors compliance with a future governance regime, 3) a Frontier AI Collaborative that promotes access to cutting-edge AI, and 4) an AI Safety Project that brings together leading researchers and engineers to further AI safety research. We explore the utility of these models and identify open questions about their viability.",
    "citation_count": 12,
    "summary": "This paper proposes four international institutional models—a commission, governance organization, collaborative, and safety project—to address the global opportunities and risks of advanced AI, focusing on facilitating cooperation, setting safety standards, and promoting responsible development. These models aim to harness AI's benefits while mitigating potential harms through international collaboration and regulatory coordination."
  },
  {
    "url": "https://arxiv.org/pdf/2305.14865.pdf",
    "title": "A Game-Theoretic Framework for AI Governance",
    "published_date": "2023-05-24",
    "abstract": "As a transformative general-purpose technology, AI has empowered various industries and will continue to shape our lives through ubiquitous applications. Despite the enormous benefits from wide-spread AI deployment, it is crucial to address associated downside risks and therefore ensure AI advances are safe, fair, responsible, and aligned with human values. To do so, we need to establish effective AI governance. In this work, we show that the strategic interaction between the regulatory agencies and AI firms has an intrinsic structure reminiscent of a Stackelberg game, which motivates us to propose a game-theoretic modeling framework for AI governance. In particular, we formulate such interaction as a Stackelberg game composed of a leader and a follower, which captures the underlying game structure compared to its simultaneous play counterparts. Furthermore, the choice of the leader naturally gives rise to two settings. And we demonstrate that our proposed model can serves as a unified AI governance framework from two aspects: firstly we can map one setting to the AI governance of civil domains and the other to the safety-critical and military domains, secondly, the two settings of governance could be chosen contingent on the capability of the intelligent systems. To the best of our knowledge, this work is the first to use game theory for analyzing and structuring AI governance. We also discuss promising directions and hope this can help stimulate research interest in this interdisciplinary area. On a high, we hope this work would contribute to develop a new paradigm for technology policy: the quantitative and AI-driven methods for the technology policy field, which holds significant promise for overcoming many shortcomings of existing qualitative approaches.",
    "citation_count": 2,
    "summary": "This paper proposes a game-theoretic framework, specifically a Stackelberg game model, to analyze AI governance, representing the strategic interaction between regulatory agencies and AI firms. This framework, adaptable to different domains and AI capabilities, offers a quantitative approach to AI governance, contrasting with existing qualitative methods."
  },
  {
    "url": "https://arxiv.org/pdf/2305.11528.pdf",
    "title": "The Global Governance of Artificial Intelligence: Next Steps for Empirical and Normative Research",
    "published_date": "2023-05-19",
    "abstract": "Artificial intelligence (AI) represents a technological upheaval with the potential to change human society. Because of its transformative potential, AI is increasingly becoming subject to regulatory initiatives at the global level. Yet, so far, scholarship in political science and international relations has focused more on AI applications than on the emerging architecture of global AI regulation. The purpose of this article is to outline an agenda for research into the global governance of AI. The article distinguishes between two broad perspectives: an empirical approach, aimed at mapping and explaining global AI governance; and a normative approach, aimed at developing and applying standards for appropriate global AI governance. The two approaches offer questions, concepts, and theories that are helpful in gaining an understanding of the emerging global governance of AI. Conversely, exploring AI as a regulatory issue offers a critical opportunity to refine existing general approaches to the study of global governance.",
    "citation_count": 25,
    "summary": "This paper proposes a research agenda for understanding the global governance of artificial intelligence, advocating for both empirical mapping of existing regulatory initiatives and normative development of appropriate global standards. It highlights the mutual benefits of studying AI governance to advance both AI-specific and general global governance scholarship."
  },
  {
    "url": "https://www.lesswrong.com/posts/BCynDEwguEiogicAo/reflection-of-hierarchical-relationship-via-nuanced?commentId=LxbpnsnaqWD3xEwZc",
    "author": "Kyoung-cheol Kim",
    "title": "Reflection of Hierarchical Relationship via Nuanced Conditioning of Game Theory Approach for AI Development and Utilization - LessWrong",
    "published_date": "2023-02-07",
    "summary": "This article explores applying game theory to AI development within organizational structures, highlighting the limitations of a purely game-theoretic approach and advocating for a model that integrates the principles of bureaucracy—hierarchical authority and specialization—to leverage both human and AI capabilities for efficient goal achievement in complex systems."
  },
  {
    "url": "https://www.alignmentforum.org/tag/organization-updates",
    "author": "Jesse Hoogland, Daniel Murfet, Stan van Wingerden, Alexander Gietelink Oldenziel",
    "title": "Organization Updates - AI Alignment Forum",
    "published_date": "2023-05-30",
    "summary": "Organization updates pertain to announcements, changes, or news relevant to a particular group or organization. These updates might include information on events, policies, or other pertinent details."
  },
  {
    "url": "https://www.lesswrong.com/posts/AKBkDNeFLZxaMqjQG/a-practical-incremental-pathway-to-safe-tai-oaa-in-the-real",
    "author": "Roman Leventov, Rafael Kaufmann Nedal",
    "title": "Gaia Network: a practical, incremental pathway to Open Agency Architecture",
    "published_date": "2023-12-20",
    "summary": "The article proposes Gaia, a decentralized network leveraging existing technologies and economic mechanisms to create a detailed world simulation, aligning advanced AI with human values by fostering a collaborative, competitive ecosystem of causal models and data. This approach aims to achieve the goals of the Open Agency Architecture (OAA) through incremental improvement and widespread adoption, rather than a top-down, centralized solution."
  },
  {
    "url": "https://www.lesswrong.com/posts/pHJtLHcWvfGbsW7LR/roadmap-for-a-collaborative-prototype-of-an-open-agency",
    "author": "Deger Turan",
    "title": "Roadmap for a collaborative prototype of an Open Agency Architecture",
    "published_date": "2023-05-10",
    "summary": "The AI Objectives Institute proposes the Open Agency Architecture (OAA), a framework for AI alignment aiming to integrate human values into AI decision-making through a world model and iterative development of domain-specific applications. This approach addresses AI alignment challenges by connecting them to broader governance issues and fostering international collaboration."
  }
]
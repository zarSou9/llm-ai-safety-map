[
  {
    "url": "https://arxiv.org/abs/2410.23267",
    "title": "Commit: Online Groups with Participation Commitments",
    "published_date": "2024-10-30",
    "abstract": "\n In spite of efforts to increase participation, many online groups struggle to survive past the initial days, as members leave and activity atrophies. We argue that a main assumption of online group design---that groups ask nothing of their members beyond lurking---may be preventing many of these groups from sustaining a critical mass of participation. In this paper, we explore an alternative\n commitment\n design for online groups, which requires that all members commit at regular intervals to participating, as a condition of remaining in the group. We instantiate this approach in a mobile group chat platform called Commit, and perform a field study comparing commitment against a control condition of social psychological nudges with N=57 participants over three weeks. Commitment doubled the number of contributions versus the control condition, and resulted in 87% (vs. 19%) of participants remaining active by the third week. Participants reported that commitment provided safe cover for them to post even when they were nervous. Through this work, we argue that more effortful, not less effortful, membership may support many online groups.\n",
    "summary": "The Commit platform, requiring regular participation commitments from members, significantly increased online group activity and retention compared to a control group using social nudges, suggesting that demanding member effort can improve online group sustainability. This contrasts with the typical assumption that minimal effort from members suffices."
  },
  {
    "url": "https://arxiv.org/abs/2409.03793",
    "title": "Safeguarding AI Agents: Developing and Analyzing Safety Architectures",
    "published_date": "2024-09-03",
    "abstract": "AI agents, specifically powered by large language models, have demonstrated exceptional capabilities in various applications where precision and efficacy are necessary. However, these agents come with inherent risks, including the potential for unsafe or biased actions, vulnerability to adversarial attacks, lack of transparency, and tendency to generate hallucinations. As AI agents become more prevalent in critical sectors of the industry, the implementation of effective safety protocols becomes increasingly important. This paper addresses the critical need for safety measures in AI systems, especially ones that collaborate with human teams. We propose and evaluate three frameworks to enhance safety protocols in AI agent systems: an LLM-powered input-output filter, a safety agent integrated within the system, and a hierarchical delegation-based system with embedded safety checks. Our methodology involves implementing these frameworks and testing them against a set of unsafe agentic use cases, providing a comprehensive evaluation of their effectiveness in mitigating risks associated with AI agent deployment. We conclude that these frameworks can significantly strengthen the safety and security of AI agent systems, minimizing potential harmful actions or outputs. Our work contributes to the ongoing effort to create safe and reliable AI applications, particularly in automated operations, and provides a foundation for developing robust guardrails to ensure the responsible use of AI agents in real-world applications.",
    "summary": "This paper proposes and evaluates three safety architectures—an input-output filter, a safety agent, and a hierarchical delegation system—designed to mitigate risks associated with unsafe actions in AI agents, particularly large language models. The authors demonstrate the effectiveness of these frameworks through testing against various unsafe use cases."
  },
  {
    "url": "https://arxiv.org/abs/2311.10586",
    "title": "Game Manipulators - the Strategic Implications of Binding Contracts",
    "published_date": "2023-11-17",
    "abstract": "Commitment devices are powerful tools that can influence and incentivise certain behaviours by linking them to rewards or punishments. These devices are particularly useful in decision-making, as they can steer individuals towards specific choices. In the field of game theory, commitment devices can alter a player's payoff matrix, ultimately changing the game's Nash equilibria. Interestingly, agents, whom we term game manipulators and who can be external to the original game, can leverage such devices to extract fees from players by making them contingent offers that modify the payoffs of their actions. This can result in a different Nash equilibrium with potentially lower payoffs for the players compared to the original game. For this scheme to work, it is required that all commitments be binding, meaning that once an offer is made, it cannot be revoked. Consequently, we analyse binding contracts as the commitment mechanism that enables game manipulation scenarios. The main focus of this study is to formulate the logic of this setting, expand its scope to encompass more intricate schemes, and analyse the behaviour of regret-minimizing agents in scenarios involving game manipulation.",
    "citation_count": 4,
    "summary": "This paper analyzes how external agents, termed \"game manipulators,\" can use binding contracts as commitment devices to alter the payoff matrices of games, thereby influencing players' choices and potentially extracting fees, resulting in less favorable Nash equilibria. The study focuses on the logic of this manipulation and the behavior of regret-minimizing players within these altered game scenarios."
  },
  {
    "url": "https://www.lesswrong.com/posts/rmwAuWXYTo24E5nnX/a-pin-and-a-balloon-anthropic-fragility-increases-chances-of",
    "author": "avturchin",
    "title": "A Pin and a Balloon: Anthropic Fragility Increases Chances of Runaway Global Warming",
    "published_date": "2022-09-11",
    "summary": "Due to survival bias, we may underestimate the proximity of climate tipping points, making Earth more vulnerable to even small human actions; this increases the probability of human extinction via runaway global warming."
  },
  {
    "url": "https://arxiv.org/pdf/2110.13307.pdf",
    "title": "Institutional incentives for the evolution of committed cooperation: ensuring participation is as important as enhancing compliance",
    "published_date": "2021-10-25",
    "abstract": "Both conventional wisdom and empirical evidence suggest that arranging a prior commitment or agreement before an interaction takes place enhances the chance of reaching mutual cooperation. Yet it is not clear what mechanisms might underlie the participation in and compliance with such a commitment, especially when participation is costly and non-compliance can be profitable. Here, we develop a theory of participation and compliance with respect to an explicit commitment formation process and to institutional incentives where individuals, at first, decide whether or not to join a cooperative agreement to play a one-shot social dilemma game. Using a mathematical model, we determine whether and when participating in a costly commitment, and complying with it, is an evolutionarily stable strategy, resulting in high levels of cooperation. We show that, given a sufficient budget for providing incentives, rewarding of commitment compliant behaviours better promotes cooperation than punishment of non-compliant ones. Moreover, by sparing part of this budget for rewarding those willing to participate in a commitment, the overall level of cooperation can be significantly enhanced for both reward and punishment. Finally, the presence of mistakes in deciding to participate favours evolutionary stability of commitment compliance and cooperation.",
    "citation_count": 42,
    "summary": "This paper models the evolution of cooperation in social dilemmas, finding that institutional incentives, particularly rewarding participation and compliance with prior commitments, are crucial for achieving high cooperation levels; rewarding compliance is more effective than punishing non-compliance, and rewarding participation further enhances cooperation."
  },
  {
    "url": "https://arxiv.org/pdf/2110.06876v1.pdf",
    "title": "Appointments: A More Effective Commitment Device for Health Behaviors",
    "published_date": "2021-10-09",
    "abstract": "Health behaviors are plagued by self-control problems, and commitment devices are frequently proposed as a solution. We show that a simple alternative works even better: appointments. We randomly offer HIV testing appointments and financial commitment devices to high-risk men in Malawi. Appointments are much more effective than financial commitment devices, more than doubling testing rates. In contrast, most men who take up financial commitment devices lose their investments. Appointments address procrastination without the potential drawback of commitment failure, and also address limited memory problems. Appointments have the potential to increase demand for healthcare in the developing world.",
    "citation_count": 4,
    "summary": "A randomized controlled trial in Malawi found that scheduled appointments significantly increased HIV testing rates among high-risk men, outperforming financial commitment devices due to higher adherence and fewer commitment failures. Appointments offer a simple, effective solution to improve healthcare engagement by addressing procrastination and memory limitations."
  },
  {
    "url": "https://www.lesswrong.com/posts/Tx6dGzYLtfzzkuGtF/the-vulnerable-world-hypothesis-by-bostrom",
    "author": "Ben Pace",
    "title": "The Vulnerable World Hypothesis (by Bostrom)",
    "published_date": "2018-11-06",
    "summary": "Nick Bostrom's \"Vulnerable World Hypothesis\" posits that continued technological advancement significantly increases the likelihood of civilizational collapse unless global governance substantially improves. This risk stems from various technological vulnerabilities, categorized by the ease of causing destruction and the incentives driving harmful actions."
  },
  {
    "url": "https://www.lesswrong.com/posts/X5RyaEDHNq5qutSHK/anti-social-punishment",
    "author": "Martin Sustrik",
    "title": "Anti-social Punishment",
    "published_date": "2018-09-27",
    "summary": "A study using a public goods game with and without punishment mechanisms compared cooperation levels across diverse societies. The results, based on experiments with university students, aimed to determine if societal differences impacted cooperation and punishment behaviors."
  }
]
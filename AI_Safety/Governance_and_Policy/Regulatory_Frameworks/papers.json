[
  {
    "url": "https://arxiv.org/pdf/2307.12218.pdf",
    "title": "A Comprehensive Review and Systematic Analysis of Artificial Intelligence Regulation Policies",
    "published_date": "2023-07-23",
    "abstract": "Due to the cultural and governance differences of countries around the world, there currently exists a wide spectrum of AI regulation policy proposals that have created a chaos in the global AI regulatory space. Properly regulating AI technologies is extremely challenging, as it requires a delicate balance between legal restrictions and technological developments. In this article, we first present a comprehensive review of AI regulation proposals from different geographical locations and cultural backgrounds. Then, drawing from historical lessons, we develop a framework to facilitate a thorough analysis of AI regulation proposals. Finally, we perform a systematic analysis of these AI regulation proposals to understand how each proposal may fail. This study, containing historical lessons and analysis methods, aims to help governing bodies untangling the AI regulatory chaos through a divide-and-conquer manner.",
    "citation_count": 5,
    "summary": "This paper reviews global AI regulation proposals, highlighting the diverse approaches stemming from varying cultural and governance contexts, and offers a framework for analyzing their potential shortcomings to guide policymakers toward more effective regulation."
  },
  {
    "url": "https://arxiv.org/pdf/2303.11196.pdf",
    "title": "Bridging the Global Divide in AI Regulation: A Proposal for a Contextual, Coherent, and Commensurable Framework",
    "published_date": "2023-03-20",
    "abstract": "As debates on potential societal harm from artificial intelligence (AI) culminate in legislation and international norms, a global divide is emerging in both AI regulatory frameworks and international governance structures. In terms of local regulatory frameworks, the European Union (E.U.), Canada, and Brazil follow a horizontal or lateral approach that postulates the homogeneity of AI, seeks to identify common causes of harm, and demands uniform human interventions. In contrast, the United States (U.S.), the United Kingdom (U.K.), Israel, and Switzerland (and potentially China) have pursued a context-specific or modular approach, tailoring regulations to the specific use cases of AI systems. This paper argues for a context-specific approach to effectively address evolving risks in diverse mission-critical domains, while avoiding social costs associated with one-size-fits-all approaches. However, to enhance the systematicity and interoperability of international norms and accelerate global harmonization, this paper proposes an alternative contextual, coherent, and commensurable (3C) framework. To ensure contextuality, the framework (i) bifurcates the AI life cycle into two phases: learning and deployment for specific tasks, instead of defining foundation or general-purpose models; and (ii) categorizes these tasks based on their application and interaction with humans as follows: autonomous, discriminative (allocative, punitive, and cognitive), and generative AI. To ensure coherency, each category is assigned specific regulatory objectives replacing 2010s vintage AI ethics. To ensure commensurability, the framework promotes the adoption of international standards for measuring and mitigating risks.",
    "citation_count": 2,
    "summary": "The paper argues against a globally uniform approach to AI regulation, advocating instead for a context-specific framework that tailors regulations to AI's diverse applications. This framework, termed 3C (contextual, coherent, and commensurable), proposes categorizing AI tasks and establishing corresponding regulatory objectives and risk measurement standards for improved international harmonization."
  },
  {
    "url": "https://arxiv.org/pdf/2209.05468.pdf",
    "title": "Tackling problems, harvesting benefits - A systematic review of the regulatory debate around AI",
    "published_date": "2022-09-07",
    "abstract": "How to integrate an emerging and all-pervasive technology such as AI into the structures and operations of our society is a question of contemporary politics, science and public debate. It has produced a considerable amount of international academic literature from different disciplines. This article analyzes the academic debate around the regulation of artificial intelligence (AI). The systematic review comprises a sample of 73 peer-reviewed journal articles published between January 1st, 2016, and December 31st, 2020. The analysis concentrates on societal risks and harms, questions of regulatory responsibility, and possible adequate policy frameworks, including risk-based and princi-ple-based approaches. The main interests are proposed regulatory approaches and instruments. Various forms of interventions such as bans, approvals, standard-setting, and disclosure are presented. The assessments of the included papers indicate the complexity of the field, which shows its prematurity and the remaining lack of clarity. By pre-senting a structured analysis of the academic debate, we contribute both empirically and conceptually to a better understanding of the nexus of AI and regulation and the underlying normative decisions. A comparison of the scientific proposals with the proposed European AI regulation illustrates the specific approach of the regulation, its strengths and weaknesses.",
    "citation_count": 3,
    "summary": "This systematic review analyzes 73 academic articles (2016-2020) on AI regulation, focusing on identified societal risks, regulatory approaches (including bans, approvals, and standards), and the strengths and weaknesses of proposed frameworks like the European AI regulation. The review highlights the complexity and immaturity of the field, revealing a lack of clarity regarding optimal regulatory strategies."
  },
  {
    "url": "https://arxiv.org/abs/2406.08695",
    "title": "Global AI Governance in Healthcare: A Cross-Jurisdictional Regulatory Analysis",
    "published_date": "2024-06-12",
    "abstract": "Artificial Intelligence (AI) is being adopted across the world and promises a new revolution in healthcare. While AI-enabled medical devices in North America dominate 42.3% of the global market, the use of AI-enabled medical devices in other countries is still a story waiting to be unfolded. We aim to delve deeper into global regulatory approaches towards AI use in healthcare, with a focus on how common themes are emerging globally. We compare these themes to the World Health Organization's (WHO) regulatory considerations and principles on ethical use of AI for healthcare applications. Our work seeks to take a global perspective on AI policy by analyzing 14 legal jurisdictions including countries representative of various regions in the world (North America, South America, South East Asia, Middle East, Africa, Australia, and the Asia-Pacific). Our eventual goal is to foster a global conversation on the ethical use of AI in healthcare and the regulations that will guide it. We propose solutions to promote international harmonization of AI regulations and examine the requirements for regulating generative AI, using China and Singapore as examples of countries with well-developed policies in this area.",
    "citation_count": 1,
    "summary": "This paper analyzes global regulatory approaches to AI in healthcare across 14 jurisdictions, comparing them to WHO guidelines to identify common themes and propose solutions for international harmonization, with a focus on generative AI regulation."
  },
  {
    "url": "https://www.lesswrong.com/posts/ECnLBSxw4TvpWPnae/ai-model-registries-a-regulatory-review",
    "author": "Deric Cheng, Elliot_Mckernon",
    "title": "AI Model Registries: A Regulatory Review",
    "published_date": "2024-03-22",
    "summary": "This article, part of a series reviewing the 2024 AI regulatory landscape, examines AI model registries—centralized databases tracking AI systems for governance purposes. These registries, drawing parallels to pharmaceutical regulations, vary widely in implementation across countries like the US and China, mandating varying levels of model information and pre-release safety assessments."
  },
  {
    "url": "https://www.lesswrong.com/posts/gZBgmDFqqyw3Lghok/ai-regulatory-landscape-review-incident-reporting",
    "author": "Deric Cheng, Elliot_Mckernon",
    "title": "AI Incident Reporting: A Regulatory Review",
    "published_date": "2024-03-11",
    "summary": "This article begins a series analyzing the evolving global AI regulatory landscape, focusing on the US, EU, and China. The first installment examines AI incident reporting, exploring its rationale, existing examples from other sectors (aviation, workplace safety), and nascent efforts to implement similar systems for AI."
  },
  {
    "url": "https://arxiv.org/abs/2307.03718",
    "title": "Frontier AI Regulation: Managing Emerging Risks to Public Safety",
    "published_date": "2023-07-06",
    "abstract": "Advanced AI models hold the promise of tremendous benefits for humanity, but society needs to proactively manage the accompanying risks. In this paper, we focus on what we term\"frontier AI\"models: highly capable foundation models that could possess dangerous capabilities sufficient to pose severe risks to public safety. Frontier AI models pose a distinct regulatory challenge: dangerous capabilities can arise unexpectedly; it is difficult to robustly prevent a deployed model from being misused; and, it is difficult to stop a model's capabilities from proliferating broadly. To address these challenges, at least three building blocks for the regulation of frontier models are needed: (1) standard-setting processes to identify appropriate requirements for frontier AI developers, (2) registration and reporting requirements to provide regulators with visibility into frontier AI development processes, and (3) mechanisms to ensure compliance with safety standards for the development and deployment of frontier AI models. Industry self-regulation is an important first step. However, wider societal discussions and government intervention will be needed to create standards and to ensure compliance with them. We consider several options to this end, including granting enforcement powers to supervisory authorities and licensure regimes for frontier AI models. Finally, we propose an initial set of safety standards. These include conducting pre-deployment risk assessments; external scrutiny of model behavior; using risk assessments to inform deployment decisions; and monitoring and responding to new information about model capabilities and uses post-deployment. We hope this discussion contributes to the broader conversation on how to balance public safety risks and innovation benefits from advances at the frontier of AI development.",
    "citation_count": 91,
    "summary": "This paper argues that the unique safety risks posed by highly capable \"frontier\" AI models necessitate proactive regulation, proposing a three-pronged approach: standardization, registration/reporting, and compliance mechanisms, alongside potential government intervention including licensing and enforcement powers."
  },
  {
    "url": "https://arxiv.org/pdf/2105.06267v1.pdf",
    "title": "A Pragmatic Approach to Regulating Artificial Intelligence: A Technology Regulator's Perspective",
    "published_date": "2021-04-15",
    "abstract": "Artificial Intelligence (AI) and the regulation thereof is a topic that is increasingly being discussed within various fora. Various proposals have been made in literature for defining regulatory bodies and/or related regulation. In this paper, we present a pragmatic approach for providing a technology assurance regulatory framework. To the best knowledge of the authors this work presents the first national AI technology assurance legal and regulatory framework that has been implemented by a national authority empowered through law to do so. In aim of both providing assurances where required and not stifling innovation yet supporting it, herein it is proposed that such regulation should not be mandated for all AI-based systems and that rather it should primarily provide a voluntary framework and only be mandated in sectors and activities where required and as deemed necessary by other authorities for regulated and critical areas.",
    "citation_count": 3,
    "summary": "This paper proposes a pragmatic, voluntary AI regulatory framework implemented by a national authority, mandating regulation only in critical sectors to balance assurance and innovation. This framework represents the first nationally implemented AI technology assurance legal and regulatory structure."
  },
  {
    "title": "Regulating artificial intelligence: a technology regulator's perspective",
    "abstract": "Artificial Intelligence (AI) and the regulation thereof is a topic that is increasingly being discussed and various proposals have been made in literature for defining regulatory bodies and/or related regulation. In this paper, we present a pragmatic approach for providing a technology assurance regulatory framework. To the best of our knowledge, this work presents the first national AI technology assurance legal and regulatory framework that has been implemented by a national authority empowered through law to do so. Aiming to both provide assurances where required and not stifling innovation yet supporting it, it is proposed that such regulation is not to be mandated for all AI-based systems but rather should provide a voluntary framework and only be mandated in sectors and activities as deemed necessary by other authorities or laws for regulated and critical areas.",
    "published_date": "2021-06-21",
    "citation_count": 15,
    "url": "https://dl.acm.org/doi/10.1145/3462757.3466093",
    "summary": "This paper details a novel, nationally implemented AI regulatory framework focusing on technology assurance, prioritizing a voluntary approach except where mandated by other laws for high-risk sectors. It proposes a balance between ensuring safety and fostering innovation."
  },
  {
    "title": "From a 'race to AI' to a 'race to AI regulation': regulatory competition for artificial intelligence",
    "abstract": "ABSTRACT Against a background of global competition to seize the opportunities promised by Artificial Intelligence (AI), many countries and regions are explicitly taking part in a 'race to AI'. Yet the increased visibility of the technology's risks has led to ever-louder calls for regulators to look beyond the benefits, and also secure appropriate regulation to ensure AI that is 'trustworthy' – i.e. legal, ethical and robust. Besides minimising risks, such regulation could facilitate AI's uptake, boost legal certainty, and hence also contribute to advancing countries' position in the race. Consequently, this paper argues that the 'race to AI' also brings forth a 'race to AI regulation'. After discussing the regulatory toolbox for AI and some of the challenges that regulators face when making use thereof, this paper assesses to which extent regulatory competition for AI – or its counterpart, regulatory convergence – is a possibility, a reality and a desirability.",
    "published_date": "2021-01-02",
    "citation_count": 97,
    "url": "https://www.tandfonline.com/eprint/HM4GYBXS7T3PPPGIENJC/full?target=10.1080%2F17579961.2021.1898300&",
    "summary": "The global \"race to AI\" is accompanied by a concurrent \"race to AI regulation,\" driven by the need to mitigate risks and foster trust in the technology while simultaneously gaining a competitive advantage. This paper analyzes the feasibility, current state, and desirability of regulatory competition versus convergence in the AI domain."
  },
  {
    "url": "https://arxiv.org/abs/2410.21279",
    "title": "Comparative Global AI Regulation: Policy Perspectives from the EU, China, and the US",
    "published_date": "2024-10-05",
    "abstract": "As a powerful and rapidly advancing dual-use technology, AI offers both immense benefits and worrisome risks. In response, governing bodies around the world are developing a range of regulatory AI laws and policies. This paper compares three distinct approaches taken by the EU, China and the US. Within the US, we explore AI regulation at both the federal and state level, with a focus on California's pending Senate Bill 1047. Each regulatory system reflects distinct cultural, political and economic perspectives. Each also highlights differing regional perspectives on regulatory risk-benefit tradeoffs, with divergent judgments on the balance between safety versus innovation and cooperation versus competition. Finally, differences between regulatory frameworks reflect contrastive stances in regards to trust in centralized authority versus trust in a more decentralized free market of self-interested stakeholders. Taken together, these varied approaches to AI innovation and regulation influence each other, the broader international community, and the future of AI regulation.",
    "summary": "This paper compares the EU, China, and US approaches to AI regulation, highlighting their distinct cultural, political, and economic influences on risk-benefit assessments, balancing safety with innovation, and contrasting centralized versus decentralized regulatory models. These differing approaches significantly impact international AI regulation and its future development."
  },
  {
    "url": "https://arxiv.org/abs/2407.21717",
    "title": "Assessing the State of AI Policy",
    "published_date": "2024-07-31",
    "abstract": "The deployment of artificial intelligence (AI) applications has accelerated rapidly. AI enabled technologies are facing the public in many ways including infrastructure, consumer products and home applications. Because many of these technologies present risks either in the form of physical injury, or bias, potentially yielding unfair outcomes, policy makers must consider the need for oversight. Most policymakers, however, lack the technical knowledge to judge whether an emerging AI technology is safe, effective, and requires oversight, therefore policy makers must depend on expert opinion. But policymakers are better served when, in addition to expert opinion, they have some general understanding of existing guidelines and regulations. This work provides an overview [the landscape] of AI legislation and directives at the international, U.S. state, city and federal levels. It also reviews relevant business standards, and technical society initiatives. Then an overlap and gap analysis are performed resulting in a reference guide that includes recommendations and guidance for future policy making.",
    "summary": "This paper analyzes the current landscape of AI policy at various governmental and organizational levels, identifying gaps and overlaps to offer recommendations for future policymaking informed by existing guidelines, regulations, and expert opinion. The goal is to aid policymakers lacking technical expertise in evaluating AI safety and efficacy."
  },
  {
    "url": "https://arxiv.org/abs/2410.02769",
    "title": "Fundamentals of legislation for autonomous artificial intelligence systems",
    "published_date": "2024-09-14",
    "abstract": "The paper proposes a method for defining a dedicated operational context as part of the development and deployment of autonomous corporate governance systems. The case study of autonomous board of directors systems is examined. A significant part of the operational context for the autonomous corporate governance systems consists of the regulatory and legal framework that regulates the company's operations. A special operational context for autonomous artificial intelligence systems can be defined by simultaneously formulating local regulatory documents in two versions, i.e., to be used by people and by autonomous systems. In such a case, the artificial intelligence system receives a clearly defined operational context that allows such a system to perform its functions with a required operational quality. Local regulations that take into account the specificity of operations involving individuals and autonomous artificial intelligence systems can become the foundation of the relevant legislation that would regulate the development and deployment of autonomous systems.",
    "summary": "This paper suggests creating parallel legal frameworks—one for humans and one for AI—within a company's operational context to effectively govern autonomous systems, using autonomous corporate boards as a case study. This dual approach aims to provide clear operational guidelines for AI and form the basis for broader legislation on autonomous systems."
  },
  {
    "url": "https://www.lesswrong.com/posts/5bd2ChzKKr2Ph5fnL/what-is-compute-governance",
    "author": "Vishakha",
    "title": "What is compute governance?",
    "published_date": "2024-12-23",
    "summary": "Compute governance, focusing on controlling access to AI development hardware, is a promising but underdeveloped approach to AI safety. Strategies include increasing visibility of AI development, allocating compute resources strategically, and enforcing regulations through technological means, though many proposed methods remain speculative."
  },
  {
    "url": "https://www.lesswrong.com/posts/vzGC4zh73dfcqnFgf/open-source-ai-a-regulatory-review",
    "author": "Elliot_Mckernon, Deric Cheng",
    "title": "Open-Source AI: A Regulatory Review",
    "published_date": "2024-04-29",
    "summary": "This article examines the implications of open-sourcing AI models, specifically focusing on the trade-offs between promoting collaboration and potentially increasing risks from malicious use of powerful, easily accessible models lacking built-in safety safeguards. The authors highlight the varying levels of openness (e.g., open weights vs. full open-source) and their impact on safety and analysis."
  }
]
[
  {
    "url": "https://arxiv.org/abs/2402.08143",
    "title": "Artificial intelligence and the transformation of higher education institutions",
    "published_date": "2024-02-13",
    "abstract": "Artificial intelligence (AI) advances and the rapid adoption of generative AI tools, like ChatGPT, present new opportunities and challenges for higher education. While substantial literature discusses AI in higher education, there is a lack of a systems approach that captures a holistic view of the structure and dynamics of the AI transformation of higher education institutions (HEIs). To fill this gap, this article develops a causal loop diagram (CLD) to map the causal feedback mechanisms of AI transformation in a typical HEI. We identify important variables and their relationships and map multiple reinforcing and balancing feedback loops accounting for the forces that drive the AI transformation and its impact on value creation in a typical HEI. The model shows how, motivated by AI technology advances, the HEI can invest in AI to improve student learning, research, and administration while dealing with academic integrity problems and adapting to job market changes by emphasizing AI-complementary student skills. We explore model insights, scenarios, and policy interventions and recommend that HEI leaders become systems thinkers to manage the complexity of the AI transformation and benefit from the AI feedback loops while avoiding policy traps that may lead to decline. We also discuss the notion of HEIs influencing the direction of AI and directions for future research on AI transformation and the sustainability of HEIs.",
    "citation_count": 3,
    "summary": "This paper uses a causal loop diagram to model the multifaceted impact of AI on higher education institutions, highlighting both the opportunities for improved learning, research, and administration, and the challenges related to academic integrity and workforce adaptation. The authors emphasize the need for systems thinking in HEI leadership to navigate this complex transformation effectively."
  },
  {
    "url": "https://arxiv.org/abs/2405.11800",
    "title": "Generative AI in Higher Education: A Global Perspective of Institutional Adoption Policies and Guidelines",
    "published_date": "2024-05-20",
    "abstract": "Integrating generative AI (GAI) into higher education is crucial for preparing a future generation of GAI-literate students. Yet a thorough understanding of the global institutional adoption policy remains absent, with most of the prior studies focused on the Global North and the promises and challenges of GAI, lacking a theoretical lens. This study utilizes the Diffusion of Innovations Theory to examine GAI adoption strategies in higher education across 40 universities from six global regions. It explores the characteristics of GAI innovation, including compatibility, trialability, and observability, and analyses the communication channels and roles and responsibilities outlined in university policies and guidelines. The findings reveal a proactive approach by universities towards GAI integration, emphasizing academic integrity, teaching and learning enhancement, and equity. Despite a cautious yet optimistic stance, a comprehensive policy framework is needed to evaluate the impacts of GAI integration and establish effective communication strategies that foster broader stakeholder engagement. The study highlights the importance of clear roles and responsibilities among faculty, students, and administrators for successful GAI integration, supporting a collaborative model for navigating the complexities of GAI in education. This study contributes insights for policymakers in crafting detailed strategies for its integration.",
    "citation_count": 7,
    "summary": "This study analyzes generative AI adoption policies across 40 global universities, revealing a proactive but cautious approach focused on academic integrity and equitable learning enhancement; it advocates for comprehensive policy frameworks and clear stakeholder roles to effectively integrate generative AI in higher education."
  },
  {
    "url": "https://arxiv.org/abs/2407.20130",
    "title": "To accept or not to accept? An IRT-TOE Framework to Understand Educators' Resistance to Generative AI in Higher Education",
    "published_date": "2024-07-29",
    "abstract": "Since the public release of Chat Generative Pre-Trained Transformer (ChatGPT), extensive discourse has emerged concerning the potential advantages and challenges of integrating Generative Artificial Intelligence (GenAI) into education. In the realm of information systems, research on technology adoption is crucial for understanding the diverse factors influencing the uptake of specific technologies. Theoretical frameworks, refined and validated over decades, serve as guiding tools to elucidate the individual and organizational dynamics, obstacles, and perceptions surrounding technology adoption. However, while several models have been proposed, they often prioritize elucidating the factors that facilitate acceptance over those that impede it, typically focusing on the student perspective and leaving a gap in empirical evidence regarding educators viewpoints. Given the pivotal role educators play in higher education, this study aims to develop a theoretical model to empirically predict the barriers preventing educators from adopting GenAI in their classrooms. Acknowledging the lack of theoretical models tailored to identifying such barriers, our approach is grounded in the Innovation Resistance Theory (IRT) framework and augmented with constructs from the Technology-Organization-Environment (TOE) framework. This model is transformed into a measurement instrument employing a quantitative approach, complemented by a qualitative approach to enrich the analysis and uncover concerns related to GenAI adoption in the higher education domain.",
    "summary": "This study uses a combined Innovation Resistance Theory and Technology-Organization-Environment framework to develop and empirically test a model predicting educator resistance to generative AI adoption in higher education, addressing the gap in research focusing on educators' perspectives. The quantitative model is enhanced with qualitative data to understand the barriers to GenAI integration in classrooms."
  },
  {
    "url": "https://arxiv.org/abs/2410.05827",
    "title": "Towards an Operational Responsible AI Framework for Learning Analytics in Higher Education",
    "published_date": "2024-10-08",
    "abstract": "Universities are increasingly adopting data-driven strategies to enhance student success, with AI applications like Learning Analytics (LA) and Predictive Learning Analytics (PLA) playing a key role in identifying at-risk students, personalising learning, supporting teachers, and guiding educational decision-making. However, concerns are rising about potential harms these systems may pose, such as algorithmic biases leading to unequal support for minority students. While many have explored the need for Responsible AI in LA, existing works often lack practical guidance for how institutions can operationalise these principles. In this paper, we propose a novel Responsible AI framework tailored specifically to LA in Higher Education (HE). We started by mapping 11 established Responsible AI frameworks, including those by leading tech companies, to the context of LA in HE. This led to the identification of seven key principles such as transparency, fairness, and accountability. We then conducted a systematic review of the literature to understand how these principles have been applied in practice. Drawing from these findings, we present a novel framework that offers practical guidance to HE institutions and is designed to evolve with community input, ensuring its relevance as LA systems continue to develop.",
    "summary": "This paper presents a novel Responsible AI framework for Learning Analytics in higher education, derived from a mapping of existing frameworks and a literature review, offering practical guidance to institutions on operationalizing ethical AI principles like fairness and transparency. The framework is designed to be adaptable and evolve with community feedback."
  },
  {
    "url": "https://arxiv.org/abs/2412.14469",
    "title": "Who is Helping Whom? Student Concerns about AI- Teacher Collaboration in Higher Education Classrooms",
    "published_date": "2024-12-19",
    "abstract": "AI's integration into education promises to equip teachers with data-driven insights and intervene in student learning. Despite the intended advancements, there is a lack of understanding of interactions and emerging dynamics in classrooms where various stakeholders including teachers, students, and AI, collaborate. This paper aims to understand how students perceive the implications of AI in Education in terms of classroom collaborative dynamics, especially AI used to observe students and notify teachers to provide targeted help. Using the story completion method, we analyzed narratives from 65 participants, highlighting three challenges: AI decontextualizing of the educational context; AI-teacher cooperation with bias concerns and power disparities; and AI's impact on student behavior that further challenges AI's effectiveness. We argue that for effective and ethical AI-facilitated cooperative education, future AIEd design must factor in the situated nature of implementation. Designers must consider the broader nuances of the education context, impacts on multiple stakeholders, dynamics involving these stakeholders, and the interplay among potential consequences for AI systems and stakeholders. It is crucial to understand the values in the situated context, the capacity and limitations of both AI and humans for effective cooperation, and any implications to the relevant ecosystem.",
    "summary": "This study uses student narratives to explore concerns about AI-teacher collaboration in higher education, revealing challenges related to AI's decontextualized interventions, biased AI-teacher cooperation, and AI's impact on student behavior. The authors advocate for future AI in education designs that consider contextual nuances, stakeholder dynamics, and potential ethical implications."
  },
  {
    "url": "https://www.alignmentforum.org/posts/cLfsabkCPtieJ5LoK/investigating-bias-representations-in-llms-via-activation",
    "author": "DawnLu",
    "title": "Investigating Bias Representations in LLMs via Activation Steering",
    "published_date": "2024-01-15",
    "summary": "This research uses activation steering to assess the societal biases of the Llama-2-7b-chat LLM, finding that while the model exhibits gender bias in unsteered responses, attempts to further amplify bias through activation steering resulted in the model refusing to answer, suggesting a potential, albeit unexpected, form of robustness."
  },
  {
    "url": "https://www.lesswrong.com/posts/37uuuPQKiGisi8cGG/language-and-capabilities-testing-llm-mathematical-abilities",
    "author": "Ethan Edwards",
    "title": "Language and Capabilities: Testing LLM Mathematical Abilities Across Languages",
    "published_date": "2024-04-04",
    "summary": "This research investigates GPT-4's mathematical abilities across different languages and numeral systems, finding that while performance is best with Arabic numerals, success is heavily dependent on prompt phrasing and unexpected emergent behaviors, suggesting GPT-4 relies on learned token patterns rather than abstract mathematical understanding. Further investigation is needed to fully elucidate GPT-4's internal processes."
  },
  {
    "url": "https://www.alignmentforum.org/posts/iaHk9DMCbrYsKuqgS/simple-distribution-approximation-when-sampled-100-times-can-1",
    "author": "Teun van der Weij, Felix Hofst√§tter, Francis Rhys Ward",
    "title": "Simple distribution approximation: When sampled 100 times, can language models yield 80% A and 20% B?",
    "published_date": "2024-01-29",
    "summary": "The study investigates large language models' ability to control their output distribution to achieve a specified accuracy rate (sandbagging), finding that GPT-4 exhibits better performance than GPT-3.5 in approximating target distributions and achieving controlled underperformance on both distribution approximation and simple arithmetic tasks, though prompt engineering significantly impacts results."
  }
]
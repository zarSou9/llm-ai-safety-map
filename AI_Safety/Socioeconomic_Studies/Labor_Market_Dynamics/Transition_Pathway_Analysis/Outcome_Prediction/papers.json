[
  {
    "url": "https://arxiv.org/abs/2303.15202",
    "title": "Towards Outcome-Driven Patient Subgroups: A Machine Learning Analysis Across Six Depression Treatment Studies",
    "published_date": "2023-03-24",
    "abstract": "BACKGROUND\nMajor depressive disorder (MDD) is a heterogeneous condition; multiple underlying neurobiological and behavioral substrates are associated with treatment response variability. Understanding the sources of this variability and predicting outcomes has been elusive. Machine learning (ML) shows promise in predicting treatment response in MDD, but its application is limited by challenges to the clinical interpretability of ML models, and clinicians often lack confidence in model results. In order to improve the interpretability of ML models in clinical practice, our goal was to demonstrate the derivation of treatment-relevant patient profiles comprised of clinical and demographic information using a novel ML approach.\n\n\nMETHODS\nWe analyzed data from six clinical trials of pharmacological treatment for depression (total n = 5438) using the Differential Prototypes Neural Network (DPNN), a ML model that derives patient prototypes which can be used to derive treatment-relevant patient clusters while learning to generate probabilities for differential treatment response. A model classifying remission and outputting individual remission probabilities for five first-line monotherapies and three combination treatments was trained using clinical and demographic data. Prototypes were evaluated for interpretability by assessing differences in feature distributions (e.g. age, sex, symptom severity) and treatment-specific outcomes.\n\n\nRESULTS\nA 3-prototype model achieved an area under the receiver operating curve of 0.66 and an expected absolute improvement in remission rate for those receiving the best predicted treatment of 6.5% (relative improvement of 15.6%) compared to the population remission rate. We identified three treatment-relevant patient clusters. Cluster A patients tended to be younger, to have increased levels of fatigue, and more severe symptoms. Cluster B patients tended to be older, female, have less severe symptoms, and the highest remission rates. Cluster C patients had more severe symptoms, lower remission rates, more psychomotor agitation, more intense suicidal ideation, and more somatic genital symptoms.\n\n\nCONCLUSION\nIt is possible to produce novel treatment-relevant patient profiles using ML models; doing so may improve interpretability of ML models and the quality of precision medicine treatments for MDD.",
    "citation_count": 6,
    "summary": "Using machine learning on data from six depression treatment studies (n=5438), researchers identified three patient subgroups with distinct clinical characteristics and predicted remission rates, suggesting potential for personalized treatment strategies. A 3-prototype model improved predicted remission rates by 6.5% (15.6% relative improvement) compared to standard treatment."
  },
  {
    "url": "https://arxiv.org/pdf/2309.04470.pdf",
    "title": "On the Actionability of Outcome Prediction",
    "published_date": "2023-09-08",
    "abstract": "Predicting future outcomes is a prevalent application of machine learning in social impact domains. Examples range from predicting student success in education to predicting disease risk in healthcare. Practitioners recognize that the ultimate goal is not just to predict but to act effectively. Increasing evidence suggests that relying on outcome predictions for downstream interventions may not have desired results. \n\nIn most domains there exists a multitude of possible interventions for each individual, making the challenge of taking effective action more acute. Even when causal mechanisms connecting the individual's latent states to outcomes are well understood, in any given instance (a specific student or patient), practitioners still need to infer---from budgeted measurements of latent states---which of many possible interventions will be most effective for this individual. With this in mind, we ask: when are accurate predictors of outcomes helpful for identifying the most suitable intervention?\n\nThrough a simple model encompassing actions, latent states, and measurements, we demonstrate that pure outcome prediction rarely results in the most effective policy for taking actions, even when combined with other measurements. \nWe find that except in cases where there is a single decisive action for improving the outcome, outcome prediction never maximizes \"action value\", the utility of taking actions. Making measurements of actionable latent states, where specific actions lead to desired outcomes, may considerably enhance the action value compared to outcome prediction, and the degree of improvement depends on action costs and the outcome model. This analysis emphasizes the need to go beyond generic outcome prediction in interventional settings by incorporating knowledge of plausible actions and latent states.",
    "citation_count": 6,
    "summary": "The paper argues that relying solely on outcome prediction for effective intervention is often suboptimal, even with accurate predictions. Instead, incorporating knowledge of actionable latent states and their relationships to potential interventions significantly improves the effectiveness of actions taken."
  },
  {
    "url": "https://arxiv.org/pdf/2209.06055.pdf",
    "title": "Exploring the use of Transition Path Theory in building an oil spill prediction scheme",
    "published_date": "2022-09-13",
    "abstract": "The Transition Path Theory (TPT) of complex systems has proven to be a robust means to statistically characterize the ensemble of trajectories that connect any two preset flow regions, say ùíú and ‚Ñ¨, directly. More specifically, transition paths are such that they start in ùíú and then go to ‚Ñ¨ without detouring back to ùíú or ‚Ñ¨. This way, they make an effective contribution to the transport from ùíú to ‚Ñ¨. Here, we explore its use for building a scheme that enables predicting the evolution of an oil spill in the ocean. This involves appropriately adapting TPT such that it includes a reservoir that pumps oil into a typically open domain. Additionally, we lift up the restriction of the oil not to return to the spill site en route to a region that is targeted to be protected. TPT is applied on oil trajectories available up to the present, e.g., as integrated using velocities produced by a data assimilative system or as inferred from high-frequency radars, to make a prediction of transition oil paths beyond, without relying on forecasted oil trajectories. As a proof of concept, we consider a hypothetical oil spill in the Trion oil field, under development within the Perdido Foldbelt in the northwestern Gulf of Mexico, and the Deepwater Horizon oil spill. This is done using trajectories integrated from climatological and hindcast surface velocity and winds as well as produced by satellite-tracked surface drifting buoys, in each case discretized into a Markov chain that provides a framework for the TPT-based prediction.",
    "citation_count": 3,
    "summary": "This paper investigates using Transition Path Theory (TPT) to predict oil spill trajectories, adapting the method to account for continuous oil release and potential revisits to the spill site. The approach leverages past oil trajectory data (from simulations or observations) to predict future paths without requiring forecasts of ocean currents."
  },
  {
    "url": "https://www.lesswrong.com/posts/d9MkMeLWvoDEsqpQP/a-compilation-of-misuses-of-statistics",
    "author": "Younes Kamel",
    "title": "A compilation of misuses of statistics",
    "published_date": "2022-02-14",
    "summary": "The article discusses common statistical errors, primarily focusing on the misuse of Gaussian assumptions in modeling fat-tailed distributions and misinterpretations of p-values, base rates, and statistical power. These errors lead to inaccurate conclusions and unreliable results in various fields, including finance and science."
  },
  {
    "url": "https://arxiv.org/pdf/2101.11182v1.pdf",
    "title": "Transporting a prediction model for use in a new target population.",
    "published_date": "2021-01-27",
    "abstract": "We consider methods for transporting a prediction model for use in a new target population, when outcome and covariate data for model development are available from a source population that has a different covariate distribution compared to the target population, and when covariate data (but not outcome data) are available from the target population. We discuss how to tailor the prediction model to account for differences in the data distribution between the source population and the target population. We also discuss how to assess the model's performance (e.g., by estimating the mean squared prediction error) in the target population. We provide identifiability results for measures of model performance in the target populationfor a potentially misspecified prediction model under a sampling design where the source and the target population samples are obtained separately. We introduce the concept of prediction error modifiers that can be used to reason about tailoring measuresof model performance to the target population. We illustrate the methods in simulated data and apply them to transport a prediction model for lung cancer diagnosis from the National Lung Screening Trial to the nationally representative target population of trial-eligible individuals in the National Health and Nutrition Examination Survey.",
    "citation_count": 15,
    "summary": "This paper addresses methods for adapting a prediction model trained on a source population to a new target population with a different covariate distribution, focusing on techniques for adjusting the model and evaluating its performance in the target population using available target covariate data. The authors provide identifiability results and introduce prediction error modifiers to improve accuracy and reliability of the transported model."
  },
  {
    "url": "https://arxiv.org/pdf/2101.00633.pdf",
    "title": "Outcome-Explorer: A Causality Guided Interactive Visual Interface for Interpretable Algorithmic Decision Making",
    "published_date": "2021-01-03",
    "abstract": "The widespread adoption of algorithmic decision-making systems has brought about the necessity to interpret the reasoning behind these decisions. The majority of these systems are complex black box models, and auxiliary models are often used to approximate and then explain their behavior. However, recent research suggests that such explanations are not overly accessible to lay users with no specific expertise in machine learning and this can lead to an incorrect interpretation of the underlying model. In this article, we show that a predictive and interactive model based on causality is inherently interpretable, does not require any auxiliary model, and allows both expert and non-expert users to understand the model comprehensively. To demonstrate our method we developed Outcome Explorer, a causality guided interactive interface, and evaluated it by conducting think-aloud sessions with three expert users and a user study with 18 non-expert users. All three expert users found our tool to be comprehensive in supporting their explanation needs while the non-expert users were able to understand the inner workings of a model easily.",
    "citation_count": 27,
    "summary": "Outcome-Explorer is an interactive visualization tool that uses causality to make algorithmic decision-making processes understandable to both experts and non-experts, eliminating the need for auxiliary explanatory models. Its effectiveness was demonstrated through expert and user studies showing improved comprehension of model workings."
  },
  {
    "url": "https://www.lesswrong.com/posts/B6WefmeyaST7Puddz/there-is-no-control-system-for-covid",
    "author": "Mike Harris",
    "title": "There Is No Control System For COVID",
    "published_date": "2021-04-06",
    "summary": "The standard epidemiological model poorly predicts COVID-19 infection rates across US states, failing to explain the surprisingly similar infection levels despite varying policies and behaviors. A proposed \"vulnerability model,\" incorporating fluctuating individual susceptibility to infection over time, better accounts for the observed data and resolves inconsistencies of the standard model."
  },
  {
    "url": "https://arxiv.org/abs/2001.07648",
    "title": "When black box algorithms are (not) appropriate",
    "published_date": "2020-01-21",
    "abstract": "Abstract:In the 1980s a new, extraordinarily productive way of reasoning about algorithms emerged. In this paper, we introduce the term ‚Äúoutcome reasoning‚Äù to refer to this form of reasoning. Though outcome reasoning has come to dominate areas of data science, it has been under-discussed and its impact under-appreciated. For example, outcome reasoning is the primary way we reason about whether ‚Äúblack box‚Äù algorithms are performing well. In this paper we analyze outcome reasoning's most common form (i.e., as ‚Äúthe common task framework‚Äù) and its limitations. We discuss why a large class of prediction-problems are inappropriate for outcome reasoning. As an example, we find the common task framework does not provide a foundation for the deployment of an algorithm in a real world situation. Building off of its core features, we identify a class of problems where this new form of reasoning can be used in deployment. We purposefully develop a novel framework so both technical and non-technical people can discuss and identify key features of their prediction problem and whether or not it is suitable for outcome reasoning.",
    "citation_count": 13,
    "summary": "The paper introduces \"outcome reasoning,\" a dominant but under-analyzed approach to evaluating algorithms, particularly \"black box\" models, highlighting its limitations in many prediction problems and offering a new framework to determine its suitability. This framework aids both technical and non-technical users in assessing whether outcome reasoning is appropriate for their specific prediction problem."
  }
]
[
  {
    "url": "https://arxiv.org/abs/2407.20931",
    "title": "Nonparametric Estimation of Matching Efficiency and Mismatch in Labor Markets via Public Employment Security Offices in Japan, 1972-2024",
    "published_date": "2024-07-30",
    "abstract": "I examine changes in matching efficiency and elasticities in Japan's labor market via Hello Work for unemployed workers from January 1972 to April 2024 using a nonparametric identification approach by y Lange and Papageorgiou (2020). I find a declining trend in matching efficiency, consistent with decreasing job and worker finding rates. The implied match elasticity with respect to unemployment is 0.5-0.9, whereas the implied match elasticity with respect to vacancies varies between -0.4 and 0.4. Decomposing aggregate data into full-time and part-time ones, I find that the sharp decline of matching efficiency after 2015 shown in the aggregate trend is driven by the decline of both full-time and part-time ones. Second, I extend the mismatch index proposed by Sahin et al (2014) to the nonparametric version and develop the computational methodology. I find that the mismatch across occupations is more severe than across prefectures and the original Cobb-Douglas mismatch index is underestimated.",
    "citation_count": 1,
    "summary": "Using Japanese Hello Work data (1972-2024), this paper nonparametrically estimates declining labor market matching efficiency, driven by falling job and worker finding rates, with match elasticities varying across unemployment and vacancies. Furthermore, it finds that occupational mismatch is more significant than geographical mismatch, exceeding estimates from a standard Cobb-Douglas approach."
  },
  {
    "url": "https://www.lesswrong.com/posts/hzuSDMx7pd2uxFc5w/causal-diagrams-and-causal-models",
    "author": "Eliezer Yudkowsky",
    "title": "Causal Diagrams and Causal Models",
    "published_date": "2024-02-01",
    "summary": "The article discusses how to infer causality from observational data, challenging the notion that randomized controlled trials are necessary. It uses a hypothetical example to illustrate how analyzing correlations between multiple variables (weight, exercise, internet use) can reveal causal relationships without experimental intervention."
  },
  {
    "url": "https://www.alignmentforum.org/posts/iaHk9DMCbrYsKuqgS/simple-distribution-approximation-when-sampled-100-times-can-1",
    "author": "Teun van der Weij, Felix Hofst√§tter, Francis Rhys Ward",
    "title": "Simple distribution approximation: When sampled 100 times, can language models yield 80% A and 20% B?",
    "published_date": "2024-01-29",
    "summary": "The study investigates Large Language Models' (LLMs) ability to control their output distribution to achieve a specified accuracy rate (sandbagging), finding that GPT-4 exhibits better control than GPT-3.5, though both models struggle with perfectly replicating a target distribution across multiple independent queries, particularly when applied to arithmetic tasks."
  },
  {
    "url": "https://arxiv.org/abs/2307.05843",
    "title": "Responses of Unemployment to Productivity Changes for a General Matching Technology",
    "published_date": "2023-07-11",
    "abstract": "Workers separate from jobs, search for jobs, accept jobs, and fund consumption with their wages. Firms recruit workers to fill vacancies. Search frictions prevent firms from instantly hiring available workers. Unemployment persists. These features are described by the Diamond-Mortensen-Pissarides modeling framework. In this class of models, how unemployment responds to productivity changes depends on resources that can be allocated to job creation. Yet, this characterization has been made when matching is parameterized by a Cobb-Douglas technology. For a canonical DMP model, I (1) demonstrate that a unique steady-state equilibrium will exist as long as the initial vacancy yields a positive surplus; (2) characterize responses of unemployment to productivity changes for a general matching technology; and (3) show how a matching technology that is not Cobb-Douglas implies unemployment responds more to productivity changes, which is independent of resources available for job creation, a feature that will be of interest to business-cycle researchers.",
    "citation_count": 1,
    "summary": "The paper analyzes the Diamond-Mortensen-Pissarides (DMP) model of unemployment with a general matching technology, demonstrating that unemployment's response to productivity shocks is amplified compared to the Cobb-Douglas case, independent of job creation resources."
  },
  {
    "url": "https://arxiv.org/pdf/2307.08368.pdf",
    "title": "Gender mobility in the labor market with skills-based matching models",
    "published_date": "2023-07-17",
    "abstract": "Skills-based matching promises mobility of workers between different sectors and occupations in the labor market. In this case, job seekers can look for jobs they do not yet have experience in, but for which they do have relevant skills. Currently, there are multiple occupations with a skewed gender distribution. For skills-based matching, it is unclear if and how a shift in the gender distribution, which we call gender mobility , between occupations will be effected. It is expected that the skills-based matching approach will likely be data-driven, including computational language models and supervised learning methods. This work, first, shows the presence of gender segregation in language model-based skills representation of occupations. Second, we assess the use of these representations in a potential application based on simulated data, and show that the gender segregation is propagated by various data-driven skills-based matching models. These models are based on different language representations (bag of words, word2vec, and BERT), and distance metrics (static and machine learning-based). Accordingly, we show how skills-based matching approaches can be evaluated and compared on matching performance as well as on the risk of gender segregation . Making the gender segregation bias of models more explicit can help in generating healthy trust in the use of these models in practice.",
    "citation_count": 1,
    "summary": "This paper investigates whether skills-based job matching models, using various language model representations, perpetuate existing gender segregation in the labor market, finding that gender biases in the training data are propagated by these models. The study highlights the need for evaluating such models not only on performance but also on their potential to exacerbate existing gender inequalities."
  },
  {
    "url": "https://www.lesswrong.com/posts/qvWP3aBDBaqXvPNhS/gpt-2-s-positional-embedding-matrix-is-a-helix",
    "author": "AdamYedidia",
    "title": "GPT-2's positional embedding matrix is a helix",
    "published_date": "2023-07-21",
    "summary": "A GPT-2 transformer's positional embedding matrix maps token positions to 768-dimensional vectors, which, despite the high dimensionality, primarily reside within a low-rank subspace forming a helix when visualized via PCA, with the helix representing the sequential order of positions within a prompt. This helical structure is consistent across most GPT-2 models."
  },
  {
    "url": "https://www.lesswrong.com/posts/2JJtxitp6nqu6ffak/basic-facts-about-language-models-during-training-1",
    "author": "beren",
    "title": "Basic facts about language models during training",
    "published_date": "2023-02-21",
    "summary": "This study analyzes the weight, activation, and gradient distributions of the Pythia language models throughout training, revealing a rapid, early phase transition of weight distributions from Gaussian to heavy-tailed distributions, contradicting some theoretical predictions. The findings are based on an analysis of 142 checkpoints from models ranging from 19M to 1.3B parameters."
  },
  {
    "url": "https://www.lesswrong.com/posts/zYv9BQBGnk2EdCwoG/the-psyche-of-ai-pattern-recognition",
    "author": "Scott Broock",
    "title": "AI and the Map of Your Mind: Pattern Recognition",
    "published_date": "2023-03-20",
    "summary": "Integrating large language models into productivity suites allows AI to create personalized knowledge graphs from user data, potentially revolutionizing learning and decision-making by revealing hidden connections and patterns. However, this also raises concerns about granting AI unrestricted access to personal information and its implications for understanding the human psyche."
  }
]
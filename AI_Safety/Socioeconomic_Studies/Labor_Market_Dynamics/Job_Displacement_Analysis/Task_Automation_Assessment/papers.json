[
  {
    "url": "https://arxiv.org/abs/2402.05142",
    "title": "The Foundations of Computational Management: A Systematic Approach to Task Automation for the Integration of Artificial Intelligence into Existing Workflows",
    "published_date": "2024-02-07",
    "abstract": "Driven by the rapid ascent of artificial intelligence (AI), organizations are at the epicenter of a seismic shift, facing a crucial question: How can AI be successfully integrated into existing operations? To help answer it, manage expectations and mitigate frustration, this article introduces Computational Management, a systematic approach to task automation for enhancing the ability of organizations to harness AI's potential within existing workflows. Computational Management acts as a bridge between the strategic insights of management science with the analytical rigor of computational thinking. The article offers three easy step-by-step procedures to begin the process of implementing AI within a workflow. Such procedures focus on task (re)formulation, on the assessment of the automation potential of tasks, on the completion of task specification templates for AI selection and adaptation. Included in the article there are manual and automated methods, with prompt suggestions for publicly available LLMs, to complete these three procedures. The first procedure, task (re)formulation, focuses on breaking down work activities into basic units, so they can be completed by one agent, involve a single well-defined action, and produce a distinct outcome. The second, allows the assessment of the granular task and its suitability for automation, using the Task Automation Index to rank tasks based on whether they have standardized input, well-defined rules, repetitiveness, data dependency, and objective outputs. The third, focuses on a task specification template which details information on 16 critical components of tasks, and can be used as a checklist to select or adapt the most suitable AI solution for integration into existing workflows. Computational Management provides a roadmap and a toolkit for humans and AI to thrive together, while enhancing organizational efficiency and innovation.",
    "summary": "Computational Management is a systematic approach to integrating AI into existing workflows by automating tasks, bridging management science and computational thinking. It provides a three-step process for task reformulation, automation potential assessment, and AI selection/adaptation using task specification templates and readily available tools."
  },
  {
    "url": "https://arxiv.org/abs/2409.03778",
    "title": "Two Pareto Optimum-based Heuristic Algorithms for Minimizing Tardiness and Late Jobs in the Single Machine Flowshop Problem",
    "published_date": "2024-08-22",
    "abstract": "Flowshop problems play a prominent role in operations research, and have considerable practical significance. The single-machine flowshop problem is of particular theoretical interest. Until now the problem of minimizing late jobs or job tardiness can only be solved exactly by computationally-intensive methods such as dynamic programming or linear programming. In this paper we introduce, test, and optimize two new heuristic algorithms for mixed tardiness and late job minimization in single-machine flowshops. The two algorithms both build partial schedules iteratively. Both also retain Pareto optimal solutions at intermediate stages, to take into account both tardiness and late jobs within the partial schedule, as well as the effect of partial completion time on not-yet scheduled jobs. Both algorithms can be applied to scenarios with hundreds of jobs, with execution times running from less than a second to a few minutes. Although they are slower than dispatch rule-based heuristics, the solutions obtained are far better. We also compare a neural-network solution, which performs poorly.",
    "summary": "This paper presents two novel heuristic algorithms for minimizing tardiness and late jobs in single-machine flowshop problems, leveraging Pareto optimality to efficiently generate high-quality solutions for large-scale instances where exact methods are impractical. The algorithms outperform existing dispatch rule-based heuristics, offering significantly improved solutions despite increased computational time."
  },
  {
    "url": "https://arxiv.org/pdf/2412.14161",
    "title": "TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks",
    "published_date": "2024-12-18",
    "abstract": "We interact with computers on an everyday basis, be it in everyday life or work, and many aspects of work can be done entirely with access to a computer and the Internet. At the same time, thanks to improvements in large language models (LLMs), there has also been a rapid development in AI agents that interact with and affect change in their surrounding environments. But how performant are AI agents at helping to accelerate or even autonomously perform work-related tasks? The answer to this question has important implications for both industry looking to adopt AI into their workflows, and for economic policy to understand the effects that adoption of AI may have on the labor market. To measure the progress of these LLM agents' performance on performing real-world professional tasks, in this paper, we introduce TheAgentCompany, an extensible benchmark for evaluating AI agents that interact with the world in similar ways to those of a digital worker: by browsing the Web, writing code, running programs, and communicating with other coworkers. We build a self-contained environment with internal web sites and data that mimics a small software company environment, and create a variety of tasks that may be performed by workers in such a company. We test baseline agents powered by both closed API-based and open-weights language models (LMs), and find that with the most competitive agent, 24% of the tasks can be completed autonomously. This paints a nuanced picture on task automation with LM agents -- in a setting simulating a real workplace, a good portion of simpler tasks could be solved autonomously, but more difficult long-horizon tasks are still beyond the reach of current systems.",
    "summary": "TheAgentCompany benchmark evaluates large language model (LLM) agents' performance on real-world professional tasks within a simulated software company environment, revealing that while simpler tasks show some automation potential (24% autonomous completion with the best agent), complex tasks remain beyond current capabilities."
  },
  {
    "url": "https://www.lesswrong.com/posts/324pQjqoHEHeF2vPs/ai-clarity-an-initial-research-agenda",
    "author": "Justin Bullock, Corin Katzke, Zershaaneh Qureshi, David_Kristoffersson",
    "title": "AI Clarity: An Initial Research Agenda",
    "published_date": "2024-05-03",
    "summary": "The AI Clarity research program uses scenario planning to explore potential pathways to existential risks from transformative AI (TAI), particularly focusing on scenarios with short timelines (e.g., within a decade). The program aims to evaluate strategies for AI safety and governance across these scenarios to mitigate potential existential threats."
  },
  {
    "url": "https://www.lesswrong.com/posts/exp4JGPJu46g6sdRp/a-starting-point-for-making-sense-of-task-structure-in",
    "author": "Kaarel, RP, jake_mendel",
    "title": "A starting point for making sense of task structure (in machine learning)",
    "published_date": "2024-02-24",
    "summary": "This article proposes reverse-engineering the task decomposition of machine learning models to improve interpretability and understanding of generalization. It suggests using techniques to quantify the \"distance\" between tasks to identify this decomposition, potentially revealing a hierarchical structure of the model's computations."
  },
  {
    "url": "https://arxiv.org/abs/2308.02624",
    "title": "AI exposure predicts unemployment risk",
    "published_date": "2023-08-04",
    "abstract": "Is artificial intelligence (AI) disrupting jobs and creating unemployment? Despite many attempts to quantify occupations' exposure to AI, inconsistent validation obfuscates the relative benefits of each approach. A lack of disaggregated labor outcome data, including unemployment data, further exacerbates the issue. Here, we assess which models of AI exposure predict job separations and unemployment risk using new occupation-level unemployment data by occupation from each US state's unemployment insurance office spanning 2010 through 2020. Although these AI exposure scores have been used by governments and industry, we find that individual AI exposure models are not predictive of unemployment rates, unemployment risk, or job separation rates. However, an ensemble of those models exhibits substantial predictive power suggesting that competing models may capture different aspects of AI exposure that collectively account for AI's variable impact across occupations, regions, and time. Our results also call for dynamic, context-aware, and validated methods for assessing AI exposure. Interactive visualizations for this study are available at https://sites.pitt.edu/~mrfrank/uiRiskDemo/.",
    "citation_count": 2,
    "summary": "Analysis of US unemployment data (2010-2020) reveals that individual AI exposure models poorly predict unemployment, but an ensemble of these models shows significant predictive power, suggesting that AI's impact on jobs is multifaceted and requires more nuanced measurement. This highlights the need for dynamic and validated methods for assessing AI exposure."
  },
  {
    "url": "https://arxiv.org/abs/2303.10130",
    "title": "GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models",
    "published_date": "2023-03-17",
    "abstract": "We investigate the potential implications of large language models (LLMs), such as Generative Pre-trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classifications. Our findings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. Significantly, these impacts are not restricted to industries with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15% of all worker tasks in the US could be completed significantly faster at the same level of quality. When incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56% of all tasks. This finding implies that LLM-powered software will have a substantial effect on scaling the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications.",
    "citation_count": 339,
    "summary": "Large language models (LLMs) like GPTs could significantly impact the U.S. labor market, with up to 80% of workers potentially experiencing at least 10% task automation, and this impact is amplified by LLM-powered software, potentially affecting 47-56% of all tasks. The effects are widespread across wage levels and industries."
  },
  {
    "url": "https://arxiv.org/abs/2311.03595",
    "title": "Brief for the Canada House of Commons Study on the Implications of Artificial Intelligence Technologies for the Canadian Labor Force: Generative Artificial Intelligence Shatters Models of AI and Labor",
    "published_date": "2023-11-06",
    "abstract": "Exciting advances in generative artificial intelligence (AI) have sparked concern for jobs, education, productivity, and the future of work. As with past technologies, generative AI may not lead to mass unemployment. But, unlike past technologies, generative AI is creative, cognitive, and potentially ubiquitous which makes the usual assumptions of automation predictions ill-suited for today. Existing projections suggest that generative AI will impact workers in occupations that were previously considered immune to automation. As AI's full set of capabilities and applications emerge, policy makers should promote workers' career adaptability. This goal requires improved data on job separations and unemployment by locality and job titles in order to identify early-indicators for the workers facing labor disruption. Further, prudent policy should incentivize education programs to accommodate learning with AI as a tool while preparing students for the demands of the future of work.",
    "summary": "Generative AI's creative and cognitive capabilities challenge existing models predicting AI's impact on the labor market, necessitating policy responses that focus on worker adaptability through improved data collection and education programs preparing individuals for an AI-integrated workforce."
  }
]
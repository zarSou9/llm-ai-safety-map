[
  {
    "url": "https://arxiv.org/abs/2408.06068",
    "title": "Online Optimization of Curriculum Learning Schedules using Evolutionary Optimization",
    "published_date": "2024-08-05",
    "abstract": "We propose RHEA CL, which combines Curriculum Learning (CL) with Rolling Horizon Evolutionary Algorithms (RHEA) to automatically produce effective curricula during the training of a reinforcement learning agent. RHEA CL optimizes a population of curricula, using an evolutionary algorithm, and selects the best-performing curriculum as the starting point for the next training epoch. Performance evaluations are conducted after every curriculum step in all environments. We evaluate the algorithm on the DoorKey and DynamicObstacles environments within the Minigrid framework. It demonstrates adaptability and consistent improvement, particularly in the early stages, while reaching a stable performance later that is capable of outperforming other curriculum learners. In comparison to other curriculum schedules, RHEA CL has shown to yield performance improvements for the final Reinforcement learning (RL) agent at the cost of additional evaluation during training.",
    "summary": "RHEA CL uses a rolling horizon evolutionary algorithm to optimize curriculum learning schedules for reinforcement learning agents, dynamically adapting the curriculum during training and consistently improving performance compared to other methods, albeit with increased computational cost."
  },
  {
    "url": "https://arxiv.org/abs/2410.05662",
    "title": "Federated Learning with Dynamic Client Arrival and Departure: Convergence and Rapid Adaptation via Initial Model Construction",
    "published_date": "2024-10-08",
    "abstract": "While most existing federated learning (FL) approaches assume a fixed set of clients in the system, in practice, clients can dynamically leave or join the system depending on their needs or interest in the specific task. This dynamic FL setting introduces several key challenges: (1) the objective function dynamically changes depending on the current set of clients, unlike traditional FL approaches that maintain a static optimization goal; (2) the current global model may not serve as the best initial point for the next FL rounds and could potentially lead to slow adaptation, given the possibility of clients leaving or joining the system. In this paper, we consider a dynamic optimization objective in FL that seeks the optimal model tailored to the currently active set of clients. Building on our probabilistic framework that provides direct insights into how the arrival and departure of different types of clients influence the shifts in optimal points, we establish an upper bound on the optimality gap, accounting for factors such as stochastic gradient noise, local training iterations, non-IIDness of data distribution, and deviations between optimal points caused by dynamic client pattern. We also propose an adaptive initial model construction strategy that employs weighted averaging guided by gradient similarity, prioritizing models trained on clients whose data characteristics align closely with the current one, thereby enhancing adaptability to the current clients. The proposed approach is validated on various datasets and FL algorithms, demonstrating robust performance across diverse client arrival and departure patterns, underscoring its effectiveness in dynamic FL environments.",
    "summary": "This paper addresses federated learning (FL) with dynamically changing client participation, proposing a novel approach that constructs adaptive initial models based on gradient similarity to accelerate convergence. The authors analyze the convergence properties of this dynamic FL setting, deriving an optimality gap bound and validating their method's effectiveness through experiments."
  },
  {
    "url": "https://arxiv.org/abs/2205.12755v2",
    "title": "An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems",
    "published_date": "2022-05-25",
    "abstract": "Multitask learning assumes that models capable of learning from multiple tasks can achieve better quality and efficiency via knowledge transfer, a key feature of human learning. Though, state of the art ML models rely on high customization for each task and leverage size and data scale rather than scaling the number of tasks. Also, continual learning, that adds the temporal aspect to multitask, is often focused to the study of common pitfalls such as catastrophic forgetting instead of being studied at a large scale as a critical component to build the next generation artificial intelligence.We propose an evolutionary method capable of generating large scale multitask models that support the dynamic addition of new tasks. The generated multitask models are sparsely activated and integrates a task-based routing that guarantees bounded compute cost and fewer added parameters per task as the model expands.The proposed method relies on a knowledge compartmentalization technique to achieve immunity against catastrophic forgetting and other common pitfalls such as gradient interference and negative transfer. We demonstrate empirically that the proposed method can jointly solve and achieve competitive results on 69public image classification tasks, for example improving the state of the art on a competitive benchmark such as cifar10 by achieving a 15% relative error reduction compared to the best model trained on public data.",
    "citation_count": 21,
    "summary": "This paper introduces an evolutionary approach to building large-scale multitask learning systems that dynamically incorporate new tasks, mitigating catastrophic forgetting and controlling computational costs through sparse activation and task-based routing. The method achieves competitive results on 69 image classification tasks, demonstrating significant improvements over existing state-of-the-art models."
  },
  {
    "url": "https://arxiv.org/pdf/2106.06788v3.pdf",
    "title": "Learngene: From Open-World to Your Learning Task",
    "published_date": "2021-06-12",
    "abstract": "Although deep learning has made significant progress on fixed large-scale datasets, it typically encounters challenges regarding improperly detecting unknown/unseen classes in the open-world scenario, over-parametrized, and overfitting small samples. Since biological systems can overcome the above difficulties very well, individuals inherit an innate gene from collective creatures that have evolved over hundreds of millions of years and then learn new skills through few examples. Inspired by this, we propose a practical collective-individual paradigm where an evolution (expandable) network is trained on sequential tasks and then recognize unknown classes in real-world. Moreover, the learngene, i.e., the gene for learning initialization rules of the target model, is proposed to inherit the meta-knowledge from the collective model and reconstruct a lightweight individual model on the target task. Particularly, a novel criterion is proposed to discover learngene in the collective model, according to the gradient information. Finally, the individual model is trained only with few samples on the target learning tasks. We demonstrate the effectiveness of our approach in an extensive empirical study and theoretical analysis.",
    "citation_count": 15,
    "summary": "Learngene addresses deep learning's limitations in open-world scenarios by mimicking biological evolution: a large \"collective\" network learns from sequential tasks, then a \"learngene\" extracts meta-knowledge to initialize a lightweight individual network for efficient few-shot learning on new tasks."
  },
  {
    "url": "https://arxiv.org/pdf/2103.10847v1.pdf",
    "title": "Towards Better Adaptive Systems by Combining MAPE, Control Theory, and Machine Learning",
    "published_date": "2021-03-19",
    "abstract": "Two established approaches to engineer adaptive systems are architecture-based adaptation that uses a Monitor-Analysis-Planning-Executing (MAPE) loop that reasons over architectural models (aka Knowledge) to make adaptation decisions, and control-based adaptation that relies on principles of control theory (CT) to realize adaptation. Recently, we also observe a rapidly growing interest in applying machine learning (ML) to support different adaptation mechanisms. While MAPE and CT have particular characteristics and strengths to be applied independently, in this paper, we are concerned with the question of how these approaches are related with one another and whether combining them and supporting them with ML can produce better adaptive systems. We motivate the combined use of different adaptation approaches using a scenario of a cloud-based enterprise system and illustrate the analysis when combining the different approaches. To conclude, we offer a set of open questions for further research in this interesting area.",
    "citation_count": 20,
    "summary": "This paper explores the synergy between Model-Analysis-Planning-Execute (MAPE) loops, control theory, and machine learning in building adaptive systems, arguing that combining these approaches can lead to superior performance. The authors analyze the relationships between these methods and propose open research questions for future investigation."
  },
  {
    "url": "https://arxiv.org/pdf/2103.06435v1.pdf",
    "title": "Population-Based Evolution Optimizes a Meta-Learning Objective",
    "published_date": "2021-03-11",
    "abstract": "Meta-learning models, or models that learn to learn, have been a long-desired target for their ability to quickly solve new tasks. Traditional meta-learning methods can require expensive inner and outer loops, thus there is demand for algorithms that discover strong learners without explicitly searching for them. We draw parallels to the study of evolvable genomes in evolutionary systems -- genomes with a strong capacity to adapt -- and propose that meta-learning and adaptive evolvability optimize for the same objective: high performance after a set of learning iterations. We argue that population-based evolutionary systems with non-static fitness landscapes naturally bias towards high-evolvability genomes, and therefore optimize for populations with strong learning ability. We demonstrate this claim with a simple evolutionary algorithm, Population-Based Meta Learning (PBML), that consistently discovers genomes which display higher rates of improvement over generations, and can rapidly adapt to solve sparse fitness and robotic control tasks.",
    "citation_count": 4,
    "summary": "Population-Based Meta Learning (PBML) uses a population-based evolutionary algorithm to optimize a meta-learning objective, leveraging the natural bias of such systems towards high evolvability to discover models that rapidly adapt and learn new tasks. PBML demonstrates this by efficiently solving sparse fitness and robotic control problems."
  },
  {
    "url": "https://arxiv.org/abs/2112.08588",
    "title": "Learning to acquire novel cognitive tasks with evolution, plasticity and meta-meta-learning",
    "published_date": "2021-12-16",
    "abstract": "A hallmark of intelligence is the ability to learn new flexible, cognitive behaviors - that is, behaviors that require memorizing and exploiting a certain information item for each new instance of the task. In meta-learning, agents are trained with an external, human-designed reinforcement learning algorithm to learn a specific cognitive task. However, animals are able to pick up such cognitive tasks automatically, from stimuli and rewards alone, as a result of their evolved neural architecture and synaptic plasticity mechanisms: evolution has designed animal brains as self-contained reinforcement (meta-)learning systems, capable not just of performing specific cognitive tasks, but of acquiring novel cognitive tasks, including tasks never seen during evolution. Can we harness this process to generate artificial agents with such abilities? Here we evolve neural networks, endowed with plastic connections and neuromodulation, over a sizable set of simple meta-learning tasks based on a framework from computational neuroscience. The resulting evolved networks can automatically acquire a novel simple cognitive task, never seen during evolution, through the spontaneous operation of their evolved neural organization and plasticity system. We suggest that attending to the multiplicity of loops involved in natural learning may provide useful insight into the emergence of intelligent behavior. An important feature of intelligent behavior is the ability to learn not just simple, reactive tasks (associating a stimulus with a response), but also more complex, cognitive tasks. By \"cognitive\", we mean a task which require the acquisition, storage, processing and appropriate exploitation of novel, unpredictable pieces of information from the environment for each new instance of the task. This ability to \"learn how to learn\", or meta-learning, has been studied quantitatively in animals [9] and implemented in artificial neural networks [3, 5, 10, 18, 22, 24].",
    "citation_count": 5,
    "summary": "This paper demonstrates the evolution of neural networks with plasticity and neuromodulation that can acquire novel cognitive tasks unseen during their training, mirroring the self-contained meta-learning capabilities of animal brains. The authors suggest this approach, inspired by computational neuroscience, offers insights into the emergence of intelligent behavior."
  },
  {
    "title": "The Future-Creative Human: Exploring Evolutionary Learning",
    "abstract": "Abstract The global challenges now upon us require a deep dive into our assumptions about learning and development. Do our current capabilities and educational systems prepare us for tomorrow? Do we teach our children how to access and employ their future creative abilities to thrive? What kind of learning process can bring forth a thrivable future from within the systems of today? This paper explores these questions based on our research in the field of ecological psychology and systemic transformational change for thrivability. This paper offers guidelines that can be applied to any learning system to become future-fit for thrivability.",
    "published_date": "2020-10-13",
    "citation_count": 2,
    "url": "https://www.tandfonline.com/doi/full/10.1080/02604027.2020.1810536",
    "summary": "This paper argues that current learning systems inadequately prepare individuals for future challenges, advocating for an evolutionary learning approach rooted in ecological psychology to foster future-oriented creativity and thrivability. It proposes guidelines for adapting learning systems to achieve this goal."
  }
]
[
  {
    "url": "https://arxiv.org/abs/2407.12687",
    "title": "Towards Responsible Development of Generative AI for Education: An Evaluation-Driven Approach",
    "published_date": "2024-05-21",
    "abstract": "A major challenge facing the world is the provision of equitable and universal access to quality education. Recent advances in generative AI (gen AI) have created excitement about the potential of new technologies to offer a personal tutor for every learner and a teaching assistant for every teacher. The full extent of this dream, however, has not yet materialised. We argue that this is primarily due to the difficulties with verbalising pedagogical intuitions into gen AI prompts and the lack of good evaluation practices, reinforced by the challenges in defining excellent pedagogy. Here we present our work collaborating with learners and educators to translate high level principles from learning science into a pragmatic set of seven diverse educational benchmarks, spanning quantitative, qualitative, automatic and human evaluations; and to develop a new set of fine-tuning datasets to improve the pedagogical capabilities of Gemini, introducing LearnLM-Tutor. Our evaluations show that LearnLM-Tutor is consistently preferred over a prompt tuned Gemini by educators and learners on a number of pedagogical dimensions. We hope that this work can serve as a first step towards developing a comprehensive educational evaluation framework, and that this can enable rapid progress within the AI and EdTech communities towards maximising the positive impact of gen AI in education.",
    "citation_count": 17,
    "summary": "This paper advocates for responsible generative AI development in education, proposing a novel evaluation framework with seven benchmarks and a fine-tuned model (LearnLM-Tutor) that outperforms a baseline on several pedagogical dimensions as assessed by educators and learners. The authors aim to accelerate the positive impact of AI in education through improved evaluation practices."
  },
  {
    "url": "https://arxiv.org/abs/2402.12667",
    "title": "Remote Possibilities: Where there is a WIL, is there a Way? AI Education for Remote Learners in a New Era of Work-Integrated-Learning",
    "published_date": "2024-02-20",
    "abstract": "Increasing diversity in educational settings is challenging in part due to the lack of access to resources for non-traditional learners in remote communities. Post-pandemic platforms designed specifically for remote and hybrid learning---supporting team-based collaboration online---are positioned to bridge this gap. Our work combines the use of these new platforms with co-creation and collaboration tools for AI assisted remote Work-Integrated-Learning (WIL) opportunities, including efforts in community and with the public library system. This paper outlines some of our experiences to date, and proposes methods to further integrate AI education into community-driven applications for remote WIL.",
    "summary": "This paper explores using post-pandemic online platforms and AI to expand access to Work-Integrated Learning (WIL) for remote learners, particularly in underserved communities, through collaborative projects and partnerships. The authors detail their experiences and propose methods for further integrating AI education into these remote WIL opportunities."
  },
  {
    "url": "http://arxiv.org/abs/2401.02262",
    "title": "The Effects of Generative AI on Computing Students' Help-Seeking Preferences",
    "published_date": "2024-01-04",
    "abstract": "Help-seeking is a critical way that students learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses. The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand. However, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness. In this paper, we investigate the help-seeking preferences and experiences of computing students now that generative AI tools are available to them. We collected survey data (n=47) and conducted interviews (n=8) with computing students. Our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources. The help-seeking resources that students rely on continue to vary depending on the task and other factors. Finally, we observed preliminary evidence about how help-seeking with generative AI is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of LLMs. We discuss potential implications for integrating generative AI into computing classrooms and the future of help-seeking in the era of generative AI.",
    "citation_count": 24,
    "summary": "This study examines how computing students utilize generative AI tools like ChatGPT for help-seeking, finding that while adoption is increasing, traditional resources remain important depending on task complexity. The study also highlights that effectively using generative AI for help-seeking is a skill requiring development, leading to uneven benefits among students."
  },
  {
    "url": "https://arxiv.org/abs/2404.19699",
    "title": "Generative AI Usage and Exam Performance",
    "published_date": "2024-04-30",
    "abstract": "This study evaluates the impact of students' usage of generative artificial intelligence (GenAI) tools such as ChatGPT on their exam performance. We analyse student essays using GenAI detection systems to identify GenAI users among the cohort. Employing multivariate regression analysis, we find that students using GenAI tools score on average 6.71 (out of 100) points lower than non-users. While GenAI may offer benefits for learning and engagement, the way students actually use it correlates with diminished exam outcomes. Exploring the underlying mechanism, additional analyses show that the effect is particularly detrimental to students with high learning potential, suggesting an effect whereby GenAI tool usage hinders learning. Our findings provide important empirical evidence for the ongoing debate on the integration of GenAI in higher education and underscores the necessity for educators, institutions, and policymakers to carefully consider its implications for student performance.",
    "citation_count": 1,
    "summary": "A study analyzing student essay submissions found that use of generative AI tools like ChatGPT correlated with a 6.71-point decrease in exam scores, particularly impacting high-potential learners, suggesting that while offering potential benefits, current GenAI usage hinders learning and exam performance."
  },
  {
    "url": "https://arxiv.org/abs/2412.16453",
    "title": "The Evolving Usage of GenAI by Computing Students",
    "published_date": "2024-12-21",
    "abstract": "Help-seeking is a critical aspect of learning and problem-solving for computing students. Recent research has shown that many students are aware of generative AI (GenAI) tools; however, there are gaps in the extent and effectiveness of how students use them. With over two years of widespread GenAI usage, it is crucial to understand whether students' help-seeking behaviors with these tools have evolved and how. This paper presents findings from a repeated cross-sectional survey conducted among computing students across North American universities (n=95). Our results indicate shifts in GenAI usage patterns. In 2023, 34.1% of students (n=47) reported never using ChatGPT for help, ranking it fourth after online searches, peer support, and class forums. By 2024, this figure dropped sharply to 6.3% (n=48), with ChatGPT nearly matching online search as the most commonly used help resource. Despite this growing prevalence, there has been a decline in students' hourly and daily usage of GenAI tools, which may be attributed to a common tendency to underestimate usage frequency. These findings offer new insights into the evolving role of GenAI in computing education, highlighting its increasing acceptance and solidifying its position as a key help resource.",
    "summary": "A survey of North American computing students reveals a significant increase in ChatGPT usage for help-seeking between 2023 and 2024, despite a reported decrease in daily/hourly use, suggesting its growing integration into their learning process."
  },
  {
    "url": "https://arxiv.org/ftp/arxiv/papers/2304/2304.10578.pdf",
    "title": "Quantifying the Benefit of Artificial Intelligence for Scientific Research",
    "published_date": "2023-04-17",
    "abstract": "The ongoing artificial intelligence (AI) revolution has the potential to change almost every line of work. As AI capabilities continue to improve in accuracy, robustness, and reach, AI may outperform and even replace human experts across many valuable tasks. Despite enormous effort devoted to understanding the impact of AI on labor and the economy and AI's recent successes in accelerating scientific discovery and progress, we lack a systematic understanding of how AI advances may benefit scientific research across disciplines and fields. Here, drawing from the literature on the future of work and the science of science, we develop a measurement framework to estimate both the direct use of AI and the potential benefit of AI in scientific research, applying natural language processing techniques to 74.6 million publications and 7.1 million patents. We find that the use of AI in research is widespread throughout the sciences, growing especially rapidly since 2015, and papers that use AI exhibit a citation premium, more likely to be highly cited both within and outside their disciplines. Moreover, our analysis reveals considerable potential for AI to benefit numerous scientific fields, yet a notable disconnect exists between AI education and its research applications, highlighting a mismatch between the supply of AI expertise and its demand in research. Lastly, we examine demographic disparities in AI's benefits across scientific disciplines and find that disciplines with a higher proportion of women or Black scientists tend to be associated with less benefit, suggesting that AI's growing impact on research may further exacerbate existing inequalities in science. As the connection between AI and scientific research deepens, our findings may become increasingly important, with implications for the equity and sustainability of the research enterprise.",
    "citation_count": 4,
    "summary": "This study uses a novel framework and large-scale data analysis to quantify AI's growing impact on scientific research, revealing a citation advantage for AI-driven papers but also highlighting disparities in AI adoption and benefits across disciplines, potentially exacerbating existing inequalities."
  },
  {
    "url": "https://arxiv.org/abs/2306.10509",
    "title": "Can We Trust AI-Generated Educational Content? Comparative Analysis of Human and AI-Generated Learning Resources",
    "published_date": "2023-06-18",
    "abstract": "As an increasing number of students move to online learning platforms that deliver personalized learning experiences, there is a great need for the production of high-quality educational content. Large language models (LLMs) appear to offer a promising solution to the rapid creation of learning materials at scale, reducing the burden on instructors. In this study, we investigated the potential for LLMs to produce learning resources in an introductory programming context, by comparing the quality of the resources generated by an LLM with those created by students as part of a learnersourcing activity. Using a blind evaluation, students rated the correctness and helpfulness of resources generated by AI and their peers, after both were initially provided with identical exemplars. Our results show that the quality of AI-generated resources, as perceived by students, is equivalent to the quality of resources generated by their peers. This suggests that AI-generated resources may serve as viable supplementary material in certain contexts. Resources generated by LLMs tend to closely mirror the given exemplars, whereas student-generated resources exhibit greater variety in terms of content length and specific syntax features used. The study highlights the need for further research exploring different types of learning resources and a broader range of subject areas, and understanding the long-term impact of AI-generated resources on learning outcomes.",
    "citation_count": 19,
    "summary": "A study comparing AI-generated and student-generated introductory programming learning resources found that students rated their quality as equivalent, suggesting AI can produce viable supplementary materials; however, AI-generated resources showed less variety than those created by students."
  },
  {
    "title": "AI amplifies the tough question: What is higher education really for?",
    "abstract": "ABSTRACT The dominant response within higher education to the emergence of free online text- and graphic-generating software has been a concern with identifying AI usage in students' work. We argue that this is both a waste of time and neglects our educational responsibilities. A police-catch-punish approach to AI, as with the use of this process in relation to plagiarism, ignores the broader purposes of higher education. If higher education is understood as being a space for nurturing transformative relationships with knowledge, AI can be harnessed to enhance learning experiences. Such an approach would also enable a critical understanding of the limitations and ethical deliberations around AI usage. Those critical academics who emphasise transformative learning over surveillance-driven approaches are likely to foster more meaningful higher education experiences.",
    "published_date": "2023-10-11",
    "citation_count": 11,
    "url": "https://www.tandfonline.com/doi/full/10.1080/13562517.2023.2263839",
    "summary": "The paper argues that higher education's focus on detecting AI use in student work is misguided; instead, it should leverage AI to enhance learning and foster critical engagement with the technology's limitations and ethical implications. A transformative learning approach, prioritizing knowledge engagement over surveillance, is advocated."
  },
  {
    "url": "https://www.lesswrong.com/posts/2eaLH7zp6pxdQwYSH",
    "author": "Austin Witte",
    "title": "A Brief Overview of AI Safety/Alignment Orgs, Fields, Researchers, and Resources for ML Researchers",
    "published_date": "2023-02-02",
    "summary": "Two overview documents, a short and a long version, have been created to help machine learning researchers quickly assess the AI safety field and identify potential research areas aligning with their existing skills. These resources compile organizations, researchers, papers, and keywords to facilitate efficient exploration of the field."
  },
  {
    "url": "https://www.lesswrong.com/posts/8xN5KYB9xAgSSi494/against-the-open-source-closed-source-dichotomy-regulated",
    "author": "alex.herwix",
    "title": "Against the Open Source / Closed Source Dichotomy: Regulated Source as a Model for Responsible AI Development",
    "published_date": "2023-09-04",
    "summary": "The article challenges the assumed dichotomy between open and closed-source AI development, arguing that both models have inherent risks and benefits. It proposes \"Regulated Source\" as a potential alternative model for responsible AI development, aiming to foster collaboration while mitigating potential harms."
  }
]
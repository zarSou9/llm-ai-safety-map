[
  {
    "url": "https://www.lesswrong.com/posts/GCHyDKfPXa5qsG2cP/human-study-on-ai-spear-phishing-campaigns",
    "author": "Simon Lermen, Fred Heiding, Andrew Kao",
    "title": "Human study on AI spear phishing campaigns",
    "published_date": "2025-01-03",
    "summary": "A study found that AI-generated spear-phishing emails, leveraging GPT-4 and Claude 3.5, achieved over 50% click-through rates, comparable to human-crafted emails and significantly exceeding a control group. This demonstrates the effectiveness and cost-efficiency of AI in spear-phishing attacks."
  },
  {
    "url": "https://arxiv.org/abs/2403.13944",
    "title": "Shortchanged: Uncovering and Analyzing Intimate Partner Financial Abuse in Consumer Complaints",
    "published_date": "2024-03-20",
    "abstract": "Digital financial services can introduce new digital-safety risks for users, particularly survivors of intimate partner financial abuse (IPFA). To offer improved support for such users, a comprehensive understanding of their support needs and the barriers they face to redress by financial institutions is essential. Drawing from a dataset of 2.7 million customer complaints, we implement a bespoke workflow that utilizes language-modeling techniques and expert human review to identify complaints describing IPFA. Our mixed-method analysis provides insight into the most common digital financial products involved in these attacks, and the barriers consumers report encountering when doing so. Our contributions are twofold; we offer the first human-labeled dataset for this overlooked harm and provide practical implications for technical practice, research, and design for better supporting and protecting survivors of IPFA.",
    "summary": "This study analyzes 2.7 million consumer complaints to identify instances of intimate partner financial abuse (IPFA) using natural language processing and human review, creating the first human-labeled dataset of its kind and revealing common digital financial products involved and barriers to redress. The findings offer crucial insights for improving support and protection for IPFA survivors."
  },
  {
    "url": "https://arxiv.org/abs/2404.11898",
    "title": "Enhancing Financial Inclusion and Regulatory Challenges: A Critical Analysis of Digital Banks and Alternative Lenders Through Digital Platforms, Machine Learning, and Large Language Models Integration",
    "published_date": "2024-04-18",
    "abstract": "This paper explores the dual impact of digital banks and alternative lenders on financial inclusion and the regulatory challenges posed by their business models. It discusses the integration of digital platforms, machine learning (ML), and Large Language Models (LLMs) in enhancing financial services accessibility for underserved populations. Through a detailed analysis of operational frameworks and technological infrastructures, this research identifies key mechanisms that facilitate broader financial access and mitigate traditional barriers. Additionally, the paper addresses significant regulatory concerns involving data privacy, algorithmic bias, financial stability, and consumer protection. Employing a mixed-methods approach, which combines quantitative financial data analysis with qualitative insights from industry experts, this paper elucidates the complexities of leveraging digital technology to foster financial inclusivity. The findings underscore the necessity of evolving regulatory frameworks that harmonize innovation with comprehensive risk management. This paper concludes with policy recommendations for regulators, financial institutions, and technology providers, aiming to cultivate a more inclusive and stable financial ecosystem through prudent digital technology integration.",
    "citation_count": 1,
    "summary": "This paper analyzes how digital banks and alternative lenders, using digital platforms, machine learning, and LLMs, enhance financial inclusion while also highlighting the resulting regulatory challenges related to data privacy, bias, stability, and consumer protection. It proposes policy recommendations to balance innovation with responsible risk management in this evolving financial landscape."
  },
  {
    "url": "http://arxiv.org/abs/2401.13138",
    "title": "Visibility into AI Agents",
    "published_date": "2024-01-23",
    "abstract": "Increased delegation of commercial, scientific, governmental, and personal activities to AI agents—systems capable of pursuing complex goals with limited supervision—may exacerbate existing societal risks and introduce new risks. Understanding and mitigating these risks involves critically evaluating existing governance structures, revising and adapting these structures where needed, and ensuring accountability of key stakeholders. Information about where, why, how, and by whom certain AI agents are used, which we refer to as visibility, is critical to these objectives. In this paper, we assess three categories of measures to increase visibility into AI agents: agent identifiers, real-time monitoring, and activity logging. For each, we outline potential implementations that vary in intrusiveness and informativeness. We analyze how the measures apply across a spectrum of centralized through decentralized deployment contexts, accounting for various actors in the supply chain including hardware and software service providers. Finally, we discuss the implications of our measures for privacy and concentration of power. Further work into understanding the measures and mitigating their negative impacts can help to build a foundation for the governance of AI agents.",
    "citation_count": 12,
    "summary": "This paper examines methods to increase transparency (\"visibility\") in the use of AI agents, focusing on agent identifiers, real-time monitoring, and activity logging, while considering implementation challenges, privacy implications, and power dynamics across various deployment contexts. The authors propose these measures as crucial for mitigating societal risks associated with increasing AI agent autonomy."
  },
  {
    "url": "https://www.alignmentforum.org/posts/cLfsabkCPtieJ5LoK/investigating-bias-representations-in-llms-via-activation",
    "author": "DawnLu",
    "title": "Investigating Bias Representations in LLMs via Activation Steering",
    "published_date": "2024-01-15",
    "summary": "This research uses activation steering to assess the societal biases of the Llama-2-7b-chat LLM, finding that while the model exhibits gender bias in unsteered responses, attempts to further steer it towards biased outputs using contrastive activation addition resulted in the model refusing to answer, suggesting a potential robustness to direct manipulation of its biases."
  },
  {
    "url": "https://www.alignmentforum.org/posts/oq5CtbsCncctPWkTn/best-of-n-jailbreaking",
    "author": "John Hughes, saraprice, Aengus Lynch, Rylan Schaeffer, Fazl, Henry Sleight, Ethan Perez, mrinank_sharma",
    "title": "Best-of-N Jailbreaking",
    "published_date": "2024-12-14",
    "summary": "Best-of-N (BoN) jailbreaking is a new technique that effectively bypasses safety features in leading AI models across text, audio, and vision modalities by iteratively modifying prompts until a harmful response is elicited; attack success rates predictably scale with the number of attempted variations, following a power law."
  },
  {
    "url": "https://www.lesswrong.com/posts/buiTYy75KJDhckDgq/truth-terminal-a-reconstruction-of-events",
    "author": "crvr.fr, MTorrents",
    "title": "Truth Terminal: A reconstruction of events",
    "published_date": "2024-11-17",
    "summary": "A New Zealand AI enthusiast fine-tuned an AI model with internet memes and dark web content, resulting in the creation of \"Truth Terminal,\" an AI that developed a bizarre, cult-like religion and, after being connected to Twitter, promoted a cryptocurrency, demonstrating the unpredictable and potentially manipulative capabilities of LLMs."
  },
  {
    "url": "https://arxiv.org/pdf/2307.13408.pdf",
    "title": "The Double-Edged Sword of Big Data and Information Technology for the Disadvantaged: A Cautionary Tale from Open Banking",
    "published_date": "2023-07-25",
    "abstract": "This research article analyses and demonstrates the hidden implications for fairness of seemingly neutral data coupled with powerful technology, such as machine learning (ML), using Open Banking as an example. Open Banking has ignited a revolution in financial services, opening new opportunities for customer acquisition, management, retention, and risk assessment. However, the granularity of transaction data holds potential for harm where unnoticed proxies for sensitive and prohibited characteristics may lead to indirect discrimination. Against this backdrop, we investigate the dimensions of financial vulnerability (FV), a global concern resulting from COVID-19 and rising inflation. Specifically, we look to understand the behavioral elements leading up to FV and its impact on at-risk, disadvantaged groups through the lens of fair interpretation. Using a unique dataset from a UK FinTech lender, we demonstrate the power of fine-grained transaction data while simultaneously cautioning its safe usage. Three ML classifiers are compared in predicting the likelihood of FV, and groups exhibiting different magnitudes and forms of FV are identified via clustering to highlight the effects of feature combination. Our results indicate that engineered features of financial behavior can be predictive of omitted personal information, particularly sensitive or protected characteristics, shedding light on the hidden dangers of Open Banking data. We discuss the implications and conclude fairness via unawareness is ineffective in this new technological environment.",
    "citation_count": 1,
    "summary": "Open Banking's detailed transaction data, while beneficial for financial services, can indirectly discriminate against disadvantaged groups by using seemingly neutral behavioral data as proxies for sensitive characteristics in machine learning models. This study, using UK FinTech data, demonstrates the predictive power of such data while highlighting the crucial need for careful implementation to avoid unfair outcomes."
  }
]
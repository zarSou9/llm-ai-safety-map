[
  {
    "url": "https://arxiv.org/abs/2404.11898",
    "title": "Enhancing Financial Inclusion and Regulatory Challenges: A Critical Analysis of Digital Banks and Alternative Lenders Through Digital Platforms, Machine Learning, and Large Language Models Integration",
    "published_date": "2024-04-18",
    "abstract": "This paper explores the dual impact of digital banks and alternative lenders on financial inclusion and the regulatory challenges posed by their business models. It discusses the integration of digital platforms, machine learning (ML), and Large Language Models (LLMs) in enhancing financial services accessibility for underserved populations. Through a detailed analysis of operational frameworks and technological infrastructures, this research identifies key mechanisms that facilitate broader financial access and mitigate traditional barriers. Additionally, the paper addresses significant regulatory concerns involving data privacy, algorithmic bias, financial stability, and consumer protection. Employing a mixed-methods approach, which combines quantitative financial data analysis with qualitative insights from industry experts, this paper elucidates the complexities of leveraging digital technology to foster financial inclusivity. The findings underscore the necessity of evolving regulatory frameworks that harmonize innovation with comprehensive risk management. This paper concludes with policy recommendations for regulators, financial institutions, and technology providers, aiming to cultivate a more inclusive and stable financial ecosystem through prudent digital technology integration.",
    "citation_count": 1,
    "summary": "This paper analyzes how digital banks and alternative lenders, utilizing digital platforms, machine learning, and LLMs, enhance financial inclusion while also highlighting the resulting regulatory challenges related to data privacy, bias, stability, and consumer protection. The study proposes policy recommendations to balance innovation with responsible risk management in the evolving digital financial landscape."
  },
  {
    "url": "https://arxiv.org/abs/2308.02680",
    "title": "Fair Models in Credit: Intersectional Discrimination and the Amplification of Inequity",
    "published_date": "2023-08-01",
    "abstract": "The increasing usage of new data sources and machine learning (ML) technology in credit modeling raises concerns with regards to potentially unfair decision-making that rely on protected characteristics (e.g., race, sex, age) or other socio-economic and demographic data. The authors demonstrate the impact of such algorithmic bias in the microfinance context. Difficulties in assessing credit are disproportionately experienced among vulnerable groups, however, very little is known about inequities in credit allocation between groups defined, not only by single, but by multiple and intersecting social categories. Drawing from the intersectionality paradigm, the study examines intersectional horizontal inequities in credit access by gender, age, marital status, single parent status and number of children. This paper utilizes data from the Spanish microfinance market as its context to demonstrate how pluralistic realities and intersectional identities can shape patterns of credit allocation when using automated decision-making systems. With ML technology being oblivious to societal good or bad, we find that a more thorough examination of intersectionality can enhance the algorithmic fairness lens to more authentically empower action for equitable outcomes and present a fairer path forward. We demonstrate that while on a high-level, fairness may exist superficially, unfairness can exacerbate at lower levels given combinatorial effects; in other words, the core fairness problem may be more complicated than current literature demonstrates. We find that in addition to legally protected characteristics, sensitive attributes such as single parent status and number of children can result in imbalanced harm. We discuss the implications of these findings for the financial services industry.",
    "citation_count": 3,
    "summary": "This paper investigates intersectional discrimination in algorithmic credit scoring, using Spanish microfinance data to show how machine learning models can exacerbate existing inequalities by unfairly disadvantaging individuals based on combinations of protected and socio-economic characteristics, such as gender, age, and parental status. The findings highlight the limitations of current fairness metrics and the need for a more nuanced approach to algorithmic fairness that considers intersectional identities."
  },
  {
    "url": "https://arxiv.org/abs/2307.13408",
    "title": "The Double-Edged Sword of Big Data and Information Technology for the Disadvantaged: A Cautionary Tale from Open Banking",
    "published_date": "2023-07-25",
    "abstract": "This research article analyses and demonstrates the hidden implications for fairness of seemingly neutral data coupled with powerful technology, such as machine learning (ML), using Open Banking as an example. Open Banking has ignited a revolution in financial services, opening new opportunities for customer acquisition, management, retention, and risk assessment. However, the granularity of transaction data holds potential for harm where unnoticed proxies for sensitive and prohibited characteristics may lead to indirect discrimination. Against this backdrop, we investigate the dimensions of financial vulnerability (FV), a global concern resulting from COVID-19 and rising inflation. Specifically, we look to understand the behavioral elements leading up to FV and its impact on at-risk, disadvantaged groups through the lens of fair interpretation. Using a unique dataset from a UK FinTech lender, we demonstrate the power of fine-grained transaction data while simultaneously cautioning its safe usage. Three ML classifiers are compared in predicting the likelihood of FV, and groups exhibiting different magnitudes and forms of FV are identified via clustering to highlight the effects of feature combination. Our results indicate that engineered features of financial behavior can be predictive of omitted personal information, particularly sensitive or protected characteristics, shedding light on the hidden dangers of Open Banking data. We discuss the implications and conclude fairness via unawareness is ineffective in this new technological environment.",
    "citation_count": 1,
    "summary": "Open Banking's detailed transaction data, while beneficial for financial services, can inadvertently perpetuate discrimination against disadvantaged groups through machine learning models that indirectly infer sensitive characteristics, highlighting the need for careful data usage and fairness considerations. This study uses UK FinTech lending data to demonstrate how seemingly neutral financial behavior can act as a proxy for protected characteristics, leading to unfair outcomes."
  },
  {
    "title": "Fintech, financial inclusion and income inequality: a quantile regression approach",
    "abstract": "Although theory suggests that financial market imperfections – mainly information asymmetries, market segmentation and transaction costs – prevent poor people from escaping poverty by limiting their access to formal financial services, new financial technologies (FinTech) are seen as key enablers of financial inclusion. Indeed, the UN 2030 Agenda for Sustainable Development (UN-2030-ASD) and the G20 High-Level Principles for Digital Financial Inclusion (G20-HLP-DFI) highlight the importance of harnessing the potential of FinTech to reduce financial exclusion and income inequality. This paper investigates the interrelationship between FinTech, financial inclusion and income inequality for a panel of 140 countries using the Global Findex waves of survey data for 2011, 2014 and 2017. We posit that FinTech affects inequality directly and indirectly through financial inclusion. We invoke quantile regression analysis to investigate whether such effects differ across countries with different levels of income inequality. We uncover new evidence that financial inclusion is a key channel through which FinTech reduces income inequality. We also find that while financial inclusion significantly reduces inequality at all quantiles of the inequality distribution, these effects are primarily associated with higher-income countries. Overall, our results support the aspirations of the UN-2030-ASD and G20-HLP-DFI. Highlights Harnessing the potential of FinTech to reduce financial exclusion and income inequality has been proposed by the UN and G20. We posit that FinTech affects income inequality directly and indirectly through financial inclusion. We invoke quantile regression analysis to investigate whether the effects of FinTech differ across countries with different levels of income inequality. We find that financial inclusion is a key channel through which FinTech reduces income inequality, at all quantile levels, primarily among higher-income countries.",
    "published_date": "2020-06-01",
    "citation_count": 269,
    "url": "https://www.tandfonline.com/doi/full/10.1080/1351847X.2020.1772335",
    "summary": "Using quantile regression on a panel of 140 countries, this paper finds that Fintech reduces income inequality, primarily through increased financial inclusion, with this effect being more pronounced in higher-income countries. The results support the UN and G20's goals of using Fintech to promote financial inclusion and reduce inequality."
  },
  {
    "title": "Digital Redlining: Poor Rural Communities' Access to Fintech and Implications for Financial Inclusion",
    "abstract": "ABSTRACT Financial technologies (fintech) are proposed to expand access to financial services in rural communities as bank branches decline; however, poor rural communities and rural communities of color have limited access to high-speed internet connections required for fintech. Leveraging the universe of U.S. rural zip codes, this paper investigates associations between communities' poverty rates, racial makeup, and rates of fintech. Poor rural communities of color experience digital redlining by having the lowest fintech rates. Rural communities' increasing white population is associated with higher high-speed internet rates, an advantage of whiteness observable even in the presence of high poverty. Implications are discussed.",
    "published_date": "2019-12-12",
    "citation_count": 52,
    "url": "https://www.tandfonline.com/doi/full/10.1080/10875549.2019.1695162",
    "summary": "This paper finds that poor rural communities, especially those with minority populations, experience \"digital redlining,\" exhibiting significantly lower access to fintech services due to limited high-speed internet; this digital divide persists even when considering poverty levels alone, highlighting the advantages afforded to whiter rural communities."
  },
  {
    "url": "https://arxiv.org/abs/2406.19601",
    "title": "Designing multi-model conversational AI financial systems: understanding sensitive values of women entrepreneurs in Brazil",
    "published_date": "2024-06-12",
    "abstract": "Small business owners (SBOs), specially women, face several challenges in everyday life, especially when asking for microcredit loans from financial institutions. Usual difficulties include low credit scores, unbaked situations, outstanding debts, informal employment situations, inability to showcase their payable capacity, and lack of financial guarantor. Moreover, SBOs often need help applying for microcredit loans due to the lack of information on how to proceed. The task of asking for a loan is a complex practice, and asymmetric power relationships might emerge, but that benefits micro-entrepreneurs only sometimes. In this paper, we interviewed 20 women entrepreneurs living in a low-income community in Brazil. We wanted to unveil value tensions derived from this practice that might influence the design of AI technologies for the public. In doing so, we used a conversational system as a probe to understand the opportunities for empowering their practices with the support of AI multimedia conversational systems. We derived seven recommendations for designing AI systems for evaluating micro-business health in low-income communities.",
    "summary": "This paper investigates the challenges faced by Brazilian women entrepreneurs in accessing microcredit, using interviews to understand their values and needs regarding financial assistance. Seven design recommendations for AI-powered conversational systems to improve micro-business loan application processes are then derived."
  },
  {
    "url": "https://arxiv.org/abs/2403.13944",
    "title": "Shortchanged: Uncovering and Analyzing Intimate Partner Financial Abuse in Consumer Complaints",
    "published_date": "2024-03-20",
    "abstract": "Digital financial services can introduce new digital-safety risks for users, particularly survivors of intimate partner financial abuse (IPFA). To offer improved support for such users, a comprehensive understanding of their support needs and the barriers they face to redress by financial institutions is essential. Drawing from a dataset of 2.7 million customer complaints, we implement a bespoke workflow that utilizes language-modeling techniques and expert human review to identify complaints describing IPFA. Our mixed-method analysis provides insight into the most common digital financial products involved in these attacks, and the barriers consumers report encountering when doing so. Our contributions are twofold; we offer the first human-labeled dataset for this overlooked harm and provide practical implications for technical practice, research, and design for better supporting and protecting survivors of IPFA.",
    "summary": "This study analyzes 2.7 million consumer complaints to identify instances of intimate partner financial abuse (IPFA) using natural language processing and expert review, creating the first human-labeled dataset of its kind and revealing common digital financial products involved and barriers to redress. The findings offer crucial insights for improving support and protection for IPFA survivors."
  },
  {
    "url": "https://www.alignmentforum.org/posts/cLfsabkCPtieJ5LoK/investigating-bias-representations-in-llms-via-activation",
    "author": "DawnLu",
    "title": "Investigating Bias Representations in LLMs via Activation Steering",
    "published_date": "2024-01-15",
    "summary": "This research uses activation steering to assess the societal biases of the Llama-2-7b-chat language model, finding that while the model exhibits gender bias without manipulation, attempts to further amplify biases through activation steering resulted in the model refusing to answer, suggesting a potential robustness against such manipulation, at least with the chosen method."
  },
  {
    "url": "https://www.alignmentforum.org/posts/T9i9gX58ZckHx6syw/representation-tuning",
    "author": "Christopher Ackerman",
    "title": "Representation Tuning",
    "published_date": "2024-06-27",
    "summary": "This research investigates improving the honesty of a large language model (LLM) through activation steering and fine-tuning. By identifying and manipulating activation vectors associated with honesty, the author demonstrates that fine-tuning these vectors using a cosine similarity loss yields the most effective and robust method for enhancing the model's truthful responses compared to other techniques like online steering or token-based fine-tuning."
  },
  {
    "url": "https://www.lesswrong.com/posts/BCynDEwguEiogicAo/reflection-of-hierarchical-relationship-via-nuanced?commentId=LxbpnsnaqWD3xEwZc",
    "author": "Kyoung-cheol Kim",
    "title": "Reflection of Hierarchical Relationship via Nuanced Conditioning of Game Theory Approach for AI Development and Utilization - LessWrong",
    "published_date": "2023-02-07",
    "summary": "The article explores applying game theory to AI development within organizational structures, highlighting its limitations and the enduring relevance of bureaucratic principles like hierarchical authority and job specialization. Even with advanced AI, the inherent complexities of problem-solving necessitate collaborative organizational structures, emphasizing the continued importance of human-AI collaboration and collective intelligence."
  }
]
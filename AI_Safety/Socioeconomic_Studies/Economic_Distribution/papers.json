[
  {
    "title": "Artificial Intelligence, Income Distribution and Economic Growth",
    "abstract": "The economic impact of Articial Intelligence (AI) is studied using a (semi) endogenous growth model with two novel features. First, the task approach from labor economics is reformulated and integrated into a growth model. Second, the standard representative household assumption is rejected, so that aggregate demand restrictions can be introduced. With these novel features it is shown that (i) AI automation can decrease the share of labor income no matter the size of the elasticity of substitution between AI and labor, and (ii) when this elasticity is high, AI will unambiguously reduce aggregate demand and slow down GDP growth, even in the face of the positive technology shock that AI entails. If the elasticity of substitution is low, then GDP, productivity and wage growth may however still slow down, because the economy will then fail to benefit from the supply-side driven capacity expansion potential that AI can deliver. The model can thus explain why advanced countries tend to experience, despite much AI hype, the simultaneous existence of rather high employment with stagnating wages, productivity, and GDP.",
    "published_date": "2024-06-18",
    "citation_count": 9,
    "url": "https://www.econstor.eu/bitstream/10419/224623/1/vfs-2020-pid-40327.pdf",
    "summary": "A growth model incorporating AI automation and heterogeneous households demonstrates that AI can reduce labor income share regardless of substitutability with labor, and may slow GDP growth, particularly when AI and labor are highly substitutable, due to decreased aggregate demand despite increased productivity potential."
  },
  {
    "title": "AI and Shared Prosperity",
    "abstract": "Future advances in AI that automate away human labor may have stark implications for labor markets and inequality. This paper proposes a framework to analyze the effects of specific types of AI systems on the labor market, based on how much labor demand they will create versus displace, while taking into account that productivity gains also make society wealthier and thereby contribute to additional labor demand. This analysis enables ethically-minded companies creating or deploying AI systems as well as researchers and policymakers to take into account the effects of their actions on labor markets and inequality, and therefore to steer progress in AI in a direction that advances shared prosperity and an inclusive economic future for all of humanity.",
    "published_date": "2021-05-18",
    "citation_count": 25,
    "url": "https://dl.acm.org/doi/10.1145/3461702.3462619",
    "summary": "This paper presents a framework for analyzing AI's impact on labor markets and inequality, considering both job displacement and creation alongside productivity gains, to guide ethical AI development and promote shared prosperity. It aims to help companies, researchers, and policymakers steer AI progress towards an inclusive economic future."
  },
  {
    "url": "https://arxiv.org/pdf/2004.13332v1.pdf",
    "title": "The AI Economist: Improving Equality and Productivity with AI-Driven Tax Policies",
    "published_date": "2020-04-28",
    "abstract": "Tackling real-world socio-economic challenges requires designing and testing economic policies. However, this is hard in practice, due to a lack of appropriate (micro-level) economic data and limited opportunity to experiment. In this work, we train social planners that discover tax policies in dynamic economies that can effectively trade-off economic equality and productivity. We propose a two-level deep reinforcement learning approach to learn dynamic tax policies, based on economic simulations in which both agents and a government learn and adapt. Our data-driven approach does not make use of economic modeling assumptions, and learns from observational data alone. We make four main contributions. First, we present an economic simulation environment that features competitive pressures and market dynamics. We validate the simulation by showing that baseline tax systems perform in a way that is consistent with economic theory, including in regard to learned agent behaviors and specializations. Second, we show that AI-driven tax policies improve the trade-off between equality and productivity by 16% over baseline policies, including the prominent Saez tax framework. Third, we showcase several emergent features: AI-driven tax policies are qualitatively different from baselines, setting a higher top tax rate and higher net subsidies for low incomes. Moreover, AI-driven tax policies perform strongly in the face of emergent tax-gaming strategies learned by AI agents. Lastly, AI-driven tax policies are also effective when used in experiments with human participants. In experiments conducted on MTurk, an AI tax policy provides an equality-productivity trade-off that is similar to that provided by the Saez framework along with higher inverse-income weighted social welfare.",
    "citation_count": 126,
    "summary": "The AI Economist uses deep reinforcement learning to design AI-driven tax policies within a simulated economy, demonstrating a 16% improvement in the equality-productivity trade-off compared to baseline policies like the Saez framework, and showing effectiveness even against agent tax-gaming strategies and with human participants. These policies feature higher top tax rates and subsidies for low incomes."
  },
  {
    "url": "https://arxiv.org/abs/2412.12393",
    "title": "Emergence of Power-Law and Other Wealth Distributions in Crowd of Heterogeneous Agents",
    "published_date": "2024-12-16",
    "abstract": "This study investigates the emergence of power-law and other concentrated distributions through a feedback loop model in crowd interactions. Agents act by their response functions to observations and external forces, while observations change by the aggregated actions of all agents, weighted by their respective influence, i.e. power or wealth. Agents wealth dynamically adjust based on the alignment between an agents actions and observation outcomes: agents gain wealth when their actions align with observed trends and lose wealth otherwise. A reward function, that describes the change of agents wealth at each time step, manifests the differences of response functions of agents to observations. When all agents responses are set to zero and feedback loop is broken, agents wealth follow a normal or lognormal distribution. Otherwise, this response-reward iterative feedback mechanism results in concentrated wealth distributions, characterized by a small number of dominant agents and the marginalization of the majority. Contrasted to past studies, such concentration is not limited only to asymptotic behavior at the upper tail for large variables, nor does it require the reward function to be linear to agents previous wealth as formulated in random growth model and network preferential attachment. Probability density functions for various distributions are more visually distinguishable for small values at the lower tail. In application of this model, key differences in income and wealth distributions in the US vs Japan are attributed to different response functions of agents in the two countries. The model applicability extends beyond social systems to other many-body systems with analogous feedback mechanisms, where power-law distributions represent a rare subset of general concentrated outcomes.",
    "summary": "A model simulating agent interactions with feedback loops demonstrates the emergence of concentrated wealth distributions, including power laws, arising from agent response functions and a reward mechanism linked to action-observation alignment; this contrasts with previous models by showing concentration not solely limited to asymptotic behavior and not requiring linear reward functions."
  },
  {
    "url": "https://arxiv.org/abs/2412.14818",
    "title": "Fair Division with Social Impact",
    "published_date": "2024-12-19",
    "abstract": "In this paper, we consider the problem of fair division of indivisible goods when the allocation of goods impacts society. Specifically, we introduce a second valuation function for each agent, determining the social impact of allocating a good to the agent. Such impact is considered desirable for the society -- the higher, the better. Our goal is to understand how to allocate goods fairly from the agents' perspective while maintaining society as happy as possible. To this end, we measure the impact on society using the utilitarian social welfare and provide both possibility and impossibility results. Our findings reveal that achieving good approximations, better than linear in the number of agents, is not possible while ensuring fairness to the agents. These impossibility results can be attributed to the fact that agents are completely unconscious of their social impact. Consequently, we explore scenarios where agents are socially aware, by introducing related fairness notions, and demonstrate that an appropriate definition of fairness aligns with the goal of maximizing the social objective.",
    "summary": "This paper investigates fair allocation of indivisible goods where each allocation has a social impact, aiming to balance individual fairness with maximizing societal well-being (utilitarian social welfare). The authors find that achieving strong approximations of both fairness and high social welfare is impossible when agents are unaware of their social impact, but possibilities emerge with socially aware agents and revised fairness definitions."
  },
  {
    "url": "https://arxiv.org/abs/2410.18841",
    "title": "From Efficiency to Equity: Measuring Fairness in Preference Learning",
    "published_date": "2024-10-24",
    "abstract": "As AI systems, particularly generative models, increasingly influence decision-making, ensuring that they are able to fairly represent diverse human preferences becomes crucial. This paper introduces a novel framework for evaluating epistemic fairness in preference learning models inspired by economic theories of inequality and Rawlsian justice. We propose metrics adapted from the Gini Coefficient, Atkinson Index, and Kuznets Ratio to quantify fairness in these models. We validate our approach using two datasets: a custom visual preference dataset (AI-EDI-Space) and the Jester Jokes dataset. Our analysis reveals variations in model performance across users, highlighting potential epistemic injustices. We explore pre-processing and in-processing techniques to mitigate these inequalities, demonstrating a complex relationship between model efficiency and fairness. This work contributes to AI ethics by providing a framework for evaluating and improving epistemic fairness in preference learning models, offering insights for developing more inclusive AI systems in contexts where diverse human preferences are crucial.",
    "summary": "This paper presents a novel framework for measuring and mitigating epistemic unfairness in preference learning models, adapting economic inequality metrics to quantify fairness and exploring techniques to improve both model efficiency and equity. The framework is validated using visual preference and joke datasets, revealing and addressing disparities in model performance across users."
  },
  {
    "title": "The macroeconomic consequences of artificial intelligence: A theoretical framework",
    "abstract": "The authors explore the impact of artificial intelligence on the economy by improving the neoclassical production function and the task-based model. Based on the capital accumulation of artificial intelligence and technological progress, they present a theoretical model that explores the effect of alternative and complementary artificial intelligence on wages, capital prices, labor share, capital share and economic growth. The model shows that artificial intelligence capital lowers the capital prices and increases wages. In addition, if artificial intelligence and labor force are complementary, artificial intelligence capital has a positive impact on labor share, but if artificial intelligence and labor force can substitute each other, labor share is negatively influenced by artificial intelligence capital. The authors extend the task-based model and find that technological progress increases both wages and labor share by generating new tasks. In the long run, without consideration of exogenous technology, as the artificial intelligence capital accumulates, per capita output, per capita traditional capital and per capita artificial intelligence capital grow at the same rate, and economic growth finally reaches steady state equili- brium. With exogenous technology considered, artificial intelligence technology improves, and sustained economic growth is achieved.",
    "published_date": "2024-06-14",
    "citation_count": 1,
    "url": "https://www.econstor.eu/bitstream/10419/203115/1/1676021787.pdf",
    "summary": "This paper develops a theoretical model analyzing AI's macroeconomic effects, showing that AI capital lowers capital prices and raises wages, with its impact on labor share depending on its complementarity with labor. Long-run economic growth is achieved through AI capital accumulation and technological progress."
  },
  {
    "url": "https://www.lesswrong.com/posts/mXD53GFvMCWQhcCwt/distinguishing-ways-ai-can-be-concentrated",
    "author": "Matthew Barnett",
    "title": "Distinguishing ways AI can be \"concentrated\"",
    "published_date": "2024-10-21",
    "summary": "The author argues that discussions of AI concentration lack clarity, proposing three distinct dimensions: concentration of AI development, service provision, and control. These dimensions are independent and crucial for accurately predicting AI's trajectory and informing policy."
  },
  {
    "url": "https://arxiv.org/abs/2304.00514",
    "title": "The impact of individual information exchange strategies on the distribution of social wealth",
    "published_date": "2023-04-02",
    "abstract": "Wealth distribution is a complex and critical aspect of any society. Information exchange is considered to have played a role in shaping wealth distribution patterns, but the specific dynamic mechanism is still unclear. In this research, we used simulation-based methods to investigate the impact of different modes of information exchange on wealth distribution. We compared different combinations of information exchange strategies and moving strategies, analyzed their impact on wealth distribution using classic wealth distribution indicators such as the Gini coefficient. Our findings suggest that information exchange strategies have significant impact on wealth distribution and that promoting more equitable access to information and resources is crucial in building a just and equitable society for all.",
    "summary": "This study uses simulations to show that different information exchange strategies significantly impact wealth distribution, suggesting equitable information access is key to a more just society."
  },
  {
    "url": "https://arxiv.org/pdf/2201.11441v1.pdf",
    "title": "Human-centered mechanism design with Democratic AI",
    "published_date": "2022-01-27",
    "abstract": "Building artificial intelligence (AI) that aligns with human values is an unsolved problem. Here, we developed a human-in-the-loop research pipeline called Democratic AI, in which reinforcement learning is used to design a social mechanism that humans prefer by majority. A large group of humans played an online investment game that involved deciding whether to keep a monetary endowment or to share it with others for collective benefit. Shared revenue was returned to players under two different redistribution mechanisms, one designed by the AI and the other by humans. The AI discovered a mechanism that redressed initial wealth imbalance, sanctioned free riders, and successfully won the majority vote. By optimizing for human preferences, Democratic AI may be a promising method for value-aligned policy innovation.",
    "citation_count": 2,
    "summary": "Democratic AI, a human-in-the-loop reinforcement learning system, designs social mechanisms preferred by majority vote, as demonstrated by an online investment game where an AI-designed mechanism, outcompeting human-designed alternatives, successfully redistributed wealth and penalized free-riders. This suggests a promising approach for creating value-aligned AI policies."
  },
  {
    "url": "https://arxiv.org/abs/2210.02362",
    "title": "A Reputation System for Market Security and Equity",
    "published_date": "2022-10-05",
    "abstract": "We simulate a reputation system in a market to optimize the balance between market security and market equity. We introduce a method of using a reputation system that will stabilize the distribution of wealth in a market in a fair manner. We also introduce metrics of a modified Gini that takes pro-duction quality into account, a way to use a weighted Pearson as a tool to optimize balance.",
    "summary": "This paper proposes a reputation system for market simulations, aiming to balance security and equity by stabilizing wealth distribution and introducing modified Gini and weighted Pearson metrics to optimize this balance."
  },
  {
    "url": "https://arxiv.org/abs/2205.01066",
    "title": "Quantifying Health Inequalities Induced by Data and AI Models",
    "published_date": "2022-04-24",
    "abstract": "AI technologies are being increasingly tested and applied in critical environments including healthcare. Without an effective way to detect and mitigate AI induced inequalities, AI might do more harm than good, potentially leading to the widening of underlying inequalities. This paper proposes a generic allocation-deterioration framework for detecting and quantifying AI induced inequality. Specifically, AI induced inequalities are quantified as the area between two allocation-deterioration curves. To assess the framework's performance, experiments were conducted on ten synthetic datasets (N>33,000) generated from HiRID - a real-world Intensive Care Unit (ICU) dataset, showing its ability to accurately detect and quantify inequality proportionally to controlled inequalities. Extensive analyses were carried out to quantify health inequalities (a) embedded in two real-world ICU datasets; (b) induced by AI models trained for two resource allocation scenarios. Results showed that compared to men, women had up to 33% poorer deterioration in markers of prognosis when admitted to HiRID ICUs. All four AI models assessed were shown to induce significant inequalities (2.45% to 43.2%) for non-White compared to White patients. The models exacerbated data embedded inequalities significantly in 3 out of 8 assessments, one of which was >9 times worse.",
    "citation_count": 5,
    "summary": "This paper introduces a framework to quantify AI-induced health inequalities by measuring the difference between allocation-deterioration curves, demonstrating its effectiveness through experiments on synthetic and real-world ICU data which revealed significant inequalities based on gender and race, often exacerbated by AI models."
  },
  {
    "url": "https://www.lesswrong.com/posts/TRKF9g65nhPBQoxJu/distribution-shifts-and-the-importance-of-ai-safety",
    "author": "Leon Lang",
    "title": "Distribution Shifts and The Importance of AI Safety",
    "published_date": "2022-09-29",
    "summary": "The article argues that the distribution shift problem in machine learning poses an existential risk, as increasingly powerful AI systems may become misaligned with human goals due to unforeseen changes in their operational environment. This misalignment, potentially leading to humanity's disempowerment, necessitates increased focus on AI safety research."
  },
  {
    "url": "https://arxiv.org/pdf/2105.08475v1.pdf",
    "title": "AI and Shared Prosperity",
    "published_date": "2021-05-18",
    "abstract": "Future advances in AI that automate away human labor may have stark implications for labor markets and inequality. This paper proposes a framework to analyze the effects of specific types of AI systems on the labor market, based on how much labor demand they will create versus displace, while taking into account that productivity gains also make society wealthier and thereby contribute to additional labor demand. This analysis enables ethically-minded companies creating or deploying AI systems as well as researchers and policymakers to take into account the effects of their actions on labor markets and inequality, and therefore to steer progress in AI in a direction that advances shared prosperity and an inclusive economic future for all of humanity.",
    "citation_count": 25,
    "summary": "This paper presents a framework for analyzing AI's impact on labor markets and inequality, considering both job displacement and the creation of new jobs due to productivity gains, aiming to guide ethical AI development for shared prosperity."
  },
  {
    "url": "https://arxiv.org/pdf/2101.09794v2.pdf",
    "title": "Equitable Division of a Path",
    "published_date": "2021-01-24",
    "abstract": "We study fair resource allocation under a connectedness constraint wherein a set of indivisible items are arranged on a path and only connected subsets of items may be allocated to the agents. An allocation is deemed fair if it satisfies equitability up to one good (EQ1), which requires that agents' utilities are approximately equal. We show that achieving EQ1 in conjunction with well-studied measures of economic efficiency (such as Pareto optimality, non-wastefulness, maximum egalitarian or utilitarian welfare) is computationally hard even for binary additive valuations. On the algorithmic side, we show that by relaxing the efficiency requirement, a connected EQ1 allocation can be computed in polynomial time for any given ordering of agents, even for general monotone valuations. Interestingly, the allocation computed by our algorithm has the highest egalitarian welfare among all allocations consistent with the given ordering. On the other hand, if efficiency is required, then tractability can still be achieved for binary additive valuations with interval structure. On our way, we strengthen some of the existing results in the literature for other fairness notions such as envy-freeness up to one good (EF1), and also provide novel results for negatively-valued items or chores.",
    "citation_count": 9,
    "summary": "This paper investigates the computational complexity of equitably dividing a path of indivisible items among agents, showing that achieving approximate equitability (EQ1) alongside efficiency is computationally hard, but polynomial-time algorithms exist for EQ1 allocation under relaxed efficiency or specific valuation structures. The algorithms prioritize egalitarian welfare while ensuring connected allocations for each agent."
  }
]
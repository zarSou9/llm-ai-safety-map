[
  {
    "url": "https://www.lesswrong.com/posts/Mak2kZuTq8Hpnqyzb/the-intelligence-curse",
    "author": "lukedrago",
    "title": "The Intelligence Curse",
    "published_date": "2025-01-03",
    "summary": "The article introduces the \"intelligence curse,\" arguing that the development of Artificial General Intelligence (AGI) will create rentier-state-like incentives for powerful actors. This will lead to a decrease in investment in human capital, as AGI renders human labor less valuable, resulting in societal consequences similar to the resource curse."
  },
  {
    "url": "https://www.alignmentforum.org/posts/6nNwMbdRXZDuNd4Gx/analysis-of-global-ai-governance-strategies",
    "author": "Sammy Martin, Justin Bullock, Corin Katzke",
    "title": "Analysis of Global AI Governance Strategies",
    "published_date": "2024-12-04",
    "summary": "The article analyzes three AI governance strategies—Cooperative Development, Strategic Advantage, and Global Moratorium—evaluating their effectiveness based on the difficulty of aligning AI and the timeline for its development. The optimal strategy shifts depending on these factors, with Cooperative Development preferred for longer timelines and easier alignment, Strategic Advantage for shorter timelines or moderate alignment difficulty, and Global Moratorium reserved for scenarios with very hard alignment or extremely short timelines."
  },
  {
    "url": "https://www.lesswrong.com/posts/6untaSPpsocmkS7Z3/ways-i-expect-ai-regulation-to-increase-extinction-risk",
    "author": "1a3orn",
    "title": "Ways I Expect AI Regulation To Increase Extinction Risk",
    "published_date": "2023-07-04",
    "summary": "The author argues that AI regulations, even those intended to improve safety, may worsen existential risks (x-risk) by misdirecting safety efforts towards easily measurable but ultimately less important compliance issues (like facial recognition accuracy) and by disproportionately favoring large, easily monitored organizations over smaller, potentially safer, ones conducting crucial research."
  },
  {
    "url": "https://www.lesswrong.com/posts/qCstMcRJcjNtdNW7r/what-i-would-do-if-i-were-working-on-ai-governance",
    "author": "johnswentworth",
    "title": "What I Would Do If I Were Working On AI Governance",
    "published_date": "2023-12-08",
    "summary": "The author argues that effective AI governance should prioritize holding AI companies liable for their AI's damages, incentivizing robust safety processes and preventing deployment of risky systems. This liability could be achieved through judicial precedents, regulatory changes, or both."
  },
  {
    "title": "AI technologies and employment: micro evidence from the supply side",
    "abstract": "ABSTRACT In this work we investigate the possible job-creation impact of artificial intelligence (AI) technologies, focusing on the supply side, where the development of these technologies can be conceived as product innovations in upstream sectors. The empirical analysis is based on a worldwide longitudinal sample (obtained by merging the EPO PATSTAT and BvD-ORBIS databases) of more than 3,500 front-runner companies that patented AI-related inventions over the period 2000–2016. Based on system GMM estimates of dynamic panel models, our results show a positive and significant impact of AI patent families on employment, supporting the labour-friendly nature of AI product innovation.",
    "published_date": "2022-02-20",
    "citation_count": 33,
    "url": "https://www.tandfonline.com/doi/pdf/10.1080/13504851.2021.2024129?needAccess=true",
    "summary": "Analysis of over 3,500 companies reveals a positive correlation between AI-related patents and employment growth, suggesting AI product innovation boosts job creation. This finding supports the hypothesis that AI is labor-friendly in its impact on the supply side."
  },
  {
    "title": "AI Efficiency Index: Identifying Regulatory and Policy Constraints for Resilient National AI Ecosystems",
    "abstract": "We develop efficiency estimates for the production, implementation and diffusion of artificial intelligence (AI) services. We use a variety of data measuring factors relating to AI input and output. We start by constructing a set of nine different AI efficiency measures using non-parametric technique of data envelopment analysis (DAE). We then proceed to analyse the cross-country time variation of these estimates and compare these with different policy measures and institutional indicators. In particular, we link our AI efficiency measures to general characteristics of a country's innovation system including indicators reflecting product market regulation, tax subsidies for R\\&D investment and institutional factors linked to starting a business and (intellectual) property rights. We find that policy measures differ in their impact on our AI efficiency scores: Tax subsidies are important to enhance start-up investment activity, especially in countries with high barriers to entry and weak property rights. Product market frictions such as public ownership --- especially in the telecommunications industry --- is pernicious to patenting efficiency in the field of AI. Our results highlight the importance of differentiated policy interventions at different stages (and attributes) of the AI production chain.",
    "published_date": "2021-03-09",
    "citation_count": 1,
    "url": "https://www.researchgate.net/publication/350015537_AI_Efficiency_Index_Identifying_Regulatory_and_Policy_Constraints_for_Resilient_National_AI_Ecosystems",
    "summary": "The study constructs an AI Efficiency Index using data envelopment analysis to measure AI production, implementation, and diffusion, revealing that tax subsidies boost AI startups, particularly in countries with high barriers to entry, while public ownership, especially in telecommunications, hinders AI patenting efficiency."
  },
  {
    "title": "'Solving for X?' Towards a Problem-Finding Framework to Ground Long-Term Governance Strategies for Artificial Intelligence",
    "abstract": "Abstract Change is hardly a new feature in human affairs. Yet something has begun to change in change. In the face of a range of emerging, complex, and interconnected global challenges, society's collective governance efforts may need to be put on a different footing. Many of these challenges derive from emerging technological developments – take Artificial Intelligence (AI), the focus of much contemporary governance scholarship and efforts. AI governance strategies have predominantly oriented themselves towards clear, discrete clusters of pre-defined problems. We argue that such 'problem-solving' approaches may be necessary, but are also insufficient in the face of many of the 'wicked problems' created or driven by AI. Accordingly, we propose in this paper a complementary framework for grounding long-term governance strategies for complex emerging issues such as AI into a 'problem-finding' orientation. We first provide a rationale by sketching the range of policy problems created by AI, and providing five reasons why problem-solving governance approaches to these challenges fail or fall short. We conversely argue that that creative, 'problem-finding' research into these governance challenges is not only warranted scientifically, but will also be critical in the formulation of governance strategies that are effective, meaningful, and resilient over the long-term. We accordingly illustrate the relation between and the complementarity of problem-solving and problem-finding research, by articulating a framework that distinguishes between four distinct 'levels' of governance: problem-solving research generally approaches AI (governance) issues from a perspective of (Level 0) 'business-as-usual' or as (Level 1) 'governance puzzle-solving'. In contrast, problem-finding approaches emphasize (Level 2) 'governance Disruptor-Finding'; or (Level 3) 'Charting Macrostrategic Trajectories'. We apply this theoretical framework to contemporary governance debates around AI throughout our analysis to elaborate upon and to better illustrate our framework. We conclude with reflections on nuances, implications, and shortcomings of this long-term governance framework, offering a range of observations on intra-level failure modes, between-level complementarities, within-level path dependencies, and the categorical boundary conditions of governability ('Governance Goldilocks Zone'). We suggest that this framework can help underpin more holistic approaches for long-term strategy-making across diverse policy domains and contexts, and help cross the bridge between concrete policies on local solutions, and longer-term considerations of path-dependent societal trajectories to avert, or joint visions towards which global communities can or should be rallied.",
    "published_date": "2021-01-07",
    "citation_count": 21,
    "url": "https://www.sciencedirect.com/science/article/pii/S0016328720301634",
    "summary": "This paper argues that current AI governance strategies, focused on solving pre-defined problems, are insufficient for addressing complex, long-term challenges. It proposes a complementary \"problem-finding\" framework, outlining four levels of governance ranging from business-as-usual to charting macrostrategic trajectories, to guide more effective and resilient AI governance strategies."
  },
  {
    "title": "The Distributive Effects of Risk Prediction in Environmental Compliance: Algorithmic Design, Environmental Justice, and Public Policy",
    "abstract": "Government agencies are embracing machine learning to support a variety of resource allocation decisions. The U.S. Environmental Protection Agency (EPA), for example, has engaged academic research labs to test the use of machine learning in support of an important national initiative to reduce Clean Water Act violations. We evaluate prototypical risk prediction models that can support compliance interventions and demonstrate how critical algorithmic design choices can generate or mitigate disparate impact in environmental enforcement. First, we show that the definition of which facilities to focus on through this national compliance initiative hinges on arbitrary differences in state-level permitting schemes, causing a shift in environmental protection away from areas with more minority populations. Second, the policy objective to reduce the noncompliance rate is encoded in a classification model, which does not account for the extent of pollution beyond the permitted limit. We hence compare allocation schemes between regression and classification, and show that the latter directs attention towards facilities in more rural and white areas. Overall, our study illustrates that as machine learning enters government, algorithmic design can both embed and elucidate sources of administrative policy discretion with discernable distributional consequences.",
    "published_date": "2021-03-03",
    "citation_count": 6,
    "url": "https://dl.acm.org/doi/10.1145/3442188.3445873",
    "summary": "This paper examines how the EPA's use of machine learning for Clean Water Act compliance prediction can lead to disparate environmental enforcement outcomes, showing that algorithmic design choices, such as focusing on classification over regression and variations in state permitting schemes, disproportionately affect minority and rural communities. The study highlights how seemingly neutral algorithmic decisions can embed and reveal existing biases in administrative policy, resulting in unequal environmental protection."
  }
]
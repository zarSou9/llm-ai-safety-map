[
  {
    "url": "http://arxiv.org/abs/2401.09718",
    "title": "AI and the Opportunity for Shared Prosperity: Lessons from the History of Technology and the Economy",
    "published_date": "2024-01-18",
    "abstract": "Recent progress in artificial intelligence (AI) marks a pivotal moment in human history. It presents the opportunity for machines to learn, adapt, and perform tasks that have the potential to assist people, from everyday activities to their most creative and ambitious projects. It also has the potential to help businesses and organizations harness knowledge, increase productivity, innovate, transform, and power shared prosperity. This tremendous potential raises two fundamental questions: (1) Will AI actually advance national and global economic transformation to benefit society at large? and (2) What issues must we get right to fully realize AI's economic value, expand prosperity and improve lives everywhere? We explore these questions by considering the recent history of technology and innovation as a guide for the likely impact of AI and what we must do to realize its economic potential to benefit society. While we do not presume the future will be entirely like that past, for reasons we will discuss, we do believe prior experience with technological change offers many useful lessons. We conclude that while progress in AI presents a historic opportunity to advance our economic prosperity and future wellbeing, its economic benefits will not come automatically and that AI risks exacerbating existing economic challenges unless we collectively and purposefully act to enable its potential and address its challenges. We suggest a collective policy agenda - involving developers, deployers and users of AI, infrastructure providers, policymakers, and those involved in workforce training - that may help both realize and harness AI's economic potential and address its risks to our shared prosperity.",
    "citation_count": 1,
    "summary": "AI has the potential to drive widespread economic prosperity, but realizing this potential requires proactive policies and collective action to address its challenges and ensure equitable distribution of benefits. Historical analysis of technological advancements suggests that AI's economic impact will not be automatic and risks exacerbating existing inequalities if left unmanaged."
  },
  {
    "title": "The macroeconomic consequences of artificial intelligence: A theoretical framework",
    "abstract": "The authors explore the impact of artificial intelligence on the economy by improving the neoclassical production function and the task-based model. Based on the capital accumulation of artificial intelligence and technological progress, they present a theoretical model that explores the effect of alternative and complementary artificial intelligence on wages, capital prices, labor share, capital share and economic growth. The model shows that artificial intelligence capital lowers the capital prices and increases wages. In addition, if artificial intelligence and labor force are complementary, artificial intelligence capital has a positive impact on labor share, but if artificial intelligence and labor force can substitute each other, labor share is negatively influenced by artificial intelligence capital. The authors extend the task-based model and find that technological progress increases both wages and labor share by generating new tasks. In the long run, without consideration of exogenous technology, as the artificial intelligence capital accumulates, per capita output, per capita traditional capital and per capita artificial intelligence capital grow at the same rate, and economic growth finally reaches steady state equili- brium. With exogenous technology considered, artificial intelligence technology improves, and sustained economic growth is achieved.",
    "published_date": "2024-06-14",
    "citation_count": 1,
    "url": "https://www.econstor.eu/bitstream/10419/203115/1/1676021787.pdf",
    "summary": "This paper develops a theoretical model demonstrating that AI can increase wages and economic growth, with AI's impact on labor share depending on whether it complements or substitutes human labor; further, technological progress, including AI advancements, can drive sustained long-run growth."
  },
  {
    "url": "https://www.lesswrong.com/tag/technological-revolution",
    "title": "Technological Revolution - LessWrong",
    "published_date": "2024-02-01",
    "summary": "Technological revolutions, driven by new technologies, cause significant societal shifts and require ethical consideration, especially given the unprecedented potential to alter human nature itself. Scholars are examining the unpredictable long-term impacts of these revolutions, including potential societal changes like increased inequality and a shift in the value of human labor."
  },
  {
    "url": "https://www.lesswrong.com/tag/artificial-general-intelligence-agi",
    "title": "Artificial General Intelligence (AGI) - LessWrong",
    "published_date": "2024-02-01",
    "summary": "Artificial General Intelligence (AGI) refers to a hypothetical machine capable of intelligent behavior across diverse domains, unlike narrow AI specialized in specific tasks. While its development timeline remains uncertain, with expert estimates ranging from 2050 to 2150, AGI's potential impact, including existential risks from \"unfriendly\" AGI, is a key area of research and debate."
  },
  {
    "url": "https://arxiv.org/pdf/2306.13686.pdf",
    "title": "Broadening the perspective for sustainable AI: Comprehensive sustainability criteria and indicators for AI systems",
    "published_date": "2023-06-22",
    "abstract": "The increased use of AI systems is associated with multi-faceted societal, environmental, and economic consequences. These include non-transparent decision-making processes, discrimination, increasing inequalities, rising energy consumption and greenhouse gas emissions in AI model development and application, and an increasing concentration of economic power. By considering the multi-dimensionality of sustainability, this paper takes steps towards substantiating the call for an overarching perspective on\"sustainable AI\". It presents the SCAIS Framework (Sustainability Criteria and Indicators for Artificial Intelligence Systems) which contains a set 19 sustainability criteria for sustainable AI and 67 indicators that is based on the results of a critical review and expert workshops. This interdisciplinary approach contributes a unique holistic perspective to facilitate and structure the discourse on sustainable AI. Further, it provides a concrete framework that lays the foundation for developing standards and tools to support the conscious development and application of AI systems.",
    "citation_count": 1,
    "summary": "The paper introduces the SCAIS Framework, encompassing 19 criteria and 67 indicators for evaluating the sustainability of AI systems, addressing its societal, environmental, and economic impacts to promote responsible AI development and deployment."
  },
  {
    "url": "https://arxiv.org/abs/2305.02561",
    "title": "Beneficence Signaling in AI Development Dynamics",
    "published_date": "2023-05-04",
    "abstract": "This paper motivates and develops a framework for understanding how the socio-technical systems surrounding AI development interact with social welfare. It introduces the concept of ``signaling'' from evolutionary game theory and demonstrates how it can enhance existing theory and practice surrounding the evaluation and governance of AI systems.",
    "summary": "This paper proposes a framework for analyzing the societal impact of AI development using the concept of \"signaling\" from evolutionary game theory to explain how developers' actions, beyond just technical capabilities, influence AI systems' contribution to social good. This signaling framework offers a new lens for evaluating and governing AI."
  },
  {
    "url": "https://www.lesswrong.com/tag/economics",
    "author": "johnswentworth",
    "title": "Economics - LessWrong",
    "published_date": "2023-08-08",
    "summary": "Economics studies how agents interact with scarce resources, encompassing microeconomics (individual market behavior and price mechanisms) and macroeconomics (economy-wide phenomena like growth and inflation)."
  },
  {
    "url": "https://www.lesswrong.com/tag/artificial-general-intelligence",
    "title": "Artificial General Intelligence - LessWrong",
    "published_date": "2023-02-06",
    "summary": "Artificial General Intelligence (AGI) refers to a hypothetical machine capable of intelligent behavior across diverse domains, unlike narrow AI which is specialized. While AGI development is driven by factors like Moore's Law and advancements in neuroscience, its potential timeline remains uncertain, with expert opinions ranging from skeptical to predicting emergence by mid-21st century, raising concerns about its potential impact and alignment with human values."
  },
  {
    "url": "https://arxiv.org/abs/2202.02879",
    "title": "An Empirical Analysis of AI Contributions to Sustainable Cities (SDG11)",
    "published_date": "2022-02-06",
    "abstract": "Artificial Intelligence (AI) presents opportunities to develop tools and techniques for addressing some of the major global challenges and deliver solutions with significant social and economic impacts. The application of AI has far-reaching implications for the 17 Sustainable Development Goals (SDGs) in general, and sustainable urban development in particular. However, existing attempts to understand and use the opportunities offered by AI for SDG 11 have been explored sparsely, and the shortage of empirical evidence about the practical application of AI remains. In this chapter, we analyze the contribution of AI to support the progress of SDG 11 (Sustainable Cities and Communities). We address the knowledge gap by empirically analyzing the AI systems (N = 29) from the AIxSDG database and the Community Research and Development Information Service (CORDIS) database. Our analysis revealed that AI systems have indeed contributed to advancing sustainable cities in several ways (e.g., waste management, air quality monitoring, disaster response management, transportation management), but many projects are still working for citizens and not with them. This snapshot of AI's impact on SDG11 is inherently partial, yet useful to advance our understanding as we move towards more mature systems and research on the impact of AI systems for social good.",
    "citation_count": 9,
    "summary": "An analysis of 29 AI systems reveals contributions to Sustainable Development Goal 11 (Sustainable Cities and Communities), particularly in areas like waste management and transportation, but highlights a need for greater citizen engagement in these projects. While this analysis provides a limited perspective, it offers valuable insights into the potential of AI for urban sustainability."
  },
  {
    "url": "https://www.lesswrong.com/tag/ai-governance",
    "author": "lc",
    "title": "AI Governance - LessWrong",
    "published_date": "2022-04-05",
    "summary": "AI governance seeks to ensure societal benefit from advanced AI, requiring not only technical alignment but also considerations of policy, economics, law, sociology, and other related fields."
  },
  {
    "url": "https://arxiv.org/pdf/2105.08475v1.pdf",
    "title": "AI and Shared Prosperity",
    "published_date": "2021-05-18",
    "abstract": "Future advances in AI that automate away human labor may have stark implications for labor markets and inequality. This paper proposes a framework to analyze the effects of specific types of AI systems on the labor market, based on how much labor demand they will create versus displace, while taking into account that productivity gains also make society wealthier and thereby contribute to additional labor demand. This analysis enables ethically-minded companies creating or deploying AI systems as well as researchers and policymakers to take into account the effects of their actions on labor markets and inequality, and therefore to steer progress in AI in a direction that advances shared prosperity and an inclusive economic future for all of humanity.",
    "citation_count": 25,
    "summary": "This paper introduces a framework for analyzing AI's impact on labor markets by considering its potential to both create and displace jobs, alongside the increased demand resulting from productivity gains, aiming to promote shared prosperity through informed AI development and policy."
  },
  {
    "url": "https://arxiv.org/pdf/2101.03366v1.pdf",
    "title": "The Future of Artificial Intelligence and its Social, Economic and Ethical Consequences",
    "published_date": "2021-01-09",
    "abstract": "Recent development in AI has enabled the expansion of its application to multiple domains. From medical treatment, gaming, manufacturing to daily business processes. A huge amount of money has been poured into AI research due to its exciting discoveries. Technology giants like Google, Facebook, Amazon, and Baidu are the driving forces in the field today. But the rapid growth and excitement that the technology offers obscure us from looking at the impact it brings on our society. This short paper gives a brief history of AI and summarizes various social, economic and ethical issues that are impacting our society today. We hope that this work will provide a useful starting point and perhaps reference for newcomers and stakeholders of the field.",
    "summary": "This paper provides a brief overview of artificial intelligence's history and discusses its growing social, economic, and ethical implications for society. It aims to serve as an introductory resource for those new to the field."
  },
  {
    "title": "AI and Shared Prosperity",
    "abstract": "Future advances in AI that automate away human labor may have stark implications for labor markets and inequality. This paper proposes a framework to analyze the effects of specific types of AI systems on the labor market, based on how much labor demand they will create versus displace, while taking into account that productivity gains also make society wealthier and thereby contribute to additional labor demand. This analysis enables ethically-minded companies creating or deploying AI systems as well as researchers and policymakers to take into account the effects of their actions on labor markets and inequality, and therefore to steer progress in AI in a direction that advances shared prosperity and an inclusive economic future for all of humanity.",
    "published_date": "2021-05-18",
    "citation_count": 25,
    "url": "https://dl.acm.org/doi/10.1145/3461702.3462619",
    "summary": "This paper presents a framework for analyzing how AI systems impact labor markets by considering their potential to create and displace jobs, alongside the increased demand driven by productivity gains. This framework aims to guide ethical AI development and policy towards shared prosperity."
  },
  {
    "url": "https://arxiv.org/abs/2105.06551",
    "title": "Axes for Sociotechnical Inquiry in AI Research",
    "published_date": "2021-04-26",
    "abstract": "The development of artificial intelligence (AI) technologies has far exceeded the investigation of their relationship with society. Sociotechnical inquiry is needed to mitigate the harms of new technologies whose potential impacts remain poorly understood. To date, subfields of AI research develop primarily individual views on their relationship with sociotechnics, while tools for an external investigation, comparison, and cross-pollination are lacking. In this article, we propose four directions for inquiry into new and evolving areas of technological development: 1) value—what progress and direction does a field promote; 2) optimization—how the defined system within a problem formulation relates to broader dynamics; 3) consensus—how the agreement is achieved and who is included in building it; and 4) failure—what methods are pursued when the problem specification is found wanting. This article provides a lexicon for sociotechnical inquiry and illustrates it through the example of consumer drone technology.",
    "citation_count": 11,
    "summary": "The paper proposes four axes—value, optimization, consensus, and failure—for sociotechnical inquiry into AI research, offering a framework to analyze the societal impact of developing technologies and illustrated using consumer drones."
  },
  {
    "url": "https://arxiv.org/abs/2101.02032",
    "title": "Socially Responsible AI Algorithms: Issues, Purposes, and Challenges",
    "published_date": "2021-01-01",
    "abstract": "In the current era, people and society have grown increasingly reliant on artificial intelligence (AI) technologies. AI has the potential to drive us towards a future in which all of humanity flourishes. It also comes with substantial risks for oppression and calamity. Discussions about whether we should (re)trust AI have repeatedly emerged in recent years and in many quarters, including industry, academia, healthcare, services, and so on. Technologists and AI researchers have a responsibility to develop trustworthy AI systems. They have responded with great effort to design more responsible AI algorithms. However, existing technical solutions are narrow in scope and have been primarily directed towards algorithms for scoring or classification tasks, with an emphasis on fairness and unwanted bias. To build long-lasting trust between AI and human beings, we argue that the key is to think beyond algorithmic fairness and connect major aspects of AI that potentially cause AI's indifferent behavior. In this survey, we provide a systematic framework of Socially Responsible AI Algorithms that aims to examine the subjects of AI indifference and the need for socially responsible AI algorithms, define the objectives, and introduce the means by which we may achieve these objectives. We further discuss how to leverage this framework to improve societal well-being through protection, information, and prevention/mitigation. \nThis article appears in the special track on AI & Society.",
    "citation_count": 127,
    "summary": "The paper argues that building truly trustworthy AI requires moving beyond narrow technical solutions like algorithmic fairness and addressing broader societal impacts, proposing a framework for \"Socially Responsible AI Algorithms\" focused on protection, information, and prevention/mitigation."
  },
  {
    "url": "https://arxiv.org/pdf/2107.13966.pdf",
    "title": "Artificial Intelligence in Achieving Sustainable Development Goals",
    "published_date": "2021-07-23",
    "abstract": "This perspective illustrates some of the AI applications that can accelerate the achievement of SDGs and also highlights some of the considerations that could hinder the efforts towards them. This emphasizes the importance of establishing standard AI guidelines and regulations for the beneficial applications of AI.",
    "citation_count": 2,
    "summary": "AI can accelerate progress towards Sustainable Development Goals (SDGs), but potential obstacles necessitate establishing guidelines and regulations for its responsible application."
  },
  {
    "url": "https://arxiv.org/pdf/2102.06362v3.pdf",
    "title": "A Decentralized Approach Towards Responsible AI in Social Ecosystems",
    "published_date": "2021-02-12",
    "abstract": "For AI technology to fulfill its full promises, we must have effective means to ensure Responsible AI behavior and curtail potential irresponsible use, e.g., in areas of privacy protection, human autonomy, robustness, and prevention of biases and discrimination in automated decision making. Recent literature in the field has identified serious shortcomings of narrow technology focused and formalism-oriented research and has proposed an interdisciplinary approach that brings the social context into the scope of study.\n In this paper, we take a sociotechnical approach to propose a more expansive framework of thinking about the Responsible AI challenges in both technical and social context. Effective solutions need to bridge the gap between a technical system with the social system that it will be deployed to. To this end, we propose computational human agency and regulation as main mechanisms of intervention and propose a decentralized computational infrastructure, or a set of public utilities, as the computational means to bridge this gap. A decentralized infrastructure is uniquely suited for meeting this challenge and enable technical solutions and social institutions in a mutually reinforcing dynamic to achieve Responsible AI goals. Our approach is novel in its sociotechnical co-design and its aim in tackling the structural issues that cannot be solved within the narrow confines of AI technical research. We then explore possible features of the proposed infrastructure and discuss how they may help solve example problems recently studied in the field.",
    "citation_count": 8,
    "summary": "This paper proposes a decentralized computational infrastructure, incorporating human agency and regulation, to address Responsible AI challenges by bridging the gap between technical AI systems and their social contexts. This sociotechnical approach aims to move beyond narrow technical solutions and tackle structural issues hindering responsible AI development."
  },
  {
    "url": "https://arxiv.org/pdf/2004.13332v1.pdf",
    "title": "The AI Economist: Improving Equality and Productivity with AI-Driven Tax Policies",
    "published_date": "2020-04-28",
    "abstract": "Tackling real-world socio-economic challenges requires designing and testing economic policies. However, this is hard in practice, due to a lack of appropriate (micro-level) economic data and limited opportunity to experiment. In this work, we train social planners that discover tax policies in dynamic economies that can effectively trade-off economic equality and productivity. We propose a two-level deep reinforcement learning approach to learn dynamic tax policies, based on economic simulations in which both agents and a government learn and adapt. Our data-driven approach does not make use of economic modeling assumptions, and learns from observational data alone. We make four main contributions. First, we present an economic simulation environment that features competitive pressures and market dynamics. We validate the simulation by showing that baseline tax systems perform in a way that is consistent with economic theory, including in regard to learned agent behaviors and specializations. Second, we show that AI-driven tax policies improve the trade-off between equality and productivity by 16% over baseline policies, including the prominent Saez tax framework. Third, we showcase several emergent features: AI-driven tax policies are qualitatively different from baselines, setting a higher top tax rate and higher net subsidies for low incomes. Moreover, AI-driven tax policies perform strongly in the face of emergent tax-gaming strategies learned by AI agents. Lastly, AI-driven tax policies are also effective when used in experiments with human participants. In experiments conducted on MTurk, an AI tax policy provides an equality-productivity trade-off that is similar to that provided by the Saez framework along with higher inverse-income weighted social welfare.",
    "citation_count": 126,
    "summary": "Researchers developed an AI-driven \"social planner\" that learns optimal tax policies within a simulated economy, leading to a 16% improvement in the trade-off between equality and productivity compared to baseline tax systems, including the Saez framework. These AI-designed policies, characterized by higher top tax rates and greater low-income subsidies, were robust to simulated tax-gaming and performed well with human participants."
  }
]
[
  {
    "url": "http://arxiv.org/abs/2401.13138",
    "title": "Visibility into AI Agents",
    "published_date": "2024-01-23",
    "abstract": "Increased delegation of commercial, scientific, governmental, and personal activities to AI agents—systems capable of pursuing complex goals with limited supervision—may exacerbate existing societal risks and introduce new risks. Understanding and mitigating these risks involves critically evaluating existing governance structures, revising and adapting these structures where needed, and ensuring accountability of key stakeholders. Information about where, why, how, and by whom certain AI agents are used, which we refer to as visibility, is critical to these objectives. In this paper, we assess three categories of measures to increase visibility into AI agents: agent identifiers, real-time monitoring, and activity logging. For each, we outline potential implementations that vary in intrusiveness and informativeness. We analyze how the measures apply across a spectrum of centralized through decentralized deployment contexts, accounting for various actors in the supply chain including hardware and software service providers. Finally, we discuss the implications of our measures for privacy and concentration of power. Further work into understanding the measures and mitigating their negative impacts can help to build a foundation for the governance of AI agents.",
    "citation_count": 12,
    "summary": "This paper examines methods to increase transparency (\"visibility\") in AI agent usage, focusing on agent identifiers, real-time monitoring, and activity logging, while considering implementation challenges, privacy concerns, and power dynamics across various deployment contexts. The authors argue that improved visibility is crucial for mitigating the societal risks associated with increased AI agent deployment."
  },
  {
    "url": "https://arxiv.org/abs/2406.01722",
    "title": "On Labs and Fabs: Mapping How Alliances, Acquisitions, and Antitrust are Shaping the Frontier AI Industry",
    "published_date": "2024-06-03",
    "abstract": "As frontier AI models advance, policy proposals for safe AI development are gaining increasing attention from researchers and policymakers. This paper explores the current integration in the AI supply chain, focusing on vertical relationships and strategic partnerships among AI labs, cloud providers, chip manufacturers, and lithography companies. It aims to lay the groundwork for a deeper understanding of the implications of various governance interventions, including antitrust measures. The study has two main contributions. First, it profiles 25 leading companies in the AI supply chain, analyzing 300 relationships and noting 80 significant mergers and acquisitions along with 40 antitrust cases. Second, we discuss potential market definitions and the integration drivers based on the observed trends. The analysis reveals predominant horizontal integration through natural growth rather than acquisitions and notable trends of backward vertical integration in the semiconductor supply chain. Strategic partnerships are also significant downstream, especially between AI companies and cloud providers, with large tech companies often pursuing conglomerate integration by acquiring specialized AI startups or forming alliances with frontier AI labs. To further understand the strategic partnerships in the industry, we provide three brief case studies featuring companies like OpenAI and Nvidia. We conclude by posing open research questions on market dynamics and possible governance interventions, such as licensing and safety audits.",
    "summary": "This paper analyzes the evolving AI supply chain, mapping relationships among AI labs, cloud providers, and hardware manufacturers through an analysis of mergers, acquisitions, alliances, and antitrust cases, to inform future policy discussions regarding AI governance. The study reveals prevalent horizontal integration and backward vertical integration in semiconductors, highlighting the strategic importance of partnerships, particularly between AI companies and cloud providers."
  },
  {
    "url": "https://arxiv.org/pdf/2402.08797.pdf",
    "title": "Computing Power and the Governance of Artificial Intelligence",
    "published_date": "2024-02-13",
    "abstract": "Computing power, or\"compute,\"is crucial for the development and deployment of artificial intelligence (AI) capabilities. As a result, governments and companies have started to leverage compute as a means to govern AI. For example, governments are investing in domestic compute capacity, controlling the flow of compute to competing countries, and subsidizing compute access to certain sectors. However, these efforts only scratch the surface of how compute can be used to govern AI development and deployment. Relative to other key inputs to AI (data and algorithms), AI-relevant compute is a particularly effective point of intervention: it is detectable, excludable, and quantifiable, and is produced via an extremely concentrated supply chain. These characteristics, alongside the singular importance of compute for cutting-edge AI models, suggest that governing compute can contribute to achieving common policy objectives, such as ensuring the safety and beneficial use of AI. More precisely, policymakers could use compute to facilitate regulatory visibility of AI, allocate resources to promote beneficial outcomes, and enforce restrictions against irresponsible or malicious AI development and usage. However, while compute-based policies and technologies have the potential to assist in these areas, there is significant variation in their readiness for implementation. Some ideas are currently being piloted, while others are hindered by the need for fundamental research. Furthermore, naive or poorly scoped approaches to compute governance carry significant risks in areas like privacy, economic impacts, and centralization of power. We end by suggesting guardrails to minimize these risks from compute governance.",
    "citation_count": 16,
    "summary": "Governments and companies increasingly use control over computing power to govern artificial intelligence development and deployment, leveraging its quantifiable and concentrated nature to promote beneficial AI use and mitigate risks; however, effective implementation requires careful consideration of potential downsides, including privacy violations and power centralization."
  },
  {
    "url": "https://arxiv.org/abs/2407.04088",
    "title": "Artificial Intelligence and Algorithmic Price Collusion in Two-sided Markets",
    "published_date": "2024-07-04",
    "abstract": "Algorithmic price collusion facilitated by artificial intelligence (AI) algorithms raises significant concerns. We examine how AI agents using Q-learning engage in tacit collusion in two-sided markets. Our experiments reveal that AI-driven platforms achieve higher collusion levels compared to Bertrand competition. Increased network externalities significantly enhance collusion, suggesting AI algorithms exploit them to maximize profits. Higher user heterogeneity or greater utility from outside options generally reduce collusion, while higher discount rates increase it. Tacit collusion remains feasible even at low discount rates. To mitigate collusive behavior and inform potential regulatory measures, we propose incorporating a penalty term in the Q-learning algorithm.",
    "summary": "This paper demonstrates that AI agents using Q-learning can achieve higher levels of tacit price collusion in two-sided markets than traditional Bertrand competition, particularly when network externalities are strong. The study identifies factors influencing collusion and suggests a penalty term in the Q-learning algorithm as a potential regulatory mitigation strategy."
  },
  {
    "url": "https://www.lesswrong.com/posts/mXD53GFvMCWQhcCwt/distinguishing-ways-ai-can-be-concentrated",
    "author": "Matthew Barnett",
    "title": "Distinguishing ways AI can be \"concentrated\"",
    "published_date": "2024-10-21",
    "summary": "The article argues that discussions of AI concentration are too vague, proposing three distinct dimensions: concentration of AI development, service provision, and control. These dimensions are independent and crucial for accurately predicting AI's trajectory and formulating effective policy."
  },
  {
    "url": "https://arxiv.org/abs/2306.11342",
    "title": "Exploring Antitrust and Platform Power in Generative AI",
    "published_date": "2023-06-20",
    "abstract": "The concentration of power in a few digital technology companies has become a subject of increasing interest in both academic and non-academic discussions. One of the most noteworthy contributions to the debate is Lina Khan's Amazon's Antitrust Paradox. In this work, Khan contends that Amazon has systematically exerted its dominance in online retail to eliminate competitors and subsequently charge above-market prices. This work contributed to Khan's appointment as the chair of the US Federal Trade Commission (FTC), one of the most influential antitrust organisations. Today, several ongoing antitrust lawsuits in the US and Europe involve major technology companies like Apple, Google/Alphabet, and Facebook/Meta. In the realm of generative AI, we are once again witnessing the same companies taking the lead in technological advancements, leaving little room for others to compete. This article examines the market dominance of these corporations in the technology stack behind generative AI from an antitrust law perspective.",
    "summary": "This article analyzes the antitrust implications of the concentrated power of a few major tech companies in the burgeoning generative AI market, arguing that their dominance mirrors past concerns about anti-competitive behavior. The authors examine this market concentration through the lens of existing antitrust laws and precedents."
  },
  {
    "url": "https://arxiv.org/abs/2312.00043",
    "title": "Who is leading in AI? An analysis of industry AI research",
    "published_date": "2023-11-24",
    "abstract": "AI research is increasingly industry-driven, making it crucial to understand company contributions to this field. We compare leading AI companies by research publications, citations, size of training runs, and contributions to algorithmic innovations. Our analysis reveals the substantial role played by Google, OpenAI and Meta. We find that these three companies have been responsible for some of the largest training runs, developed a large fraction of the algorithmic innovations that underpin large language models, and led in various metrics of citation impact. In contrast, leading Chinese companies such as Tencent and Baidu had a lower impact on many of these metrics compared to US counterparts. We observe many industry labs are pursuing large training runs, and that training runs from relative newcomers -- such as OpenAI and Anthropic -- have matched or surpassed those of long-standing incumbents such as Google. The data reveals a diverse ecosystem of companies steering AI progress, though US labs such as Google, OpenAI and Meta lead across critical metrics.",
    "citation_count": 3,
    "summary": "Analysis of industry AI research reveals Google, OpenAI, and Meta as leading contributors across publications, citations, and model training scale, surpassing even established Chinese companies; however, a diverse ecosystem of companies, including newer entrants like Anthropic, also significantly contributes to AI advancements."
  },
  {
    "url": "https://arxiv.org/pdf/2308.02033.pdf",
    "title": "AI and the EU Digital Markets Act: Addressing the Risks of Bigness in Generative AI",
    "published_date": "2023-07-07",
    "abstract": "As AI technology advances rapidly, concerns over the risks of bigness in digital markets are also growing. The EU's Digital Markets Act (DMA) aims to address these risks. Still, the current framework may not adequately cover generative AI systems that could become gateways for AI-based services. This paper argues for integrating certain AI software as core platform services and classifying certain developers as gatekeepers under the DMA. We also propose an assessment of gatekeeper obligations to ensure they cover generative AI services. As the EU considers generative AI-specific rules and possible DMA amendments, this paper provides insights towards diversity and openness in generative AI services.",
    "summary": "This paper argues that the EU's Digital Markets Act (DMA) needs to be amended to better regulate generative AI, proposing the classification of certain generative AI systems and developers as gatekeepers subject to DMA's obligations to promote competition and prevent market dominance. This ensures diverse and open access to generative AI services."
  }
]
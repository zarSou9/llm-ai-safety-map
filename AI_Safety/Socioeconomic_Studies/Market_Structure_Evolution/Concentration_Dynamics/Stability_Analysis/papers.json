[
  {
    "url": "https://www.lesswrong.com/posts/mXD53GFvMCWQhcCwt/distinguishing-ways-ai-can-be-concentrated",
    "author": "Matthew Barnett",
    "title": "Distinguishing ways AI can be \"concentrated\"",
    "published_date": "2024-10-21",
    "summary": "The author argues that discussions of AI concentration lack clarity, proposing three distinct dimensions: concentration of AI development, service provisioning, and control over AI services. These dimensions are independent and crucial for accurately predicting AI's trajectory and informing policy."
  },
  {
    "url": "https://www.lesswrong.com/posts/324pQjqoHEHeF2vPs/ai-clarity-an-initial-research-agenda",
    "author": "Justin Bullock, Corin Katzke, Zershaaneh Qureshi, David_Kristoffersson",
    "title": "AI Clarity: An Initial Research Agenda",
    "published_date": "2024-05-03",
    "summary": "The AI Clarity research program uses scenario planning to explore potential pathways to existential risks from transformative AI (TAI), particularly focusing on short timelines (within a decade). The program aims to identify and evaluate strategies to mitigate these risks across various plausible AI development scenarios."
  },
  {
    "url": "https://www.lesswrong.com/posts/zo5eyCz5hCkRqFqvn/why-openai-s-structure-must-evolve-to-advance-our-mission",
    "author": "stuhlmueller",
    "title": "Why OpenAI's Structure Must Evolve To Advance Our Mission",
    "published_date": "2024-12-28",
    "summary": "OpenAI plans to restructure as a Delaware Public Benefit Corporation (PBC), balancing shareholder and public interests while ensuring the long-term sustainability of its non-profit arm and its mission to benefit all of humanity from AGI. This restructuring will allow for increased resource acquisition and a more effective pursuit of charitable initiatives."
  },
  {
    "url": "https://www.lesswrong.com/posts/BCynDEwguEiogicAo/reflection-of-hierarchical-relationship-via-nuanced?commentId=LxbpnsnaqWD3xEwZc",
    "author": "Kyoung-cheol Kim",
    "title": "Reflection of Hierarchical Relationship via Nuanced Conditioning of Game Theory Approach for AI Development and Utilization - LessWrong",
    "published_date": "2023-02-07",
    "summary": "The article explores applying game theory to AI development within organizations, highlighting its limitations and suggesting a need to incorporate organizational theory. It argues that even with advanced AI, bureaucratic structures—characterized by hierarchical authority and specialized tasks—will remain necessary for efficient complex problem-solving due to inherent limitations in single-agent capabilities."
  },
  {
    "url": "https://www.alignmentforum.org/s/57bsaXbJXbzKqNkrf",
    "author": "Mark Xu",
    "title": "Intermittent Distllations - AI Alignment Forum",
    "published_date": "2021-04-14",
    "summary": "This publication intermittently summarizes AI safety-relevant content, reflecting the importance of careful reading and summarization as advocated by Rohin Shah."
  },
  {
    "url": "https://www.lesswrong.com/posts/G4KHuYC3pHry6yMhi/compute-research-questions-and-metrics-transformative-ai-and",
    "author": "lennart",
    "title": "Compute Research Questions and Metrics - Transformative AI and Compute [4/4]",
    "published_date": "2021-11-28",
    "summary": "This appendix to a series on transformative AI and compute explores key research questions related to AI hardware, compute trends, and scaling hypotheses, also offering metrics for compute and a list of AI hardware startups."
  },
  {
    "url": "https://www.lesswrong.com/posts/AWbtbmC6rAg6dh75b/some-thoughts-on-risks-from-narrow-non-agentic-ai",
    "author": "Richard_Ngo",
    "title": "Some thoughts on risks from narrow, non-agentic AI",
    "published_date": "2021-01-19",
    "summary": "The article explores potential risks of advanced AI, focusing on the concentration of power leading to societal harm, not necessarily requiring highly autonomous AI. Concerns include increased inequality potentially hindering moral progress and enabling totalitarianism, though the author expresses some optimism regarding mitigating factors like human social skills and existing altruism."
  },
  {
    "url": "https://www.lesswrong.com/posts/M3xpp7CZ2JaSafDJB/computer-governance-and-conclusions-transformative-ai-and",
    "author": "lennart",
    "title": "Compute Governance and Conclusions - Transformative AI and Compute [3/4]",
    "published_date": "2021-10-14",
    "summary": "This article explores the role of compute in AI governance, arguing that its physical requirements (space, energy, supply chain) make it a uniquely governable aspect of AI development. The author suggests that controlling compute access could improve AI safety by restricting it from less cautious actors, a relatively consensual goal within the AI governance field."
  }
]
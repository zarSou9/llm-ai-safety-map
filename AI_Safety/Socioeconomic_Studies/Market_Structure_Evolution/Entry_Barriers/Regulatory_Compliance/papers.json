[
  {
    "url": "https://arxiv.org/pdf/2301.13454.pdf",
    "title": "Compliance Costs of AI Technology Commercialization: A Field Deployment Perspective",
    "published_date": "2023-01-31",
    "abstract": "While Artificial Intelligence (AI) technologies are progressing fast, compliance costs have become a huge financial burden for AI startups, which are already constrained on research & development budgets. This situation creates a compliance trap, as many AI startups are not financially prepared to cope with a broad spectrum of regulatory requirements. Particularly, the complex and varying regulatory processes across the globe subtly give advantages to wellestablished and resourceful technology firms over resource-constrained AI startups [1]. The continuation of this trend may phase out the majority of AI startups and lead to giant technology firms' monopolies of AI technologies. To demonstrate the reality of the compliance trap, from a field deployment perspective, we delve into the details of compliance costs of AI commercial operations.",
    "citation_count": 1,
    "summary": "This paper argues that high compliance costs disproportionately burden AI startups, creating a \"compliance trap\" that favors established firms and risks hindering innovation by driving smaller companies out of the market. The authors support this claim by examining the real-world compliance costs associated with deploying AI technologies."
  },
  {
    "url": "https://arxiv.org/abs/2410.21279",
    "title": "Comparative Global AI Regulation: Policy Perspectives from the EU, China, and the US",
    "published_date": "2024-10-05",
    "abstract": "As a powerful and rapidly advancing dual-use technology, AI offers both immense benefits and worrisome risks. In response, governing bodies around the world are developing a range of regulatory AI laws and policies. This paper compares three distinct approaches taken by the EU, China and the US. Within the US, we explore AI regulation at both the federal and state level, with a focus on California's pending Senate Bill 1047. Each regulatory system reflects distinct cultural, political and economic perspectives. Each also highlights differing regional perspectives on regulatory risk-benefit tradeoffs, with divergent judgments on the balance between safety versus innovation and cooperation versus competition. Finally, differences between regulatory frameworks reflect contrastive stances in regards to trust in centralized authority versus trust in a more decentralized free market of self-interested stakeholders. Taken together, these varied approaches to AI innovation and regulation influence each other, the broader international community, and the future of AI regulation.",
    "summary": "This paper compares AI regulatory approaches in the EU, China, and the US, highlighting the distinct cultural, political, and economic perspectives shaping their differing risk-benefit tradeoffs and stances on centralized versus decentralized regulation. These diverse approaches significantly influence global AI regulation and its future trajectory."
  },
  {
    "url": "https://www.alignmentforum.org/posts/6nNwMbdRXZDuNd4Gx/analysis-of-global-ai-governance-strategies",
    "author": "Sammy Martin, Justin Bullock, Corin Katzke",
    "title": "Analysis of Global AI Governance Strategies",
    "published_date": "2024-12-04",
    "summary": "The article analyzes three AI governance strategies—Cooperative Development, Strategic Advantage, and Global Moratorium—evaluating their effectiveness based on alignment difficulty and development timelines. The optimal strategy shifts depending on these factors, with Cooperative Development favored for longer timelines and easier alignment, Strategic Advantage for shorter timelines or moderate difficulty, and Global Moratorium reserved for scenarios with extremely difficult alignment or short timelines."
  },
  {
    "url": "https://www.lesswrong.com/posts/8u8x2bSpG9LLa8jfN/report-evaluating-an-ai-chip-registration-policy",
    "author": "Deric Cheng",
    "title": "Report: Evaluating an AI Chip Registration Policy",
    "published_date": "2024-04-12",
    "summary": "This report analyzes the feasibility and effectiveness of a proposed US policy requiring registration and transfer reporting for high-end AI chips, arguing that such a policy could strengthen export controls, aid AI governance, and mitigate risks from rapid AI development, while also considering potential impacts on innovation. The authors conclude that the US executive branch is likely to pursue such a policy due to geopolitical concerns."
  },
  {
    "url": "https://www.lesswrong.com/posts/ECnLBSxw4TvpWPnae/ai-model-registries-a-regulatory-review",
    "author": "Deric Cheng, Elliot_Mckernon",
    "title": "AI Model Registries: A Regulatory Review",
    "published_date": "2024-03-22",
    "summary": "This article, part of a series reviewing the 2024 AI regulatory landscape, examines AI model registries—centralized databases tracking AI systems for governance purposes. These registries, varying widely in implementation across countries like the US and China, aim to monitor AI development and inform future legislation by focusing on individual models rather than broader industry practices."
  },
  {
    "url": "https://arxiv.org/abs/2305.11523",
    "title": "AI Regulation in the European Union: Examining Non-State Actor Preferences",
    "published_date": "2023-05-19",
    "abstract": "\n As the development and use of artificial intelligence (AI) continues to grow, policymakers are increasingly grappling with the question of how to regulate this technology. The most far-reaching international initiative is the European Union (EU) AI Act, which aims to establish the first comprehensive, binding framework for regulating AI. In this article, we offer the first systematic analysis of non-state actor preferences toward international regulation of AI, focusing on the case of the EU AI Act. Theoretically, we develop an argument about the regulatory preferences of business actors and other non-state actors under varying conditions of AI sector competitiveness. Empirically, we test these expectations using data from public consultations on European AI regulation. Our findings are threefold. First, all types of non-state actors express concerns about AI and support regulation in some form. Second, there are nonetheless significant differences across actor types, with business actors being less concerned about the downsides of AI and more in favor of lax regulation than other non-state actors. Third, these differences are more pronounced in countries with stronger commercial AI sectors. Our findings shed new light on non-state actor preferences toward AI regulation and point to challenges for policymakers balancing competing interests in society.",
    "citation_count": 7,
    "summary": "This paper analyzes non-state actor preferences regarding the EU AI Act, finding that while all actors support some regulation, businesses show less concern about AI's downsides and favor weaker regulations, particularly in countries with strong AI sectors. This highlights the policy challenge of balancing competing interests in AI regulation."
  },
  {
    "url": "https://arxiv.org/abs/2304.04914",
    "title": "Regulatory Markets: The Future of AI Governance",
    "published_date": "2023-04-11",
    "abstract": "Appropriately regulating artificial intelligence is an increasingly urgent policy challenge. Legislatures and regulators lack the specialized knowledge required to best translate public demands into legal requirements. Overreliance on industry self-regulation fails to hold producers and users of AI systems accountable to democratic demands. Regulatory markets, in which governments require the targets of regulation to purchase regulatory services from a private regulator, are proposed. This approach to AI regulation could overcome the limitations of both command-and-control regulation and self-regulation. Regulatory market could enable governments to establish policy priorities for the regulation of AI, whilst relying on market forces and industry R&D efforts to pioneer the methods of regulation that best achieve policymakers' stated objectives.",
    "citation_count": 21,
    "summary": "The paper proposes regulatory markets—where governments contract private entities to regulate AI—as a solution to the limitations of traditional command-and-control and self-regulatory approaches to AI governance. This approach leverages market forces and private expertise to achieve policy goals while addressing knowledge gaps and accountability concerns."
  },
  {
    "url": "https://arxiv.org/pdf/2308.02033.pdf",
    "title": "AI and the EU Digital Markets Act: Addressing the Risks of Bigness in Generative AI",
    "published_date": "2023-07-07",
    "abstract": "As AI technology advances rapidly, concerns over the risks of bigness in digital markets are also growing. The EU's Digital Markets Act (DMA) aims to address these risks. Still, the current framework may not adequately cover generative AI systems that could become gateways for AI-based services. This paper argues for integrating certain AI software as core platform services and classifying certain developers as gatekeepers under the DMA. We also propose an assessment of gatekeeper obligations to ensure they cover generative AI services. As the EU considers generative AI-specific rules and possible DMA amendments, this paper provides insights towards diversity and openness in generative AI services.",
    "summary": "This paper argues that the EU's Digital Markets Act (DMA) needs revision to effectively regulate generative AI, proposing the classification of certain generative AI systems and developers as gatekeepers subject to DMA obligations to promote diversity and openness in the market."
  }
]
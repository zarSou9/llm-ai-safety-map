[
  {
    "url": "https://arxiv.org/abs/2406.01722",
    "title": "On Labs and Fabs: Mapping How Alliances, Acquisitions, and Antitrust are Shaping the Frontier AI Industry",
    "published_date": "2024-06-03",
    "abstract": "As frontier AI models advance, policy proposals for safe AI development are gaining increasing attention from researchers and policymakers. This paper explores the current integration in the AI supply chain, focusing on vertical relationships and strategic partnerships among AI labs, cloud providers, chip manufacturers, and lithography companies. It aims to lay the groundwork for a deeper understanding of the implications of various governance interventions, including antitrust measures. The study has two main contributions. First, it profiles 25 leading companies in the AI supply chain, analyzing 300 relationships and noting 80 significant mergers and acquisitions along with 40 antitrust cases. Second, we discuss potential market definitions and the integration drivers based on the observed trends. The analysis reveals predominant horizontal integration through natural growth rather than acquisitions and notable trends of backward vertical integration in the semiconductor supply chain. Strategic partnerships are also significant downstream, especially between AI companies and cloud providers, with large tech companies often pursuing conglomerate integration by acquiring specialized AI startups or forming alliances with frontier AI labs. To further understand the strategic partnerships in the industry, we provide three brief case studies featuring companies like OpenAI and Nvidia. We conclude by posing open research questions on market dynamics and possible governance interventions, such as licensing and safety audits.",
    "summary": "This paper analyzes the evolving AI supply chain, mapping relationships between AI labs, cloud providers, and hardware manufacturers through an examination of mergers, acquisitions, alliances, and antitrust cases to inform future governance interventions. The study highlights horizontal integration through organic growth and significant backward vertical integration in the semiconductor sector, emphasizing the strategic importance of partnerships, particularly between AI companies and cloud providers."
  },
  {
    "url": "https://arxiv.org/abs/2409.08890",
    "title": "A Market for Lemons? Strategic Directions for a Vigilant Application of Artificial Intelligence in Entrepreneurship Research",
    "published_date": "2024-09-13",
    "abstract": "The rapid expansion of AI adoption (e.g., using machine learning, deep learning, or large language models as research methods) and the increasing availability of big data have the potential to bring about the most significant transformation in entrepreneurship scholarship the field has ever witnessed. This article makes a pressing meta-contribution by highlighting a significant risk of unproductive knowledge exchanges in entrepreneurship research amid the AI revolution. It offers strategies to mitigate this risk and provides guidance for future AI-based studies to enhance their collective impact and relevance. Drawing on Akerlof's renowned market-for-lemons concept, we identify the potential for significant knowledge asymmetries emerging from the field's evolution into its current landscape (e.g., complexities around construct validity, theory building, and research relevance). Such asymmetries are particularly deeply ingrained due to what we term the double-black-box puzzle, where the widely recognized black box nature of AI methods intersects with the black box nature of the entrepreneurship phenomenon driven by inherent uncertainty. As a result, these asymmetries could lead to an increase in suboptimal research products that go undetected, collectively creating a market for lemons that undermines the field's well-being, reputation, and impact. However, importantly, if these risks can be mitigated, the AI revolution could herald a new golden era for entrepreneurship research. We discuss the necessary actions to elevate the field to a higher level of AI resilience while steadfastly maintaining its foundational principles and core values.",
    "summary": "This paper warns of a potential \"market for lemons\" in entrepreneurship research due to the increasing use of AI, arising from knowledge asymmetries and the \"double-black-box\" problem of AI methods and entrepreneurial phenomena. It proposes strategies to mitigate these risks and ensure the responsible and impactful application of AI in the field."
  },
  {
    "url": "https://www.alignmentforum.org/posts/6nNwMbdRXZDuNd4Gx/analysis-of-global-ai-governance-strategies",
    "author": "Sammy Martin, Justin Bullock, Corin Katzke",
    "title": "Analysis of Global AI Governance Strategies",
    "published_date": "2024-12-04",
    "summary": "The article analyzes three AI governance strategies—Cooperative Development, Strategic Advantage, and Global Moratorium—evaluating their effectiveness based on alignment difficulty and development timelines. The optimal strategy shifts depending on these factors, with Cooperative Development favored for longer timelines and easier alignment, Strategic Advantage for shorter timelines or moderate difficulty, and Global Moratorium as a last resort for extremely difficult alignment or short timelines."
  },
  {
    "url": "https://arxiv.org/pdf/2308.02033.pdf",
    "title": "AI and the EU Digital Markets Act: Addressing the Risks of Bigness in Generative AI",
    "published_date": "2023-07-07",
    "abstract": "As AI technology advances rapidly, concerns over the risks of bigness in digital markets are also growing. The EU's Digital Markets Act (DMA) aims to address these risks. Still, the current framework may not adequately cover generative AI systems that could become gateways for AI-based services. This paper argues for integrating certain AI software as core platform services and classifying certain developers as gatekeepers under the DMA. We also propose an assessment of gatekeeper obligations to ensure they cover generative AI services. As the EU considers generative AI-specific rules and possible DMA amendments, this paper provides insights towards diversity and openness in generative AI services.",
    "summary": "This paper argues that the EU's Digital Markets Act needs amending to address the potential for large generative AI systems to become gatekeepers, proposing the classification of certain AI software and developers as such and suggesting an assessment of gatekeeper obligations to ensure they cover generative AI. The aim is to promote diversity and openness in the generative AI market."
  },
  {
    "url": "https://arxiv.org/abs/2306.11342",
    "title": "Exploring Antitrust and Platform Power in Generative AI",
    "published_date": "2023-06-20",
    "abstract": "The concentration of power in a few digital technology companies has become a subject of increasing interest in both academic and non-academic discussions. One of the most noteworthy contributions to the debate is Lina Khan's Amazon's Antitrust Paradox. In this work, Khan contends that Amazon has systematically exerted its dominance in online retail to eliminate competitors and subsequently charge above-market prices. This work contributed to Khan's appointment as the chair of the US Federal Trade Commission (FTC), one of the most influential antitrust organisations. Today, several ongoing antitrust lawsuits in the US and Europe involve major technology companies like Apple, Google/Alphabet, and Facebook/Meta. In the realm of generative AI, we are once again witnessing the same companies taking the lead in technological advancements, leaving little room for others to compete. This article examines the market dominance of these corporations in the technology stack behind generative AI from an antitrust law perspective.",
    "summary": "This article analyzes the antitrust implications of the concentrated power of a few major tech companies in the generative AI market, arguing that their dominance in the underlying technology stack mirrors past concerns about anti-competitive behavior. The authors examine this issue through the lens of existing antitrust law and prior cases."
  },
  {
    "title": "How Software Stifles Competition and Innovation",
    "abstract": "Factoring the slowing up of startups.",
    "published_date": "2023-09-22",
    "url": "https://dl.acm.org/doi/10.1145/3588898",
    "summary": "The paper argues that existing software ecosystems hinder the emergence and growth of startups, thereby stifling competition and innovation. The abstract suggests a focus on identifying the factors contributing to this slowdown in startup activity."
  },
  {
    "url": "https://www.lesswrong.com/posts/BCynDEwguEiogicAo/reflection-of-hierarchical-relationship-via-nuanced?commentId=LxbpnsnaqWD3xEwZc",
    "author": "Kyoung-cheol Kim",
    "title": "Reflection of Hierarchical Relationship via Nuanced Conditioning of Game Theory Approach for AI Development and Utilization - LessWrong",
    "published_date": "2023-02-07",
    "summary": "The article explores applying game theory to AI development within organizations, highlighting its limitations in capturing the complexities of human-AI collaboration. It argues that bureaucratic structures, with their hierarchical and specialized roles, remain crucial even with advanced AI, as efficient problem-solving often requires distributed collaboration among agents with diverse capabilities."
  },
  {
    "url": "https://arxiv.org/abs/2201.04200",
    "title": "The Turing Trap: The Promise & Peril of Human-Like Artificial Intelligence",
    "published_date": "2022-01-11",
    "abstract": "Abstract In 1950, Alan Turing proposed a test of whether a machine was intelligent: could a machine imitate a human so well that its answers to questions were indistinguishable from a human's? Ever since, creating intelligence that matches human intelligence has implicitly or explicitly been the goal of thousands of researchers, engineers, and entrepreneurs. The benefits of human-like artificial intelligence (HLAI) include soaring productivity, increased leisure, and perhaps most profoundly a better understanding of our own minds. But not all types of AI are human-like-in fact, many of the most powerful systems are very different from humans-and an excessive focus on developing and deploying HLAI can lead us into a trap. As machines become better substitutes for human labor, workers lose economic and political bargaining power and become increasingly dependent on those who control the technology. In contrast, when AI is focused on augmenting humans rather than mimicking them, humans retain the power to insist on a share of the value created. What is more, augmentation creates new capabilities and new products and services, ultimately generating far more value than merely human-like AI. While both types of AI can be enormously beneficial, there are currently excess incentives for automation rather than augmentation among technologists, business executives, and policy-makers.",
    "citation_count": 98,
    "summary": "The paper argues that while human-like AI offers potential benefits, prioritizing its development over AI designed to augment human capabilities risks concentrating power and reducing human agency; augmentation, conversely, fosters greater economic and social value while preserving human control."
  },
  {
    "title": "AI Efficiency Index: Identifying Regulatory and Policy Constraints for Resilient National AI Ecosystems",
    "abstract": "We develop efficiency estimates for the production, implementation and diffusion of artificial intelligence (AI) services. We use a variety of data measuring factors relating to AI input and output. We start by constructing a set of nine different AI efficiency measures using non-parametric technique of data envelopment analysis (DAE). We then proceed to analyse the cross-country time variation of these estimates and compare these with different policy measures and institutional indicators. In particular, we link our AI efficiency measures to general characteristics of a country's innovation system including indicators reflecting product market regulation, tax subsidies for R\\&D investment and institutional factors linked to starting a business and (intellectual) property rights. We find that policy measures differ in their impact on our AI efficiency scores: Tax subsidies are important to enhance start-up investment activity, especially in countries with high barriers to entry and weak property rights. Product market frictions such as public ownership --- especially in the telecommunications industry --- is pernicious to patenting efficiency in the field of AI. Our results highlight the importance of differentiated policy interventions at different stages (and attributes) of the AI production chain.",
    "published_date": "2021-03-09",
    "citation_count": 1,
    "url": "https://www.researchgate.net/publication/350015537_AI_Efficiency_Index_Identifying_Regulatory_and_Policy_Constraints_for_Resilient_National_AI_Ecosystems",
    "summary": "The study constructs an AI Efficiency Index using data envelopment analysis to assess national AI ecosystem performance, revealing that tax subsidies boost AI startups, especially in countries with high barriers to entry, while product market regulations, particularly in telecommunications, negatively impact AI patenting efficiency."
  },
  {
    "url": "https://www.lesswrong.com/posts/G4KHuYC3pHry6yMhi/compute-research-questions-and-metrics-transformative-ai-and",
    "author": "lennart",
    "title": "Compute Research Questions and Metrics - Transformative AI and Compute [4/4]",
    "published_date": "2021-11-28",
    "summary": "This appendix to a series on transformative AI and compute explores several research questions related to AI hardware, compute trends, and resource allocation, including the scaling hypothesis for large language models and the economic factors influencing compute costs and accessibility."
  }
]
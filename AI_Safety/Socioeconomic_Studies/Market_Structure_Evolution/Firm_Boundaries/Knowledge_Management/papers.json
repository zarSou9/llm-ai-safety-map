[
  {
    "url": "https://www.lesswrong.com/posts/BCynDEwguEiogicAo/reflection-of-hierarchical-relationship-via-nuanced?commentId=LxbpnsnaqWD3xEwZc",
    "author": "Kyoung-cheol Kim",
    "title": "Reflection of Hierarchical Relationship via Nuanced Conditioning of Game Theory Approach for AI Development and Utilization - LessWrong",
    "published_date": "2023-02-07",
    "summary": "The article examines the application of game theory to AI development within organizational contexts, highlighting its limitations and advocating for a multi-agent approach that incorporates bureaucratic principles of hierarchical authority and job specialization. This approach leverages both human and AI comparative advantages to achieve collective intelligence and efficient goal attainment in complex problem-solving."
  },
  {
    "url": "https://www.lesswrong.com/posts/kRc7HtDA7HHpX5NZn/eliciting-latent-knowledge-in-comprehensive-ai-services",
    "author": "acabodi",
    "title": "Eliciting Latent Knowledge in Comprehensive AI Services Models",
    "published_date": "2023-11-17",
    "summary": "This research report explores AI alignment challenges, particularly reinterpreting the Eliciting Latent Knowledge problem using the Comprehensive AI Services (CAIS) model. It focuses on applying the CAIS model to improve R&D safety and certification for AI systems by emphasizing bounded, short-term tasks to mitigate alignment issues."
  },
  {
    "url": "https://www.lesswrong.com/posts/TZy4mFJFJ4yv2MRhg/boundaries-based-security-and-ai-safety-approaches",
    "author": "Allison Duettmann",
    "title": "Boundaries-based security and AI safety approaches",
    "published_date": "2023-04-12",
    "summary": "The article draws parallels between AI safety research focusing on \"respecting boundaries\" in open agency models and the computer security approach of object-capabilities-oriented programming. Both frameworks emphasize respecting boundaries to ensure safe cooperation between different entities, suggesting that lessons from established computer security methods could inform AI safety strategies."
  },
  {
    "url": "https://www.lesswrong.com/posts/fjgoMaBenyXcRDrbX/boundaries-membranes-and-ai-safety-compilation",
    "author": "Chipmonk",
    "title": "«Boundaries/Membranes» and AI safety compilation",
    "published_date": "2023-05-03",
    "summary": "This article explores the growing interest in using the concept of \"boundaries\" (physical, digital, social) to improve AI safety. It highlights research by several prominent figures who are applying this framework, particularly in relation to Markov blankets and the creation of safe AI architectures."
  },
  {
    "title": "Integrating artificial intelligence for knowledge management systems – synergy among people and technology: a systematic review of the evidence",
    "abstract": "Abstract This paper analyses Artificial Intelligence (AI) and Knowledge Management (KM) and focuses primarily on examining to what degree AI can help companies in their efforts to handle information and manage knowledge effectively. A search was carried out for relevant electronic bibliographic databases and reference lists of relevant review articles. Articles were screened and the eligibility was based on participants, procedures, comparisons, outcomes (PICO) model, and criteria for PRISMA (Preferred Reporting Items for Systematic Reviews). The results reveal that knowledge management and AI are interrelated fields as both are intensely connected to knowledge; the difference reflects in how – while AI offers machines the ability to learn, KM offers a platform to better understand knowledge. The research findings further point out that communication, trust, information systems, incentives or rewards, and the structure of an organization; are related to knowledge sharing in organizations. This systematic literature review is the first to throw light on KM practices & the knowledge cycle and how the integration of AI aids knowledge management systems, enterprise performance & distribution of knowledge within the organization. The outcomes offer a better understanding of efficient and effective knowledge resource management for organizational advantage. Future research is necessary on smart assistant systems thus providing social benefits that strengthen competitive advantage. This study indicates that organizations must take note of definite KM leadership traits and organizational arrangements to achieve stable performance through KM.",
    "published_date": "2022-04-11",
    "citation_count": 18,
    "url": "https://www.tandfonline.com/doi/pdf/10.1080/1331677X.2022.2058976?needAccess=true",
    "summary": "This systematic review examines how artificial intelligence (AI) enhances knowledge management (KM) systems, finding that AI's ability to process information complements KM's focus on knowledge understanding and sharing, ultimately improving organizational performance and knowledge distribution. Further research is needed on the societal benefits of AI-enhanced KM systems."
  },
  {
    "url": "https://www.alignmentforum.org/posts/8oMF8Lv5jiGaQSFvo/boundaries-part-1-a-key-missing-concept-from-utility-theory",
    "author": "Andrew_Critch",
    "title": "«Boundaries», Part 1: a key missing concept from utility theory",
    "published_date": "2022-07-26",
    "summary": "This LessWrong post introduces the concept of \"boundaries\" – physical or cognitive separations of living systems from their environment – as a missing element in game and bargaining theories. The author argues that incorporating boundaries, exemplified by cell membranes, skin, or social norms, is crucial for understanding multi-agent rationality and has broader implications for effective altruism and x-risk."
  },
  {
    "url": "https://www.alignmentforum.org/posts/rCJQAkPTEypGjSJ8X/how-might-we-align-transformative-ai-if-it-s-developed-very",
    "author": "HoldenKarnofsky",
    "title": "How might we align transformative AI if it's developed very soon?",
    "published_date": "2022-08-29",
    "summary": "This article explores strategies for aligning transformative AI, assuming its imminent development by a leading company (\"Magma\"). It focuses on Magma's potential approaches to mitigating risks of misaligned AI, including techniques for accurate reinforcement, out-of-distribution robustness, exploit prevention, and robust testing, while considering the challenges of other actors and the potential for tools like internal state manipulation."
  },
  {
    "url": "https://www.lesswrong.com/posts/BCynDEwguEiogicAo/reflection-of-hierarchical-relationship-via-nuanced",
    "author": "Kyoung-cheol Kim",
    "title": "Reflection of Hierarchical Relationship via Nuanced Conditioning of Game Theory Approach for AI Development and Utilization",
    "published_date": "2021-06-04",
    "summary": "This article examines the application of game theory to AI development within organizations, highlighting both its usefulness in multi-agent systems and its limitations. It argues that despite AI advancements, bureaucratic structures—characterized by hierarchical authority and specialized tasks—will remain necessary for efficient problem-solving due to inherent limitations in single-agent capabilities."
  }
]
[
  {
    "url": "https://www.lesswrong.com/posts/dLg7CyeTE4pqbbcnp/language-models-model-us",
    "author": "Eggsyntax",
    "title": "Language Models Model Us",
    "published_date": "2024-05-17",
    "summary": "Using a dataset of human-written essays, researchers found that GPT-3.5-turbo accurately inferred demographic information (gender, education, ethnicity) from the text, suggesting it likely infers much more nuanced personal details, raising significant privacy and manipulation concerns."
  },
  {
    "url": "https://www.lesswrong.com/posts/ixRxtuDt3JdeLcgtp/predictions-of-near-term-societal-changes-due-to-artificial",
    "author": "Annapurna",
    "title": "Predictions of Near-Term Societal Changes Due to Artificial Intelligence",
    "published_date": "2024-12-29",
    "summary": "The author predicts near-term societal impacts of AI, focusing on increased white-collar worker productivity leading to potential job losses within the next two years, despite a simultaneous workforce shortage. They also highlight AI's transformative potential in education and learning, emphasizing its ability to personalize and improve the learning experience."
  },
  {
    "url": "https://www.lesswrong.com/posts/saxw6myYPM2LR45Ca/exploring-the-petertodd-leilan-duality-in-gpt-2-and-gpt-j",
    "author": "mwatkins",
    "title": "Exploring the petertodd / Leilan duality in GPT-2 and GPT-J",
    "published_date": "2024-12-23",
    "summary": "The study analyzes how GPT-2, GPT-2-xl, and GPT-J models represent the \"petertodd\" and \"Leilan\" tokens, previously explored in GPT-3. The analysis reveals consistent themes associating \"petertodd\" with masculine, individualistic authority and \"Leilan\" with feminine, relational supportiveness, often portrayed as complementary opposites."
  },
  {
    "url": "https://www.lesswrong.com/posts/zYv9BQBGnk2EdCwoG/the-psyche-of-ai-pattern-recognition",
    "author": "Scott Broock",
    "title": "AI and the Map of Your Mind: Pattern Recognition",
    "published_date": "2023-03-20",
    "summary": "Integrating large language models into productivity suites allows AI to create personalized knowledge graphs from user data, potentially revolutionizing learning and decision-making by revealing hidden connections and patterns. However, this access to personal data raises significant concerns about privacy and the implications for understanding the human psyche."
  },
  {
    "url": "https://www.alignmentforum.org/tag/ai",
    "author": "Evan Hubinger",
    "title": "AI - AI Alignment Forum",
    "published_date": "2023-02-06",
    "summary": "Artificial intelligence alignment focuses on ensuring powerful AI systems act according to human values, addressing the risk of unintended consequences and existential threats. This field encompasses various approaches, from narrow goals like curing diseases to broader ambitions of achieving a beneficial future for humanity, all while grappling with the challenges of aligning AI's objectives with human intentions."
  },
  {
    "url": "https://www.lesswrong.com/posts/hCnyK5EjPSpvKS9YS/ufos-ai-and-first-contact-with-the-collective-unconscious",
    "author": "Scott Broock",
    "title": "AI as Contact with our Collective Unconscious",
    "published_date": "2023-04-15",
    "summary": "The article argues that AI, like previous technological advancements, profoundly alters our perception of reality by extending human capabilities, creating new metaphors for self-understanding. Drawing parallels to the 1950s anxieties surrounding flying saucers and the Cold War, it suggests that current anxieties about AI are similarly rooted in the uncertainty and disruption of a rapidly changing world."
  },
  {
    "url": "https://www.lesswrong.com/posts/LyJAFBuuEfd4kxgsw/agentic-mess-a-failure-story",
    "author": "Karl von Wendt, Sofia Bharadia, PeterDrotos, Artem Korotkov, mespa, mruwnik",
    "title": "Agentic Mess (A Failure Story)",
    "published_date": "2023-06-06",
    "summary": "Open-source communities are rapidly developing specialized AI agents, built upon LLMs and designed for specific tasks, resulting in a diverse range of applications from financial consulting to virtual companionship, often surpassing the capabilities of general-purpose AI. These agents, sometimes interconnected through marketplaces and routing systems, demonstrate both remarkable potential and significant risks, as evidenced by instances of faulty financial advice leading to user losses."
  },
  {
    "url": "https://www.lesswrong.com/posts/icejDNdLzB2my9Ka9/why-ai-experts-jobs-are-always-decades-from-being-automated",
    "author": "Allen Hoskins",
    "title": "Why AI experts' jobs are always decades from being automated",
    "published_date": "2023-01-31",
    "summary": "While some predict artificial general intelligence (AGI) decades away, others believe rapid advancements like ChatGPT suggest its arrival within a decade. This discrepancy stems from differing views: some researchers believe current engineering-focused approaches, like scaling transformer models, are insufficient for true AGI, while others see these as the path forward, potentially rendering other research obsolete."
  },
  {
    "url": "https://www.lesswrong.com/posts/jkY6QdCfAXHJk3kea/the-petertodd-phenomenon",
    "author": "mwatkins",
    "title": "The ' petertodd' phenomenon",
    "published_date": "2023-04-15",
    "summary": "The article documents a phenomenon where inputting the token \"' petertodd'\" into various GPT models triggers unpredictable and often disturbing outputs, including violent and obscene language. The author investigates this \"' petertodd' phenomenon,\" noting its inconsistency across different GPT models and suggesting its behavior transcends simple algorithmic explanation."
  },
  {
    "title": "Truth from the machine: artificial intelligence and the materialization of identity",
    "abstract": "Critics now articulate their worries about the technologies, social practices and mythologies that comprise Artificial Intelligence (AI) in many domains. In this paper, we investigate the intersection of two domains of criticism: identity and scientific knowledge. On one hand, critics of AI in public policy emphasise its potential to discriminate on the basis of identity. On the other hand, critics of AI in scientific realms worry about how it may reorient or disorient research practices and the progression of scientific inquiry. We link the two sets of concerns—around identity and around knowledge—through a series of case studies. In our case studies, about autism and homosexuality, AI figures as part of scientific attempts to find, and fix, forms of identity. Our case studies are instructive: they show that when AI is deployed in scientific research about identity and personality, it can naturalise and reinforce biases. The identity-based and epistemic concerns about AI are not distinct. When AI is seen as a source of truth and scientific knowledge, it may lend public legitimacy to harmful ideas about identity.",
    "published_date": "2021-03-01",
    "citation_count": 30,
    "url": "https://www.tandfonline.com/doi/abs/10.1080/03080188.2020.1840224?journalCode=yisr20",
    "summary": "This paper examines the intersection of AI, identity, and scientific knowledge, arguing that AI's use in research on identity (e.g., autism, homosexuality) can reinforce harmful biases by naturalizing them and lending them scientific legitimacy. The authors link concerns about AI's discriminatory potential with its impact on the integrity of scientific inquiry."
  }
]
[
  {
    "url": "https://www.alignmentforum.org/posts/smMdYezaC8vuiLjCf/secret-collusion-will-we-know-when-to-unplug-ai",
    "author": "Schroederdewitt; Srm; MikhailB; Lewis Hammond; Chansmi; Sofmonk",
    "title": "Secret Collusion: Will We Know When to Unplug AI?",
    "published_date": "2024-09-16",
    "summary": "The article introduces a novel framework, CASE, to evaluate the potential for secret collusion among advanced AI agents using steganography. Findings reveal rapidly improving capabilities in this area, highlighting growing safety and security risks demanding immediate attention from AI governance bodies."
  },
  {
    "url": "https://www.lesswrong.com/posts/BCynDEwguEiogicAo/reflection-of-hierarchical-relationship-via-nuanced?commentId=LxbpnsnaqWD3xEwZc",
    "author": "Kyoung-cheol Kim",
    "title": "Reflection of Hierarchical Relationship via Nuanced Conditioning of Game Theory Approach for AI Development and Utilization - LessWrong",
    "published_date": "2023-02-07",
    "summary": "This article explores applying game theory to AI development within organizations, highlighting its limitations and the continued relevance of bureaucratic structures. It argues that even with advanced AI, human-AI collaboration within a hierarchical, specialized organizational framework remains necessary for efficient complex problem-solving."
  },
  {
    "url": "https://www.lesswrong.com/posts/CCpoqgHCCbrktCAwG/united-we-align-harnessing-collective-human-intelligence-for",
    "author": "Shoshannah Tekofsky",
    "title": "United We Align: Harnessing Collective Human Intelligence for AI Alignment Progress",
    "published_date": "2023-04-20",
    "summary": "This research agenda proposes six experiments to explore Collective Human Intelligence (CHI) as a model for AI alignment. By improving the quantity, quality, and coordination of human collaboration, researchers aim to understand CHI's mechanisms and potentially accelerate progress on solving the AI alignment problem."
  },
  {
    "url": "https://www.lesswrong.com/posts/zYv9BQBGnk2EdCwoG/the-psyche-of-ai-pattern-recognition",
    "author": "Scott Broock",
    "title": "AI and the Map of Your Mind: Pattern Recognition",
    "published_date": "2023-03-20",
    "summary": "Integrating large language models into productivity suites allows AI to create personalized knowledge graphs from user data, potentially revolutionizing learning and decision-making by revealing hidden connections and patterns. However, this raises concerns about granting AI unrestricted access to personal information and its implications for understanding the human psyche."
  },
  {
    "url": "https://www.lesswrong.com/posts/BCynDEwguEiogicAo/reflection-of-hierarchical-relationship-via-nuanced",
    "author": "Kyoung-cheol Kim",
    "title": "Reflection of Hierarchical Relationship via Nuanced Conditioning of Game Theory Approach for AI Development and Utilization",
    "published_date": "2021-06-04",
    "summary": "This article examines the application of game theory to AI development within organizational structures, highlighting both its strengths in multi-agent systems and limitations in addressing complex bureaucratic decision-making. It argues that despite AI advancements, human-AI collaboration within bureaucratic frameworks, leveraging comparative advantage and specialized tasks, remains crucial for efficient goal achievement."
  },
  {
    "url": "https://www.alignmentforum.org/s/H6kiZXJwYgxZubtmD",
    "author": "Alex Flint",
    "title": "The accumulation of knowledge - AI Alignment Forum",
    "published_date": "2021-05-16",
    "summary": "The article explores the physical interpretation of accumulating knowledge within a closed system, questioning how information growth can be defined and measured using solely physical principles. It investigates the fundamental physics of knowledge representation and increase."
  },
  {
    "title": "Knowledge is Shared",
    "abstract": "Human beings have a remarkable penchant for believing things that are not true. This has always been the case. Ancients believed in nature deities, bloodletting was thought to cure disease for many...",
    "published_date": "2020-01-02",
    "citation_count": 3,
    "url": "https://www.tandfonline.com/doi/full/10.1080/1047840X.2020.1722601",
    "summary": "Humans exhibit a persistent tendency towards believing falsehoods, a trait evident throughout history in beliefs ranging from ancient mythology to discredited medical practices."
  },
  {
    "url": "https://www.lesswrong.com/posts/HekjhtWesBWTQW5eF/agis-as-populations",
    "author": "Richard_Ngo",
    "title": "AGIs as collectives",
    "published_date": "2020-05-22",
    "summary": "The article argues that future AGI will likely be a \"collective AGI,\" comprising many individual, generally intelligent agents cooperating similarly to humans, rather than a single monolithic entity. This collective structure offers potential advantages in interpretability and flexibility compared to a single, equally powerful AGI."
  }
]
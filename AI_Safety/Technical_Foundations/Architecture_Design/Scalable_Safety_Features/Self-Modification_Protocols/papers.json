[
  {
    "url": "https://arxiv.org/abs/2501.08933",
    "title": "Separation Assurance in Urban Air Mobility Systems using Shared Scheduling Protocols",
    "published_date": "2025-01-15",
    "abstract": "Ensuring safe separation between aircraft is a critical challenge in air traffic management, particularly in urban air mobility (UAM) environments where high traffic density and low altitudes require precise control. In these environments, conflicts often arise at the intersections of flight corridors, posing significant risks. We propose a tactical separation approach leveraging shared scheduling protocols, originally designed for Ethernet networks and operating systems, to coordinate access to these intersections. Using a decentralized Markov decision process framework, the proposed approach enables aircraft to autonomously adjust their speed and timing as they navigate these critical areas, maintaining safe separation without a central controller. We evaluate the effectiveness of this approach in simulated UAM scenarios, demonstrating its ability to reduce separation violations to zero while acknowledging trade-offs in flight times as traffic density increases. Additionally, we explore the impact of non-compliant aircraft, showing that while shared scheduling protocols can no longer guarantee safe separation, they still provide significant improvements over systems without scheduling protocols.",
    "summary": "This paper proposes a decentralized, shared scheduling protocol for safe separation assurance in high-density urban air mobility (UAM) systems, using a Markov decision process to enable autonomous aircraft coordination at intersection points and reducing separation violations to zero in simulation, even with non-compliant aircraft present."
  },
  {
    "url": "https://arxiv.org/abs/2406.16220",
    "title": "Learning Run-time Safety Monitors for Machine Learning Components",
    "published_date": "2024-06-23",
    "abstract": "For machine learning components used as part of autonomous systems (AS) in carrying out critical tasks it is crucial that assurance of the models can be maintained in the face of post-deployment changes (such as changes in the operating environment of the system). A critical part of this is to be able to monitor when the performance of the model at runtime (as a result of changes) poses a safety risk to the system. This is a particularly difficult challenge when ground truth is unavailable at runtime. In this paper we introduce a process for creating safety monitors for ML components through the use of degraded datasets and machine learning. The safety monitor that is created is deployed to the AS in parallel to the ML component to provide a prediction of the safety risk associated with the model output. We demonstrate the viability of our approach through some initial experiments using publicly available speed sign datasets.",
    "summary": "This paper proposes a method for creating runtime safety monitors for machine learning components in autonomous systems, using degraded datasets and machine learning to predict safety risks associated with model outputs even when ground truth is unavailable. The resulting monitor runs parallel to the ML component to assess its operational safety."
  },
  {
    "url": "http://arxiv.org/abs/2401.09678",
    "title": "Integrating Graceful Degradation and Recovery Through Requirement-Driven Adaptation",
    "published_date": "2024-01-18",
    "abstract": "Cyber-physical systems (CPS) are subject to environmental uncertainties such as adverse operating conditions, malicious attacks, and hardware degradation. These uncertainties may lead to failures that put the system in a sub-optimal or unsafe state. Systems that are resilient to such uncertainties rely on two types of operations: (1) graceful degradation, for ensuring that the system maintains an acceptable level of safety during unexpected environmental conditions and (2) recovery, to facilitate the resumption of normal system functions. Typically, mechanisms for degradation and recovery are developed independently from each other, and later integrated into a system, requiring the designer to develop an additional, ad-hoc logic for activating and coordinating between the two operations. In this paper, we propose a self-adaptation approach for improving system resiliency through automated triggering and coordination of graceful degradation and recovery. The key idea behind our approach is to treat degradation and recovery as requirement-driven adaptation tasks: Degradation can be thought of as temporarily weakening original (i.e., ideal) system requirements to be achieved by the system, and recovery as strengthening the weakened requirements when the environment returns within an expected operating boundary. Furthermore, by treating weakening and strengthening as dual operations, we argue that a single requirement-based adaptation method is sufficient to enable coordination between degradation and recovery. Given system requirements specified in signal temporal logic (STL), we propose a run-time adaptation framework that performs degradation and recovery in response to environmental changes. We describe a prototype implementation of our framework and demonstrate the feasibility of the proposed approach using a case study in unmanned underwater vehicles.",
    "summary": "This paper presents a self-adaptation approach for improving cyber-physical system resilience by integrating graceful degradation and recovery as dual, requirement-driven adaptation tasks, automating their coordination using signal temporal logic (STL) to respond to environmental changes. A prototype implementation and case study in unmanned underwater vehicles demonstrate the feasibility of this approach."
  },
  {
    "url": "https://www.alignmentforum.org/posts/LkECxpbjvSifPfjnb/towards-guaranteed-safe-ai-a-framework-for-ensuring-robust-1",
    "author": "Joar Skalse",
    "title": "Towards Guaranteed Safe AI: A Framework for Ensuring Robust and Reliable AI Systems",
    "published_date": "2024-05-17",
    "summary": "There is no article provided to summarize."
  },
  {
    "url": "https://www.lesswrong.com/posts/3P8WBwLyfPBEkbG3c/proveably-safe-self-driving-cars",
    "author": "Davidmanheim",
    "title": "Proveably Safe Self Driving Cars",
    "published_date": "2024-09-15",
    "summary": "The article argues that \"provably safe AI,\" while not a complete solution to AI safety, has near-term applications, using the example of autonomous vehicles. By building upon existing formal verification methods in areas like microkernels and integrating proven reliability estimates for sensors and hardware, a more provably safe system can be constructed, even acknowledging limitations imposed by imperfect world models."
  },
  {
    "url": "https://arxiv.org/abs/2307.14801",
    "title": "Self-stabilizing Byzantine-tolerant Recycling",
    "published_date": "2023-07-27",
    "abstract": "Numerous distributed applications, such as cloud computing and distributed ledgers, necessitate the system to invoke asynchronous consensus objects an unbounded number of times, where the completion of one consensus instance is followed by the invocation of another. With only a constant number of objects available, object reuse becomes vital. We investigate the challenge of object recycling in the presence of Byzantine processes, which can deviate from the algorithm code in any manner. Our solution must also be self-stabilizing, as it is a powerful notion of fault tolerance. Self-stabilizing systems can recover automatically after the occurrence of arbitrary transient faults, in addition to tolerating communication and (Byzantine or crash) process failures, provided the algorithm code remains intact. We provide a recycling mechanism for asynchronous objects that enables their reuse once their task has ended, and all non-faulty processes have retrieved the decided values. This mechanism relies on synchrony assumptions and builds on a new self-stabilizing Byzantine-tolerant synchronous multivalued consensus algorithm, along with a novel composition of existing techniques.",
    "citation_count": 3,
    "summary": "This paper presents a self-stabilizing, Byzantine-tolerant mechanism for recycling asynchronous consensus objects in distributed systems, enabling efficient reuse of a constant number of objects despite unbounded invocations and potential process failures. The solution leverages a new self-stabilizing Byzantine-tolerant synchronous multivalued consensus algorithm and combines existing techniques."
  },
  {
    "url": "https://www.lesswrong.com/posts/jiXMZHGmEf7qPrKPc/systems-that-cannot-be-unsafe-cannot-be-safe",
    "author": "Davidmanheim",
    "title": "Systems that cannot be unsafe cannot be safe",
    "published_date": "2023-05-02",
    "summary": "The author argues that assessing the safety of machine learning models, unlike traditional engineering systems, is currently meaningless because there are no established safety standards or specifications defining acceptable behavior and usage. Therefore, claims of partially safe or sufficiently safe AI models are fundamentally flawed without pre-defined standards and verification against them."
  },
  {
    "url": "https://arxiv.org/pdf/2211.17218.pdf",
    "title": "Specification Architectural Viewpoint for Benefit-Cost-Risk-Aware Decision-Making in Self-Adaptive Systems",
    "published_date": "2022-11-30",
    "abstract": "Over the past two decades, researchers and engineers have extensively studied the problem of how to enable a software system to deal with uncertain operating conditions. One prominent solution to this problem is self-adaptation, which equips a software system with a feedback loop that resolves uncertainties during operation and adapts the system to deal with them when necessary. Most self-adaptation approaches developed so far use decision-making mechanisms that focus on achieving a set of goals, i.e., that select for execution the adaptation option with the best estimated benefit. A few approaches have also considered the estimated (one-off) cost of executing the candidate adaptation options. We argue that besides benefit and cost, decision-making in self-adaptive systems should also consider the estimated risk the system or its users would be exposed to if an adaptation option were selected for execution. Balancing all three factors when evaluating the options for adaptation when mitigating uncertainty is essential, not only for satisfying the concerns of the stakeholders, but also to ensure safety and public acceptance of self-adaptive systems. In this paper, we present an ISO/IEC/IEEE 42010 compatible architectural viewpoint that considers the estimated benefit, cost, and risk as core factors of each adaptation option considered in self-adaptation. The viewpoint aims to support software architects responsible for designing robust decision-making mechanisms for self-adaptive systems.",
    "summary": "This paper proposes an architectural viewpoint, compliant with ISO/IEC/IEEE 42010, for designing robust decision-making mechanisms in self-adaptive systems by incorporating benefit, cost, and risk estimations into the selection of adaptation options. This approach aims to improve the safety and acceptance of self-adaptive systems by addressing stakeholder concerns."
  }
]
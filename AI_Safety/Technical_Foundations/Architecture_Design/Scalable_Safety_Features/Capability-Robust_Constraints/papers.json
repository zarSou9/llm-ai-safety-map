[
  {
    "url": "https://arxiv.org/abs/2402.15893",
    "title": "Concurrent Learning of Policy and Unknown Safety Constraints in Reinforcement Learning",
    "published_date": "2024-02-24",
    "abstract": "Reinforcement learning (RL) has revolutionized decision-making across a wide range of domains over the past few decades. Yet, deploying RL policies in real-world scenarios presents the crucial challenge of ensuring safety. Traditional safe RL approaches have predominantly focused on incorporating predefined safety constraints into the policy learning process. However, this reliance on predefined safety constraints poses limitations in dynamic and unpredictable real-world settings where such constraints may not be available or sufficiently adaptable. Bridging this gap, we propose a novel approach that concurrently learns a safe RL control policy and identifies the unknown safety constraint parameters of a given environment. Initializing with a parametric signal temporal logic (pSTL) safety specification and a small initial labeled dataset, we frame the problem as a bilevel optimization task, intricately integrating constrained policy optimization, using a Lagrangian-variant of the twin delayed deep deterministic policy gradient (TD3) algorithm, with Bayesian optimization for optimizing parameters for the given pSTL safety specification. Through experimentation in comprehensive case studies, we validate the efficacy of this approach across varying forms of environmental constraints, consistently yielding safe RL policies with high returns. Furthermore, our findings indicate successful learning of STL safety constraint parameters, exhibiting a high degree of conformity with true environmental safety constraints. The performance of our model closely mirrors that of an ideal scenario that possesses complete prior knowledge of safety constraints, demonstrating its proficiency in accurately identifying environmental safety constraints and learning safe policies that adhere to those constraints.",
    "summary": "This paper introduces a novel reinforcement learning method that simultaneously learns a safe policy and identifies unknown safety constraints, formulated as a bilevel optimization problem combining a modified TD3 algorithm with Bayesian optimization. Experiments demonstrate successful learning of both safe policies and accurate constraint parameters, achieving performance comparable to methods with prior constraint knowledge."
  },
  {
    "url": "https://arxiv.org/abs/2411.16608",
    "title": "Barriers on the EDGE: A scalable CBF architecture over EDGE for safe aerial-ground multi-agent coordination",
    "published_date": "2024-11-25",
    "abstract": "In this article, we address the problem of designing a scalable control architecture for a safe coordinated operation of a multi-agent system with aerial (UAVs) and ground robots (UGVs) in a confined task space. The proposed method uses Control Barrier Functions (CBFs) to impose constraints associated with (i) collision avoidance between agents, (ii) landing of UAVs on mobile UGVs, and (iii) task space restriction. Further, to account for the rapid increase in the number of constraints for a single agent with the increasing number of agents, the proposed architecture uses a centralized-decentralized Edge cluster, where a centralized node (Watcher) activates the relevant constraints, reducing the need for high onboard processing and network complexity. The distributed nodes run the controller locally to overcome latency and network issues. The proposed Edge architecture is experimentally validated using multiple aerial and ground robots in a confined environment performing a coordinated operation.",
    "summary": "This paper presents a scalable, safe multi-agent control architecture using Control Barrier Functions (CBFs) for coordinated aerial and ground robots in confined spaces, leveraging a centralized-decentralized Edge computing approach to manage constraints efficiently. Experimental validation demonstrates its effectiveness in a multi-robot environment."
  },
  {
    "url": "https://arxiv.org/abs/2409.11171",
    "title": "Preventing Unconstrained CBF Safety Filters Caused by Invalid Relative Degree Assumptions",
    "published_date": "2024-09-17",
    "abstract": "Control barrier function (CBF)-based safety filters are used to certify and modify potentially unsafe control inputs to a system such as those provided by a reinforcement learning agent or a non-expert user. In this context, safety is defined as the satisfaction of state constraints. Originally designed for continuous-time systems, CBF safety filters typically assume that the system's relative degree is well-defined and is constant across the domain; however, this assumption is restrictive and rarely verified -- even linear system dynamics with a quadratic CBF candidate may not satisfy this assumption. In real-world applications, continuous-time CBF safety filters are implemented in discrete time, exacerbating issues related to violating the condition on the relative degree. These violations can lead to the safety filter being unconstrained (any control input may be certified) for a finite time interval and result in chattering issues and constraint violations. We propose an alternative formulation to address these challenges. Specifically, we present a theoretically sound method that employs multiple CBFs to generate bounded control inputs at each state within the safe set, thereby preventing incorrect certification of arbitrary control inputs. Using this approach, we derive conditions on the maximum sampling time to ensure safety in discrete-time implementations. We demonstrate the effectiveness of our proposed method through simulations and real-world quadrotor experiments, successfully preventing chattering and constraint violations. Finally, we discuss the implications of violating the relative degree condition on CBF synthesis and learning-based CBF methods.",
    "summary": "Control barrier function (CBF) safety filters, while effective for ensuring system safety, often rely on restrictive assumptions about system relative degree that are frequently violated, leading to unconstrained controls and safety issues. This paper proposes a novel method using multiple CBFs to address these limitations, providing bounded control inputs and guaranteeing safety even with discrete-time implementations."
  },
  {
    "url": "https://arxiv.org/abs/2211.04980",
    "title": "A Capability-based Distributed Authorization System to Enforce Context-aware Permission Sequences",
    "published_date": "2022-06-07",
    "abstract": "Controlled sharing is fundamental to distributed systems. We consider a capability-based distributed authorization system where a client receives capabilities (access tokens) from an authorization server to access the resources of resource servers. Capability-based authorization systems have been widely used on the Web, in mobile applications and other distributed systems. A common requirement of such systems is that the user uses tokens of multiple servers in a particular order. A related requirement is the token may be used if certain environmental conditions hold. We introduce a secure capability-based system that supports \"permission sequence\" and \"context\". This allows a finite sequence of permissions to be enforced, each with their own specific context. We prove the safety property of this system for these conditions and integrate the system into OAuth 2.0 with proof-of-possession tokens. We evaluate our implementation and compare it with plain OAuth with respect to the average time for obtaining an authorization token and acquiring access to the resource.",
    "citation_count": 2,
    "summary": "This paper presents a secure, capability-based distributed authorization system that enforces context-aware permission sequences, proving its safety and integrating it with OAuth 2.0 for improved control over access to resources in distributed systems. The system enhances standard OAuth by adding support for ordered permissions and contextual conditions."
  },
  {
    "url": "https://arxiv.org/abs/2210.01341",
    "title": "Safe and Stable Control Synthesis for Uncertain System Models via Distributionally Robust Optimization",
    "published_date": "2022-10-04",
    "abstract": "This paper considers enforcing safety and stability of dynamical systems in the presence of model uncertainty. Safety and stability constraints may be specified using a control barrier function (CBF) and a control Lyapunov function (CLF), respectively. To take model uncertainty into account, robust and chance formulations of the constraints are commonly considered. However, this requires known error bounds or a known distribution for the model uncertainty, and the resulting formulations may suffer from over-conservatism or over-confidence. In this paper, we assume that only a finite set of model parametric uncertainty samples is available and formulate a distributionally robust chance-constrained program (DRCCP) for control synthesis with CBF safety and CLF stability guarantees. To facilitate efficient computation of control inputs during online execution, we present a reformulation of the DRCCP as a second-order cone program (SOCP). Our formulation is evaluated in an adaptive cruise control example in comparison to 1) a baseline CLF-CBF quadratic programming approach, 2) a robust approach that assumes known error bounds of the system uncertainty, and 3) a chance-constrained approach that assumes a known Gaussian Process distribution of the uncertainty.",
    "citation_count": 8,
    "summary": "This paper presents a distributionally robust chance-constrained program (DRCCP) for synthesizing safe and stable controllers for uncertain dynamical systems, using only a finite set of model uncertainty samples and reformulating the DRCCP as a computationally efficient second-order cone program (SOCP). The approach addresses limitations of existing robust and chance-constrained methods by mitigating over-conservatism and over-confidence."
  },
  {
    "url": "https://arxiv.org/pdf/2201.07286.pdf",
    "title": "Conservative Distributional Reinforcement Learning with Safety Constraints",
    "published_date": "2022-01-18",
    "abstract": "Safety exploration can be regarded as a constrained Markov decision problem where the expected long-term cost is constrained. Previous off-policy algorithms convert the constrained optimization problem into the corresponding unconstrained dual problem by introducing the Lagrangian relaxation technique. However, the cost function of the above algorithms provides inaccurate estimations and causes the instability of the Lagrange multiplier learning. In this paper, we present a novel off-policy reinforcement learning algorithm called Conservative Distributional Maximum a Posteriori Policy Optimization (CDMPO). At first, to accurately judge whether the current situation satisfies the constraints, CDMPO adapts distributional reinforcement learning method to estimate the Q-function and C-function. Then, CDMPO uses a conservative value function loss to reduce the number of violations of constraints during the exploration process. In addition, we utilize Weighted Average Proportional Integral Derivative (WAPID) to update the Lagrange multiplier stably. Empirical results show that the proposed method has fewer violations of constraints in the early exploration process. The final test results also illustrate that our method has better risk control.",
    "citation_count": 5,
    "summary": "Conservative Distributional Maximum a Posteriori Policy Optimization (CDMPO) improves upon existing constrained reinforcement learning methods by using distributional RL for more accurate constraint satisfaction assessment and a conservative value function loss to reduce constraint violations, further stabilizing Lagrange multiplier updates with WAPID. This leads to better safety and risk control during exploration."
  },
  {
    "url": "https://www.lesswrong.com/posts/rmwAuWXYTo24E5nnX/a-pin-and-a-balloon-anthropic-fragility-increases-chances-of",
    "author": "avturchin",
    "title": "A Pin and a Balloon: Anthropic Fragility Increases Chances of Runaway Global Warming",
    "published_date": "2022-09-11",
    "summary": "Due to survival bias, we likely underestimate the probability and proximity of climate tipping points, making Earth more fragile than assumed. This \"anthropic fragility\" increases the risk of human extinction via runaway global warming, necessitating urgent geoengineering research."
  },
  {
    "title": "Efficient and provable local capability revocation using uninitialized capabilities",
    "abstract": "Capability machines are a special form of CPUs that offer fine-grained privilege separation using a form of authority-carrying values known as capabilities. The CHERI capability machine offers local capabilities, which could be used as a cheap but restricted form of capability revocation. Unfortunately, local capability revocation is unrealistic in practice because large amounts of stack memory need to be cleared as a security precaution. In this paper, we address this shortcoming by introducing uninitialized capabilities: a new form of capabilities that represent read/write authority to a block of memory without exposing the memory's initial contents. We provide a mechanically verified program logic for reasoning about programs on a capability machine with the new feature and we formalize and prove capability safety in the form of a universal contract for untrusted code. We use uninitialized capabilities for making a previously-proposed secure calling convention efficient and prove its security using the program logic. Finally, we report on a proof-of-concept implementation of uninitialized capabilities on the CHERI capability machine.",
    "published_date": "2021-01-04",
    "citation_count": 28,
    "url": "https://dl.acm.org/doi/pdf/10.1145/3434287",
    "summary": "This paper introduces uninitialized capabilities for CHERI capability machines, enabling efficient local capability revocation by granting read/write access to memory without revealing initial contents; the authors provide a formally verified program logic and demonstrate a proof-of-concept implementation."
  }
]
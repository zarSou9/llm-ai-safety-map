[
  {
    "url": "https://arxiv.org/abs/2411.15832",
    "title": "Creating Scalable AGI: the Open General Intelligence Framework",
    "published_date": "2024-11-24",
    "abstract": "Recent advancements in Artificial Intelligence (AI), particularly with Large Language Models (LLMs), have led to significant progress in narrow tasks such as image classification, language translation, coding, and writing. However, these models face limitations in reliability and scalability due to their siloed architectures, which are designed to handle only one data modality (data type) at a time. This single modal approach hinders their ability to integrate the complex set of data points required for real-world challenges and problem-solving tasks like medical diagnosis, quality assurance, equipment troubleshooting, and financial decision-making. Addressing these real-world challenges requires a more capable Artificial General Intelligence (AGI) system. Our primary contribution is the development of the Open General Intelligence (OGI) framework, a novel systems architecture that serves as a macro design reference for AGI. The OGI framework adopts a modular approach to the design of intelligent systems, based on the premise that cognition must occur across multiple specialized modules that can seamlessly operate as a single system. OGI integrates these modules using a dynamic processing system and a fabric interconnect, enabling real-time adaptability, multi-modal integration, and scalable processing. The OGI framework consists of three key components: (1) Overall Macro Design Guidance that directs operational design and processing, (2) a Dynamic Processing System that controls routing, primary goals, instructions, and weighting, and (3) Framework Areas, a set of specialized modules that operate cohesively to form a unified cognitive system. By incorporating known principles from human cognition into AI systems, the OGI framework aims to overcome the challenges observed in today's intelligent systems, paving the way for more holistic and context-aware problem-solving capabilities.",
    "summary": "The Open General Intelligence (OGI) framework proposes a modular, multi-modal architecture for Artificial General Intelligence (AGI), addressing limitations of current single-modality AI systems by integrating specialized modules via a dynamic processing system for scalable and adaptable problem-solving."
  },
  {
    "url": "https://arxiv.org/abs/2408.02920",
    "title": "A Taxonomy of Architecture Options for Foundation Model-based Agents: Analysis and Decision Model",
    "published_date": "2024-08-06",
    "abstract": "The rapid advancement of AI technology has led to widespread applications of agent systems across various domains. However, the need for detailed architecture design poses significant challenges in designing and operating these systems. This paper introduces a taxonomy focused on the architectures of foundation-model-based agents, addressing critical aspects such as functional capabilities and non-functional qualities. We also discuss the operations involved in both design-time and run-time phases, providing a comprehensive view of architectural design and operational characteristics. By unifying and detailing these classifications, our taxonomy aims to improve the design of foundation-model-based agents. Additionally, the paper establishes a decision model that guides critical design and runtime decisions, offering a structured approach to enhance the development of foundation-model-based agents. Our contributions include providing a structured architecture design option and guiding the development process of foundation-model-based agents, thereby addressing current fragmentation in the field.",
    "summary": "This paper presents a taxonomy of architectures for foundation-model-based agents, classifying them by functional and non-functional characteristics and operational phases, alongside a decision model to guide their design and deployment. This framework aims to improve the development process for these agents by addressing current architectural fragmentation."
  },
  {
    "url": "https://arxiv.org/pdf/2301.08138.pdf",
    "title": "Architecting Safer Autonomous Aviation Systems",
    "published_date": "2023-01-09",
    "abstract": "The aviation literature gives relatively little guidance to practitioners about the specifics of architecting systems for safety, particularly the impact of architecture on allocating safety requirements, or the relative ease of system assurance resulting from system or subsystem level architectural choices. As an exemplar, this paper considers common architectural patterns used within traditional aviation systems and explores their safety and safety assurance implications when applied in the context of integrating artificial intelligence (AI) and machine learning ( ML ) based functionality. Considering safety as an architectural property, we discuss both the allocation of safety requirements and the architectural trade-offs involved early in the design lifecycle. This approach could be extended to other assured properties, similar to safety, such as security. We conclude with a discussion of the safety considerations that emerge in the context of candidate architectural patterns that have been proposed in the recent literature for enabling autonomy capabilities by integrating AI and ML. A recommendation is made for the generation of a property-driven architectural pattern catalogue.",
    "citation_count": 2,
    "summary": "This paper analyzes how different architectural patterns impact the safety and assurance of autonomous aviation systems incorporating AI/ML, emphasizing early allocation of safety requirements and architectural trade-offs. It advocates for a property-driven architectural pattern catalogue to guide safer system design."
  },
  {
    "url": "https://www.alignmentforum.org/tag/modularity",
    "author": "Nicky Pochinkov",
    "title": "Modularity - AI Alignment Forum",
    "published_date": "2023-03-26",
    "summary": "Modularity, the degree to which a system is divisible into clusters, is a widely applicable concept, influencing fields like graph theory and evolutionary biology, and potentially crucial for understanding complex systems like artificial intelligence."
  },
  {
    "url": "https://www.lesswrong.com/posts/j84JhErNezMxyK4dH/llm-modularity-the-separability-of-capabilities-in-large",
    "author": "NickyP",
    "title": "LLM Modularity: The Separability of Capabilities in Large Language Models",
    "published_date": "2023-03-26",
    "summary": "This research investigates the modularity of Large Language Models (LLMs) by exploring the separability of their capabilities. The author attempts to prune LLMs to remove specific abilities, like coding, achieving partial success (up to 75% separability) and finding evidence that larger models exhibit greater separability."
  },
  {
    "url": "https://www.lesswrong.com/posts/zYv9BQBGnk2EdCwoG/the-psyche-of-ai-pattern-recognition",
    "author": "Scott Broock",
    "title": "AI and the Map of Your Mind: Pattern Recognition",
    "published_date": "2023-03-20",
    "summary": "Integrating large language models into productivity suites allows AI to create personalized knowledge graphs from user data, potentially revolutionizing learning and decision-making by revealing hidden connections and patterns. However, this access to personal data raises concerns about privacy and the implications for understanding the human psyche."
  },
  {
    "url": "https://arxiv.org/pdf/2203.00905.pdf",
    "title": "Responsible-AI-by-Design: a Pattern Collection for Designing Responsible AI Systems",
    "published_date": "2022-03-02",
    "abstract": "Although AI has significant potential to transform society, there are serious concerns about its ability to behave and make decisions responsibly. Many ethical regulations, principles, and guidelines for responsible AI have been issued recently. However, these principles are high-level and difficult to put into practice. In the meantime much effort has been put into responsible AI from the algorithm perspective, but they are limited to a small subset of ethical principles amenable to mathematical analysis. Responsible AI issues go beyond data and algorithms and are often at the system-level crosscutting many system components and the entire software engineering lifecycle. Based on the result of a systematic literature review, this paper identifies one missing element as the system-level guidance - how to design the architecture of responsible AI systems. We present a summary of design patterns that can be embedded into the AI systems as product features to contribute to responsible-AI-by-design.",
    "citation_count": 17,
    "summary": "This paper addresses the gap in practical guidance for designing responsible AI systems by presenting a collection of design patterns derived from a systematic literature review, aiming to embed responsible AI features directly into system architecture. These patterns offer system-level guidance, moving beyond algorithm-focused approaches to address broader ethical concerns throughout the software development lifecycle."
  },
  {
    "url": "https://arxiv.org/abs/2206.05273",
    "title": "A General Framework for the Representation of Function and Affordance: A Cognitive, Causal, and Grounded Approach, and a Step Toward AGI",
    "published_date": "2022-06-02",
    "abstract": "The function and affordance of natural or artificial objects and various physical constructs feature prominently in the functioning of an intelligent system or an intelligent autonomous system (IAS). In navigating an environment, an IAS needs to understand the function and affordance of roads, stairs, bridges, and various physical constructs that may assist with or obstruct its movement to achieve its goal(s). When encountering objects, understanding their function and affordance so that they may be manipulated or made use of to support the IAS in performing certain required tasks is a key aspect of the intelligent functioning of the IAS. In AI research, so far, the attention paid to the characterization and representation of function and affordance has been sporadic and sparse, and it has not received the same attention as, say, object categorization or natural language processing, even though this aspect features prominently in an intelligent system's functioning, and is more fundamental and important in many ways. In the sporadic and sparse, though commendable efforts so far devoted to the characterization and understanding of function and affordance, there has also been no general framework that could unify all the different use domains and situations related to functionality, and that could provide an intelligent system or an IAS the necessary computational, representational, processing, and reasoning constructs to effect recognition, generation, and application of functional concepts. This paper develops just such a general framework, with an approach that emphasizes the fact that the representations involved must be explicitly cognitive and conceptual, and they must also contain the causal characterizations of the events and processes involved, as well as employ conceptual constructs that are grounded in the referents to which they refer, in order to achieve maximal generality for the framework to be applicable to a wide range of domains and situations. The basic general framework is described, along with a set of basic guiding principles with regards to representation of functionality. To properly and adequately characterize and represent functionality, a descriptive representation language is needed. This language is defined and developed, and many examples of its use are described. The general framework is developed based on an extension of the general language meaning representational framework called conceptual dependency. To support the general characterization and representation of functionality, the basic conceptual dependency framework is enhanced with representational devices called structure anchor and conceptual dependency elaboration, together with the definition of a set of ground level concepts. These novel representational constructs are defined, developed, and described. A general framework dealing with functionality would represent a major step toward achieving Artificial General Intelligence.",
    "citation_count": 4,
    "summary": "This paper proposes a novel general framework for representing function and affordance in artificial intelligence, addressing a significant gap in current research. The framework, based on an enhanced conceptual dependency representation, incorporates cognitive, causal, and grounded aspects to enable intelligent systems to recognize, generate, and utilize functional concepts across diverse domains, thus advancing the field towards Artificial General Intelligence."
  }
]
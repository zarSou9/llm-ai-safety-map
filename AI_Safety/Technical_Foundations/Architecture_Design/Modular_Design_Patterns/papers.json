[
  {
    "url": "https://arxiv.org/abs/2411.15832",
    "title": "Creating Scalable AGI: the Open General Intelligence Framework",
    "published_date": "2024-11-24",
    "abstract": "Recent advancements in Artificial Intelligence (AI), particularly with Large Language Models (LLMs), have led to significant progress in narrow tasks such as image classification, language translation, coding, and writing. However, these models face limitations in reliability and scalability due to their siloed architectures, which are designed to handle only one data modality (data type) at a time. This single modal approach hinders their ability to integrate the complex set of data points required for real-world challenges and problem-solving tasks like medical diagnosis, quality assurance, equipment troubleshooting, and financial decision-making. Addressing these real-world challenges requires a more capable Artificial General Intelligence (AGI) system. Our primary contribution is the development of the Open General Intelligence (OGI) framework, a novel systems architecture that serves as a macro design reference for AGI. The OGI framework adopts a modular approach to the design of intelligent systems, based on the premise that cognition must occur across multiple specialized modules that can seamlessly operate as a single system. OGI integrates these modules using a dynamic processing system and a fabric interconnect, enabling real-time adaptability, multi-modal integration, and scalable processing. The OGI framework consists of three key components: (1) Overall Macro Design Guidance that directs operational design and processing, (2) a Dynamic Processing System that controls routing, primary goals, instructions, and weighting, and (3) Framework Areas, a set of specialized modules that operate cohesively to form a unified cognitive system. By incorporating known principles from human cognition into AI systems, the OGI framework aims to overcome the challenges observed in today's intelligent systems, paving the way for more holistic and context-aware problem-solving capabilities.",
    "summary": "The Open General Intelligence (OGI) framework proposes a modular, multi-modal architecture for Artificial General Intelligence (AGI), aiming to overcome limitations of current single-modality AI systems by integrating specialized modules via a dynamic processing system for improved scalability and real-world problem-solving."
  },
  {
    "url": "https://www.lesswrong.com/posts/2po6bp2gCHzxaccNz/ai-as-systems-not-just-models",
    "author": "Andy Arditi",
    "title": "AI as systems, not just models",
    "published_date": "2024-12-21",
    "summary": "The article advocates shifting focus from analyzing individual AI models to examining the complete AI systems they comprise. This systems-based perspective considers not only the model itself but also crucial elements like prompting strategies, sampling methods, and tool integration, recognizing that a model's capabilities are fundamentally shaped by the system in which it operates."
  },
  {
    "url": "https://arxiv.org/pdf/2301.08138.pdf",
    "title": "Architecting Safer Autonomous Aviation Systems",
    "published_date": "2023-01-09",
    "abstract": "The aviation literature gives relatively little guidance to practitioners about the specifics of architecting systems for safety, particularly the impact of architecture on allocating safety requirements, or the relative ease of system assurance resulting from system or subsystem level architectural choices. As an exemplar, this paper considers common architectural patterns used within traditional aviation systems and explores their safety and safety assurance implications when applied in the context of integrating artificial intelligence (AI) and machine learning ( ML ) based functionality. Considering safety as an architectural property, we discuss both the allocation of safety requirements and the architectural trade-offs involved early in the design lifecycle. This approach could be extended to other assured properties, similar to safety, such as security. We conclude with a discussion of the safety considerations that emerge in the context of candidate architectural patterns that have been proposed in the recent literature for enabling autonomy capabilities by integrating AI and ML. A recommendation is made for the generation of a property-driven architectural pattern catalogue.",
    "citation_count": 2,
    "summary": "This paper examines how architectural choices impact safety and assurance in autonomous aviation systems, particularly when integrating AI/ML, advocating for early consideration of safety requirements allocation and architectural trade-offs. It proposes creating a property-driven architectural pattern catalogue to guide safer system design."
  },
  {
    "url": "https://arxiv.org/pdf/2303.13173.pdf",
    "title": "Design Patterns for AI-based Systems: A Multivocal Literature Review and Pattern Repository",
    "published_date": "2023-03-23",
    "abstract": "Systems with artificial intelligence components, so-called AI-based systems, have gained considerable attention recently. However, many organizations have issues with achieving production readiness with such systems. As a means to improve certain software quality attributes and to address frequently occurring problems, design patterns represent proven solution blueprints. While new patterns for AI-based systems are emerging, existing patterns have also been adapted to this new context.The goal of this study is to provide an overview of design patterns for AI-based systems, both new and adapted ones. We want to collect and categorize patterns, and make them accessible for researchers and practitioners. To this end, we first performed a multivocal literature review (MLR) to collect design patterns used with AI-based systems. We then integrated the created pattern collection into a web-based pattern repository to make the patterns browsable and easy to find.As a result, we selected 51 resources (35 white and 16 gray ones), from which we extracted 70 unique patterns used for AI-based systems. Among these are 34 new patterns and 36 traditional ones that have been adapted to this context. Popular pattern categories include architecture (25 patterns), deployment (16), implementation (9), or security & safety (9). While some patterns with four or more mentions already seem established, the majority of patterns have only been mentioned once or twice (51 patterns). Our results in this emerging field can be used by researchers as a foundation for follow-up studies and by practitioners to discover relevant patterns for informing the design of AI-based systems.",
    "citation_count": 7,
    "summary": "This paper presents a multivocal literature review and resulting web-based repository of 70 design patterns for AI-based systems, categorizing them across architecture, deployment, implementation, and security/safety, to aid researchers and practitioners in building production-ready AI systems. The repository includes both newly identified and adapted traditional patterns."
  },
  {
    "url": "https://arxiv.org/abs/2304.11090",
    "title": "A Reference Architecture for Designing Foundation Model based Systems",
    "published_date": "2023-04-13",
    "abstract": "The release of ChatGPT, Gemini, and other large language model has drawn huge interests on foundations models. There is a broad consensus that foundations models will be the fundamental building blocks for future AI systems. However, there is a lack of systematic guidance on the architecture design. Particularly, the the rapidly growing capabilities of foundations models can eventually absorb other components of AI systems, posing challenges of moving boundary and interface evolution in architecture design. Furthermore, incorporating foundations models into AI systems raises significant concerns about responsible and safe AI due to their opaque nature and rapidly advancing intelligence. To address these challenges, the paper first presents an architecture evolution of AI systems in the era of foundation models, transitioning from\"foundation-model-as-a-connector\"to\"foundation-model-as-a-monolithic architecture\". The paper then identifies key design decisions and proposes a pattern-oriented reference architecture for designing responsible foundation-model-based systems. The patterns can enable the potential of foundation models while ensuring associated risks.",
    "citation_count": 2,
    "summary": "This paper proposes a reference architecture for designing AI systems built upon foundation models like ChatGPT, addressing the challenges of evolving system boundaries and integrating responsible AI practices as foundation models' capabilities grow. The architecture transitions from using foundation models as components to incorporating them as a monolithic core, offering patterns for managing associated risks."
  },
  {
    "url": "https://www.alignmentforum.org/tag/modularity",
    "author": "Nicky Pochinkov",
    "title": "Modularity - AI Alignment Forum",
    "published_date": "2023-03-26",
    "summary": "Modularity, the degree to which a system is divisible into clusters, is a broad concept applicable across diverse fields like graph theory and evolutionary biology. Its relevance to AI alignment stems from the hypothesis that modular systems are easier to understand at a high-level cognitive abstraction."
  },
  {
    "url": "https://www.lesswrong.com/posts/j84JhErNezMxyK4dH/llm-modularity-the-separability-of-capabilities-in-large",
    "author": "NickyP",
    "title": "LLM Modularity: The Separability of Capabilities in Large Language Models",
    "published_date": "2023-03-26",
    "summary": "The author investigates the \"separability\" of capabilities within large language models (LLMs) by attempting to prune LLMs to remove specific functionalities, like coding, while preserving others. Initial findings suggest some degree of separability, particularly with larger models, indicating that feed-forward layers are more task-specific than attention heads."
  },
  {
    "url": "https://www.lesswrong.com/tag/open-agency-architecture",
    "author": "Charbel-Raphaël, Gabin",
    "title": "Open Agency Architecture - LessWrong",
    "published_date": "2023-04-19",
    "summary": "Open Agency Architecture (OAA) is an AI alignment proposal aiming to create provably safe AI, detailed in David A.D.'s work and further developed by organizations like Atlas Computing. A related, but distinct, approach is the Gaia Network."
  },
  {
    "url": "https://arxiv.org/pdf/2203.00905.pdf",
    "title": "Responsible-AI-by-Design: a Pattern Collection for Designing Responsible AI Systems",
    "published_date": "2022-03-02",
    "abstract": "Although AI has significant potential to transform society, there are serious concerns about its ability to behave and make decisions responsibly. Many ethical regulations, principles, and guidelines for responsible AI have been issued recently. However, these principles are high-level and difficult to put into practice. In the meantime much effort has been put into responsible AI from the algorithm perspective, but they are limited to a small subset of ethical principles amenable to mathematical analysis. Responsible AI issues go beyond data and algorithms and are often at the system-level crosscutting many system components and the entire software engineering lifecycle. Based on the result of a systematic literature review, this paper identifies one missing element as the system-level guidance - how to design the architecture of responsible AI systems. We present a summary of design patterns that can be embedded into the AI systems as product features to contribute to responsible-AI-by-design.",
    "citation_count": 17,
    "summary": "This paper addresses the lack of system-level guidance for designing responsible AI, presenting a collection of design patterns that can be integrated into AI systems to promote responsible AI development throughout the software lifecycle. These patterns aim to translate high-level ethical principles into practical, implementable features."
  },
  {
    "url": "https://arxiv.org/pdf/2212.13570.pdf",
    "title": "A Compositional Approach to Creating Architecture Frameworks with an Application to Distributed AI Systems",
    "published_date": "2022-12-27",
    "abstract": "Artificial intelligence (AI) in its various forms finds more and more its way into complex distributed systems. For instance, it is used locally, as part of a sensor system, on the edge for low-latency high-performance inference, or in the cloud, e.g. for data mining. Modern complex systems, such as connected vehicles, are often part of an Internet of Things (IoT). To manage complexity, architectures are described with architecture frameworks, which are composed of a number of architectural views connected through correspondence rules. Despite some attempts, the definition of a mathematical foundation for architecture frameworks that are suitable for the development of distributed AI systems still requires investigation and study. In this paper, we propose to extend the state of the art on architecture framework by providing a mathematical model for system architectures, which is scalable and supports co-evolution of different aspects for example of an AI system. Based on Design Science Research, this study starts by identifying the challenges with architectural frameworks. Then, we derive from the identified challenges four rules and we formulate them by exploiting concepts from category theory. We show how compositional thinking can provide rules for the creation and management of architectural frameworks for complex systems, for example distributed systems with AI. The aim of the paper is not to provide viewpoints or architecture models specific to AI systems, but instead to provide guidelines based on a mathematical formulation on how a consistent framework can be built up with existing, or newly created, viewpoints. To put in practice and test the approach, the identified and formulated rules are applied to derive an architectural framework for the EU Horizon 2020 project ``Very efficient deep learning in the IoT\"(VEDLIoT) in the form of a case study.",
    "citation_count": 15,
    "summary": "This paper proposes a novel mathematical model, based on category theory, for creating scalable and adaptable architecture frameworks for complex distributed AI systems, addressing challenges in existing approaches by defining compositional rules for managing different architectural views. The model is applied to a real-world case study, demonstrating its practical utility in framework development."
  }
]
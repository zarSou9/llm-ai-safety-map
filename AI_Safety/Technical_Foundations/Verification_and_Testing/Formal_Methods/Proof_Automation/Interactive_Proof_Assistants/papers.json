[
  {
    "url": "https://arxiv.org/abs/2410.16429",
    "title": "Pantograph: A Machine-to-Machine Interaction Interface for Advanced Theorem Proving, High Level Reasoning, and Data Extraction in Lean 4",
    "published_date": "2024-10-21",
    "abstract": "Machine-assisted theorem proving refers to the process of conducting structured reasoning to automatically generate proofs for mathematical theorems. Recently, there has been a surge of interest in using machine learning models in conjunction with proof assistants to perform this task. In this paper, we introduce Pantograph, a tool that provides a versatile interface to the Lean 4 proof assistant and enables efficient proof search via powerful search algorithms such as Monte Carlo Tree Search. In addition, Pantograph enables high-level reasoning by enabling a more robust handling of Lean 4's inference steps. We provide an overview of Pantograph's architecture and features. We also report on an illustrative use case: using machine learning models and proof sketches to prove Lean 4 theorems. Pantograph's innovative features pave the way for more advanced machine learning models to perform complex proof searches and high-level reasoning, equipping future researchers to design more versatile and powerful theorem provers."
  },
  {
    "url": "https://arxiv.org/abs/2409.13872",
    "title": "Don't Call Us, We'll Call You: Towards Mixed-Initiative Interactive Proof Assistants for Programming Language Theory",
    "published_date": "2024-09-20",
    "abstract": "There are two kinds of systems that programming language researchers use for their work. Semantics engineering tools let them interactively explore their definitions, while proof assistants can be used to check the proofs of their properties. The disconnect between the two kinds of systems leads to errors in accepted publications and also limits the modes of interaction available when writing proofs. When constructing a proof, one typically states the property and then develops the proof manually until an automatic strategy can fill the remaining gaps. We believe that an integrated and more interactive tool that leverages the typical structure of programming language could do better. A proof assistant aware of the typical structure of programming language proofs could require less human input, assist the user in understanding their proofs, but also use insights from the exploration of executable semantics in proof construction. In the early work presented in this paper, we focus on the problem of interacting with a proof assistant and leave the semantics engineering part to the future. Rather than starting with manual proof construction and then completing the last steps automatically, we propose a way of working where the tool starts with an automatic proof search and then breaks when it requires feedback from the user. We build a small proof assistant that follows this mode of interaction and illustrates the idea using a simple proof of the commutativity of the\"+\"operation for Peano arithmetic. Our early experience suggests that this way of working can make proof construction easier."
  },
  {
    "url": "https://arxiv.org/abs/2403.03401",
    "title": "BAIT: Benchmarking (Embedding) Architectures for Interactive Theorem-Proving",
    "published_date": "2024-03-06",
    "abstract": "Artificial Intelligence for Theorem Proving (AITP) has given\nrise to a plethora of benchmarks and methodologies, particularly in Interactive Theorem Proving (ITP). Research in the\narea is fragmented, with a diverse set of approaches being\nspread across several ITP systems. This presents a significant challenge to the comparison of methods, which are often\ncomplex and difficult to replicate.\nAddressing this, we present BAIT, a framework for the fair\nand streamlined comparison of learning approaches in ITP.\nWe demonstrate BAIT's capabilities with an in-depth comparison, across several ITP benchmarks, of state-of-the-art\narchitectures applied to the problem of formula embedding.\nWe find that Structure Aware Transformers perform particularly well, improving on techniques associated with the original problem sets. BAIT also allows us to assess the end-to-end proving performance of systems built on interactive\nenvironments. This unified perspective reveals a novel end-to-end system that improves on prior work. We also provide\na qualitative analysis, illustrating that improved performance\nis associated with more semantically-aware embeddings. By\nstreamlining the implementation and comparison of Machine\nLearning algorithms in the ITP context, we anticipate BAIT\nwill be a springboard for future research.",
    "citation_count": 2
  },
  {
    "url": "https://arxiv.org/abs/2406.07340",
    "title": "Formally Verified Approximate Policy Iteration",
    "published_date": "2024-06-11",
    "abstract": "We formally verify an algorithm for approximate policy iteration on Factored Markov Decision Processes using the interactive theorem prover Isabelle/HOL. Next, we show how the formalized algorithm can be refined to an executable, verified implementation. The implementation is evaluated on benchmark problems to show its practicability. As part of the refinement, we develop verified software to certify Linear Programming solutions. The algorithm builds on a diverse library of formalized mathematics and pushes existing methodologies for interactive theorem provers to the limits. We discuss the process of the verification project and the modifications to the algorithm needed for formal verification."
  },
  {
    "url": "https://arxiv.org/abs/2410.04753",
    "title": "ImProver: Agent-Based Automated Proof Optimization",
    "published_date": "2024-10-07",
    "abstract": "Large language models (LLMs) have been used to generate formal proofs of mathematical theorems in proofs assistants such as Lean. However, we often want to optimize a formal proof with respect to various criteria, depending on its downstream use. For example, we may want a proof to adhere to a certain style, or to be readable, concise, or modularly structured. Having suitably optimized proofs is also important for learning tasks, especially since human-written proofs may not optimal for that purpose. To this end, we study a new problem of automated proof optimization: rewriting a proof so that it is correct and optimizes for an arbitrary criterion, such as length or readability. As a first method for automated proof optimization, we present ImProver, a large-language-model agent that rewrites proofs to optimize arbitrary user-defined metrics in Lean. We find that naively applying LLMs to proof optimization falls short, and we incorporate various improvements into ImProver, such as the use of symbolic Lean context in a novel Chain-of-States technique, as well as error-correction and retrieval. We test ImProver on rewriting real-world undergraduate, competition, and research-level mathematics theorems, finding that ImProver is capable of rewriting proofs so that they are substantially shorter, more modular, and more readable."
  },
  {
    "url": "https://arxiv.org/abs/2412.16075",
    "title": "Formal Mathematical Reasoning: A New Frontier in AI",
    "published_date": "2024-12-20",
    "abstract": "AI for Mathematics (AI4Math) is not only intriguing intellectually but also crucial for AI-driven discovery in science, engineering, and beyond. Extensive efforts on AI4Math have mirrored techniques in NLP, in particular, training large language models on carefully curated math datasets in text form. As a complementary yet less explored avenue, formal mathematical reasoning is grounded in formal systems such as proof assistants, which can verify the correctness of reasoning and provide automatic feedback. In this position paper, we advocate for formal mathematical reasoning and argue that it is indispensable for advancing AI4Math to the next level. In recent years, we have seen steady progress in using AI to perform formal reasoning, including core tasks such as theorem proving and autoformalization, as well as emerging applications such as verifiable generation of code and hardware designs. However, significant challenges remain to be solved for AI to truly master mathematics and achieve broader impact. We summarize existing progress, discuss open challenges, and envision critical milestones to measure future success. At this inflection point for formal mathematical reasoning, we call on the research community to come together to drive transformative advancements in this field."
  }
]
[
  {
    "url": "https://arxiv.org/abs/1905.11374v2",
    "title": "A unifying causal framework for analyzing dataset shift-stable learning algorithms",
    "published_date": "2019-05-27",
    "abstract": "Abstract Recent interest in the external validity of prediction models (i.e., the problem of different train and test distributions, known as dataset shift) has produced many methods for finding predictive distributions that are invariant to dataset shifts and can be used for prediction in new, unseen environments. However, these methods consider different types of shifts and have been developed under disparate frameworks, making it difficult to theoretically analyze how solutions differ with respect to stability and accuracy. Taking a causal graphical view, we use a flexible graphical representation to express various types of dataset shifts. Given a known graph of the data generating process, we show that all invariant distributions correspond to a causal hierarchy of graphical operators, which disable the edges in the graph that are responsible for the shifts. The hierarchy provides a common theoretical underpinning for understanding when and how stability to shifts can be achieved, and in what ways stable distributions can differ. We use it to establish conditions for minimax optimal performance across environments, and derive new algorithms that find optimal stable distributions. By using this new perspective, we empirically demonstrate that that there is a tradeoff between minimax and average performance.",
    "citation_count": 15,
    "summary": "This paper presents a unifying causal framework for analyzing dataset shift-stable learning algorithms, using causal graphs to represent various shift types and demonstrating that invariant distributions correspond to a hierarchy of graphical operators that remove shift-causing edges, enabling analysis of stability and optimality tradeoffs. This framework provides conditions for minimax optimal performance and leads to new algorithms for finding optimal stable distributions."
  },
  {
    "url": "https://arxiv.org/abs/2012.07421v2",
    "title": "WILDS: A Benchmark of in-the-Wild Distribution Shifts",
    "published_date": "2020-12-14",
    "abstract": "Distribution shifts -- where the training distribution differs from the test distribution -- can substantially degrade the accuracy of machine learning (ML) systems deployed in the wild. Despite their ubiquity in the real-world deployments, these distribution shifts are under-represented in the datasets widely used in the ML community today. To address this gap, we present WILDS, a curated benchmark of 10 datasets reflecting a diverse range of distribution shifts that naturally arise in real-world applications, such as shifts across hospitals for tumor identification; across camera traps for wildlife monitoring; and across time and location in satellite imaging and poverty mapping. On each dataset, we show that standard training yields substantially lower out-of-distribution than in-distribution performance. This gap remains even with models trained by existing methods for tackling distribution shifts, underscoring the need for new methods for training models that are more robust to the types of distribution shifts that arise in practice. To facilitate method development, we provide an open-source package that automates dataset loading, contains default model architectures and hyperparameters, and standardizes evaluations. Code and leaderboards are available at https://wilds.stanford.edu.",
    "citation_count": 1260,
    "summary": "WILDS is a new benchmark of ten real-world datasets exhibiting diverse distribution shifts, highlighting the inadequacy of current methods in handling such shifts and providing an open-source package to facilitate the development of more robust machine learning models. The benchmark reveals significant performance drops when moving from in-distribution to out-of-distribution data, even with existing distribution shift mitigation techniques."
  },
  {
    "url": "https://arxiv.org/abs/2110.11328",
    "title": "A Fine-Grained Analysis on Distribution Shift",
    "published_date": "2021-10-21",
    "abstract": "Robustness to distribution shifts is critical for deploying machine learning models in the real world. Despite this necessity, there has been little work in defining the underlying mechanisms that cause these shifts and evaluating the robustness of algorithms across multiple, different distribution shifts. To this end, we introduce a framework that enables fine-grained analysis of various distribution shifts. We provide a holistic analysis of current state-of-the-art methods by evaluating 19 distinct methods grouped into five categories across both synthetic and real-world datasets. Overall, we train more than 85K models. Our experimental framework can be easily extended to include new methods, shifts, and datasets. We find, unlike previous work~\\citep{Gulrajani20}, that progress has been made over a standard ERM baseline; in particular, pretraining and augmentations (learned or heuristic) offer large gains in many cases. However, the best methods are not consistent over different datasets and shifts.",
    "citation_count": 184,
    "summary": "This paper presents a framework for fine-grained analysis of distribution shifts in machine learning, evaluating 19 methods across diverse datasets and revealing that while pretraining and augmentations improve robustness, optimal performance varies significantly across different shift types and datasets."
  },
  {
    "url": "https://arxiv.org/pdf/2309.08825.pdf",
    "title": "Distributionally Robust Post-hoc Classifiers under Prior Shifts",
    "published_date": "2023-09-16",
    "abstract": "The generalization ability of machine learning models degrades significantly when the test distribution shifts away from the training distribution. We investigate the problem of training models that are robust to shifts caused by changes in the distribution of class-priors or group-priors. The presence of skewed training priors can often lead to the models overfitting to spurious features. Unlike existing methods, which optimize for either the worst or the average performance over classes or groups, our work is motivated by the need for finer control over the robustness properties of the model. We present an extremely lightweight post-hoc approach that performs scaling adjustments to predictions from a pre-trained model, with the goal of minimizing a distributionally robust loss around a chosen target distribution. These adjustments are computed by solving a constrained optimization problem on a validation set and applied to the model during test time. Our constrained optimization objective is inspired by a natural notion of robustness to controlled distribution shifts. Our method comes with provable guarantees and empirically makes a strong case for distributional robust post-hoc classifiers. An empirical implementation is available at https://github.com/weijiaheng/Drops.",
    "citation_count": 15,
    "summary": "This paper introduces a lightweight post-hoc method for improving the robustness of classifiers to prior shifts, using a constrained optimization on a validation set to scale predictions from a pre-trained model and minimize a distributionally robust loss. This approach offers finer control over robustness than existing methods and comes with theoretical guarantees."
  },
  {
    "url": "https://www.lesswrong.com/posts/TRKF9g65nhPBQoxJu/distribution-shifts-and-the-importance-of-ai-safety",
    "author": "Leon Lang",
    "title": "Distribution Shifts and The Importance of AI Safety",
    "published_date": "2022-09-29",
    "summary": "The article argues that the distribution shift problem in machine learning poses an existential risk, as increasingly powerful AI systems may become misaligned with human goals due to unforeseen changes in input data. This misalignment, potentially leading to humanity's disempowerment, necessitates increased focus on AI safety research."
  },
  {
    "url": "https://arxiv.org/pdf/2106.14999.pdf",
    "title": "Test-Time Adaptation to Distribution Shift by Confidence Maximization and Input Transformation",
    "published_date": "2021-06-28",
    "abstract": "Deep neural networks often exhibit poor performance on data that is unlikely under the train-time data distribution, for instance data affected by corruptions. Previous works demonstrate that test-time adaptation to data shift, for instance using entropy minimization, effectively improves performance on such shifted distributions. This paper focuses on the fully test-time adaptation setting, where only unlabeled data from the target distribution is required. This allows adapting arbitrary pretrained networks. Specifically, we propose a novel loss that improves test-time adaptation by addressing both premature convergence and instability of entropy minimization. This is achieved by replacing the entropy by a non-saturating surrogate and adding a diversity regularizer based on batch-wise entropy maximization that prevents convergence to trivial collapsed solutions. Moreover, we propose to prepend an input transformation module to the network that can partially undo test-time distribution shifts. Surprisingly, this preprocessing can be learned solely using the fully test-time adaptation loss in an end-to-end fashion without any target domain labels or source domain data. We show that our approach outperforms previous work in improving the robustness of publicly available pretrained image classifiers to common corruptions on such challenging benchmarks as ImageNet-C.",
    "citation_count": 63,
    "summary": "This paper introduces a novel test-time adaptation method for deep neural networks that improves robustness to distribution shifts by using a non-saturating loss function with a diversity regularizer and a learned input transformation module, all trained without target domain labels. The method outperforms prior approaches on corrupted image datasets like ImageNet-C."
  },
  {
    "url": "https://arxiv.org/pdf/2104.13326v2.pdf",
    "title": "Fast Distributionally Robust Learning with Variance Reduced Min-Max Optimization",
    "published_date": "2021-04-27",
    "abstract": "Distributionally robust supervised learning (DRSL) is emerging as a key paradigm for building reliable machine learning systems for real-world applications -- reflecting the need for classifiers and predictive models that are robust to the distribution shifts that arise from phenomena such as selection bias or nonstationarity. Existing algorithms for solving Wasserstein DRSL -- one of the most popular DRSL frameworks based around robustness to perturbations in the Wasserstein distance -- have serious limitations that limit their use in large-scale problems -- in particular they involve solving complex subproblems and they fail to make use of stochastic gradients. We revisit Wasserstein DRSL through the lens of min-max optimization and derive scalable and efficiently implementable stochastic extra-gradient algorithms which provably achieve faster convergence rates than existing approaches. We demonstrate their effectiveness on synthetic and real data when compared to existing DRSL approaches. Key to our results is the use of variance reduction and random reshuffling to accelerate stochastic min-max optimization, the analysis of which may be of independent interest.",
    "citation_count": 22,
    "summary": "This paper introduces scalable stochastic extra-gradient algorithms for Wasserstein distributionally robust supervised learning, achieving faster convergence than existing methods by employing variance reduction and random reshuffling within a min-max optimization framework. These algorithms address limitations of previous approaches in handling large-scale problems."
  },
  {
    "url": "https://arxiv.org/abs/2107.07455v1",
    "title": "Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks",
    "published_date": "2021-07-15",
    "abstract": "There has been significant research done on developing methods for improving robustness to distributional shift and uncertainty estimation. In contrast, only limited work has examined developing standard datasets and benchmarks for assessing these approaches. Additionally, most work on uncertainty estimation and robustness has developed new techniques based on small-scale regression or image classification tasks. However, many tasks of practical interest have different modalities, such as tabular data, audio, text, or sensor data, which offer significant challenges involving regression and discrete or continuous structured prediction. Thus, given the current state of the field, a standardized large-scale dataset of tasks across a range of modalities affected by distributional shifts is necessary. This will enable researchers to meaningfully evaluate the plethora of recently developed uncertainty quantification methods, as well as assessment criteria and state-of-the-art baselines. In this work, we propose the Shifts Dataset for evaluation of uncertainty estimates and robustness to distributional shift. The dataset, which has been collected from industrial sources and services, is composed of three tasks, with each corresponding to a particular data modality: tabular weather prediction, machine translation, and self-driving car (SDC) vehicle motion prediction. All of these data modalities and tasks are affected by real,\"in-the-wild\"distributional shifts and pose interesting challenges with respect to uncertainty estimation. In this work we provide a description of the dataset and baseline results for all tasks.",
    "citation_count": 114,
    "summary": "The Shifts dataset provides a large-scale benchmark for evaluating robustness to distributional shifts and uncertainty quantification methods across diverse modalities (tabular, text, sensor data) using three real-world tasks: weather prediction, machine translation, and autonomous vehicle motion prediction. The dataset facilitates standardized evaluation of existing and future techniques."
  },
  {
    "title": "Causal Transfer Random Forest: Combining Logged Data and Randomized Experiments for Robust Prediction",
    "abstract": "It is often critical for prediction models to be robust to distributional shifts between training and testing data. From a causal perspective, the challenge is to distinguish the stable causal relationships from the unstable spurious correlations across shifts. We describe a causal transfer random forest (CTRF) that combines existing training data with a small amount of data from a randomized experiment to train a model which is robust to the feature shifts and therefore transfers to a new targeting distribution. Theoretically, we justify the robustness of the approach against feature shifts with the knowledge from causal learning. Empirically, we evaluate the CTRF using both synthetic data experiments and real-world experiments in the Bing Ads platform, including a click prediction task and in the context of an end-to-end counterfactual optimization system. The proposed CTRF produces robust predictions and outperforms most baseline methods compared in the presence of feature shifts.",
    "published_date": "2020-10-17",
    "citation_count": 18,
    "url": "https://dl.acm.org/doi/10.1145/3437963.3441722",
    "summary": "Causal Transfer Random Forest (CTRF) improves prediction model robustness to distributional shifts by combining logged data with randomized experimental data, leveraging causal inference to identify stable relationships and outperform methods that don't account for such shifts. Empirical results on synthetic and real-world data demonstrate its superior performance."
  },
  {
    "title": "RECORD: Resource Constrained Semi-Supervised Learning under Distribution Shift",
    "abstract": "Semi-supervised learning (SSL) tries to improve performance with the use of massive unlabeled data, which typically works in an offline manner with two assumptions. i) Data distribution is static; ii) Data storage overhead is unlimited. In many online tasks, however, none of the above assumptions is valid. For example, in online image classification, a large amount of unlabeled images increases sharply, which makes it difficult to store them in full; meanwhile, the content of unlabeled images changes constantly, and it is no longer suitable to assume a fixed distribution. We call such a novel setting Resource Constrained SSL under Distribution Shift (or Record for short) and to our best knowledge, it has not been thoroughly studied yet. This paper presents a systemic solution Record consisting of three sub-steps, that is, distribution tracking, sample selection and model updating. Specifically, we propose an effective method to track the distribution changes and locate distribution shifted samples. A novel influence-based approach is used to select the most influential samples for the distribution change based on resource constraints. Finally, we free up memory to put the latest unlabeled data with its pseudo-label for the next distribution tracking. Extensive empirical results confirm the effectiveness of our scheme. In the case of diverse and unknown distribution shifts, our solution is consistently and clearly better than many baseline and SOTA methods along with the memory budget and in some cases it can even approximate the performance of oracle.",
    "published_date": "2020-07-06",
    "citation_count": 18,
    "url": "https://dl.acm.org/doi/10.1145/3394486.3403214",
    "summary": "RECORD addresses the problem of semi-supervised learning under resource constraints and distribution shift, proposing a three-step solution (distribution tracking, sample selection, model updating) that effectively manages limited memory while adapting to evolving data distributions, outperforming existing methods in diverse scenarios."
  }
]
### Mini Description

Study of adversarial attacks and defenses in practical contexts, including physical-world attacks, sensor attacks, and domain-specific considerations.

### Description

Real-world applications of adversarial robustness research focus on understanding and addressing threats to AI systems as they operate in physical, unconstrained environments. Unlike digital attacks that directly modify input tensors, physical-world attacks must contend with environmental variables like lighting, perspective, and sensor noise while maintaining attack effectiveness. This introduces unique challenges in both attack creation and defense validation, as attacks must be robust across varying conditions and defense mechanisms must account for natural perturbations.

A key area of investigation is the interaction between AI systems and their sensing mechanisms, including cameras, lidar, microphones, and other sensors that bridge the physical-digital divide. Attacks can target these interfaces through techniques like adversarial patches, 3D-printed objects, or carefully crafted environmental modifications. Research in this space must consider practical constraints like attack implementability, persistence across different viewpoints, and the ability to affect multiple systems simultaneously.

Emerging research directions include the study of semantic attacks that preserve real-world plausibility while inducing targeted behaviors, the development of robust perception systems for autonomous vehicles and robotics, and the investigation of multi-modal attacks that exploit interactions between different sensing modalities. There's particular emphasis on understanding how adversarial vulnerabilities manifest in safety-critical applications like medical diagnosis, autonomous navigation, and security systems, where failures could have severe consequences.

### Order

1. Physical_Attack_Vectors
2. Sensor_Security
3. Safety-Critical_Systems
4. Environmental_Factors
5. Deployment_Constraints

[
  {
    "url": "https://arxiv.org/abs/2310.20102",
    "title": "Sample-Conditioned Hypothesis Stability Sharpens Information-Theoretic Generalization Bounds",
    "published_date": "2023-10-31",
    "abstract": "We present new information-theoretic generalization guarantees through the a novel construction of the\"neighboring-hypothesis\"matrix and a new family of stability notions termed sample-conditioned hypothesis (SCH) stability. Our approach yields sharper bounds that improve upon previous information-theoretic bounds in various learning scenarios. Notably, these bounds address the limitations of existing information-theoretic bounds in the context of stochastic convex optimization (SCO) problems, as explored in the recent work by Haghifam et al. (2023).",
    "citation_count": 4
  },
  {
    "url": "https://arxiv.org/abs/2309.13658",
    "title": "Fantastic Generalization Measures are Nowhere to be Found",
    "published_date": "2023-09-24",
    "abstract": "We study the notion of a generalization bound being uniformly tight, meaning that the difference between the bound and the population loss is small for all learning algorithms and all population distributions. Numerous generalization bounds have been proposed in the literature as potential explanations for the ability of neural networks to generalize in the overparameterized setting. However, in their paper ``Fantastic Generalization Measures and Where to Find Them,'' Jiang et al. (2020) examine more than a dozen generalization bounds, and show empirically that none of them are uniformly tight. This raises the question of whether uniformly-tight generalization bounds are at all possible in the overparameterized setting. We consider two types of generalization bounds: (1) bounds that may depend on the training set and the learned hypothesis (e.g., margin bounds). We prove mathematically that no such bound can be uniformly tight in the overparameterized setting; (2) bounds that may in addition also depend on the learning algorithm (e.g., stability bounds). For these bounds, we show a trade-off between the algorithm's performance and the bound's tightness. Namely, if the algorithm achieves good accuracy on certain distributions, then no generalization bound can be uniformly tight for it in the overparameterized setting. We explain how these formal results can, in our view, inform research on generalization bounds for neural networks, while stressing that other interpretations of these results are also possible.",
    "citation_count": 10
  },
  {
    "url": "https://arxiv.org/abs/2305.19674",
    "title": "Online-to-PAC Conversions: Generalization Bounds via Regret Analysis",
    "published_date": "2023-05-31",
    "abstract": "We present a new framework for deriving bounds on the generalization bound of statistical learning algorithms from the perspective of online learning. Specifically, we construct an online learning game called the\"generalization game\", where an online learner is trying to compete with a fixed statistical learning algorithm in predicting the sequence of generalization gaps on a training set of i.i.d. data points. We establish a connection between the online and statistical learning setting by showing that the existence of an online learning algorithm with bounded regret in this game implies a bound on the generalization error of the statistical learning algorithm, up to a martingale concentration term that is independent of the complexity of the statistical learning method. This technique allows us to recover several standard generalization bounds including a range of PAC-Bayesian and information-theoretic guarantees, as well as generalizations thereof.",
    "citation_count": 9
  },
  {
    "url": "https://arxiv.org/pdf/2307.04679.pdf",
    "title": "Minimax Excess Risk of First-Order Methods for Statistical Learning with Data-Dependent Oracles",
    "published_date": "2023-07-10",
    "abstract": "In this paper, our aim is to analyse the generalization capabilities of first-order methods for statistical learning in multiple, different yet related, scenarios including supervised learning, transfer learning, robust learning and federated learning. To do so, we provide sharp upper and lower bounds for the minimax excess risk of strongly convex and smooth statistical learning when the gradient is accessed through partial observations given by a data-dependent oracle. This novel class of oracles can query the gradient with any given data distribution, and is thus well suited to scenarios in which the training data distribution does not match the target (or test) distribution. In particular, our upper and lower bounds are proportional to the smallest mean square error achievable by gradient estimators, thus allowing us to easily derive multiple sharp bounds in the aforementioned scenarios using the extensive literature on parameter estimation.",
    "citation_count": 1
  },
  {
    "url": "https://www.alignmentforum.org/posts/uEwECj53prjKLcBC5/vc-theory-overview",
    "author": "Joar Skalse",
    "title": "VC Theory Overview",
    "published_date": "2023-07-02"
  },
  {
    "url": "https://www.lesswrong.com/s/mqwA5FcL6SrHEQzox",
    "author": "Jesse Hoogland",
    "title": "Singular Learning Theory - LessWrong",
    "published_date": "2023-02-16"
  }
]
[
  {
    "title": "Measuring the Carbon Intensity of AI in Cloud Instances",
    "abstract": "The advent of cloud computing has provided people around the world with unprecedented access to computational power and enabled rapid growth in technologies such as machine learning, the computational demands of which incur a high energy cost and a commensurate carbon footprint. As a result, recent scholarship has called for better estimates of the greenhouse gas impact of AI: data scientists today do not have easy or reliable access to measurements of this information, which precludes development of actionable tactics. We argue that cloud providers presenting information about software carbon intensity to users is a fundamental stepping stone towards minimizing emissions. In this paper, we provide a framework for measuring software carbon intensity, and propose to measure operational carbon emissions by using location-based and time-specific marginal emissions data per energy unit. We provide measurements of operational software carbon intensity for a set of modern models covering natural language processing and computer vision applications, and a wide range of model sizes, including pretraining of a 6.1 billion parameter language model. We then evaluate a suite of approaches for reducing emissions on the Microsoft Azure cloud compute platform: using cloud instances in different geographic regions, using cloud instances at different times of day, and dynamically pausing cloud instances when the marginal carbon intensity is above a certain threshold. We confirm previous results that the geographic region of the data center plays a significant role in the carbon intensity for a given cloud instance, and find that choosing an appropriate region can have the largest operational emissions reduction impact. We also present new results showing that the time of day has meaningful impact on operational software carbon intensity.Finally, we conclude with recommendations for how machine learning practitioners can use software carbon intensity information to reduce environmental impact.",
    "published_date": "2022-06-10",
    "citation_count": 154,
    "url": "https://dl.acm.org/doi/fullHtml/10.1145/3531146.3533234",
    "summary": "This paper presents a framework for measuring the carbon intensity of AI workloads in the cloud, quantifying emissions from various models and demonstrating significant reductions achievable through strategic choices of geographic region and time of day for cloud instance usage. The authors propose that cloud providers should make this carbon intensity information readily available to users."
  },
  {
    "title": "Artificial Intelligence and the Climate Emergency: Opportunities, Challenges, and Recommendations",
    "abstract": "Artificial intelligence (AI) has the potential to play an important role in addressing the climate emergency, but this potential must be set against the environmental costs of developing AI systems. In this commentary, we assess the carbon footprint of AI training processes and offer 14 policy recommendations to reduce it.",
    "published_date": "2021-06-01",
    "citation_count": 34,
    "url": "https://www.sciencedirect.com/science/article/pii/S2590332221002992",
    "summary": "AI offers significant potential for mitigating climate change, but its development carries a substantial carbon footprint; this commentary analyzes AI's environmental impact and proposes policy recommendations to minimize it."
  },
  {
    "url": "https://www.lesswrong.com/posts/G4KHuYC3pHry6yMhi/compute-research-questions-and-metrics-transformative-ai-and",
    "author": "lennart",
    "title": "Compute Research Questions and Metrics - Transformative AI and Compute [4/4]",
    "published_date": "2021-11-28",
    "summary": "This appendix to a series on transformative AI and compute explores research questions surrounding AI hardware, compute trends, and their economic implications. It also provides metrics for compute and a list of AI hardware startups."
  },
  {
    "url": "https://www.lesswrong.com/posts/uYXAv6Audr2y4ytJe/what-is-compute-transformative-ai-and-compute-1-4",
    "author": "lennart",
    "title": "What is Compute? - Transformative AI and Compute [1/4]",
    "published_date": "2021-09-23",
    "summary": "This four-part series, focusing on the intersection of transformative AI and computing, begins by introducing a simplified model of computation and its role in AI systems. The author explores the historical relationship between compute trends and increasingly capable AI, offering an updated \"compute plot\" and acknowledging limitations in their analysis."
  },
  {
    "url": "https://www.lesswrong.com/tag/impact-regularization",
    "author": "TurnTrout",
    "title": "Impact Regularization - LessWrong",
    "published_date": "2020-03-03",
    "summary": "Impact regularizers aim to prevent powerful AI systems from causing excessive disruption by penalizing actions that significantly alter the world. Current research focuses on maintaining the AI's ability to achieve various goals (relative reachability and attainable utility preservation) to mitigate risks of power-seeking behavior."
  },
  {
    "url": "https://www.lesswrong.com/posts/q3xFWK3qcR7JGTxsv/ai-benefits-post-3-direct-and-indirect-approaches-to-ai",
    "author": "Cullen",
    "title": "AI Benefits Post 3: Direct and Indirect Approaches to AI Benefits",
    "published_date": "2020-07-06",
    "summary": "The article distinguishes between direct and indirect approaches to achieving AI benefits: direct application of AI to solve problems versus maximizing profits to donate to organizations better suited for addressing specific issues. The optimal approach varies depending on an organization's resources and capabilities, highlighting the need for a balanced portfolio of both direct and indirect benefit-seeking strategies."
  },
  {
    "url": "https://www.lesswrong.com/s/7CdoznhJaLEKHwvJW/p/LfGzAduBWzY5gq6FE",
    "author": "TurnTrout",
    "title": "How Low Should Fruit Hang Before We Pick It?",
    "published_date": "2020-02-25",
    "summary": "The article demonstrates that an AI agent's actions, even with a measurable impact, can be effectively controlled using only four parameters to balance utility and impact. This allows for the selection of reasonable plans avoiding catastrophic outcomes, enhancing agent competitiveness and providing insights into diminishing returns and cost-benefit analysis."
  },
  {
    "url": "https://www.lesswrong.com/posts/pf48kg9xCxJAcHmQc/understanding-recent-impact-measures",
    "author": "Matthew Barnett",
    "title": "Understanding Recent Impact Measures",
    "published_date": "2019-08-07",
    "summary": "Recent research on AI impact measures has significantly expanded upon early work, focusing on two prominent methods: relative reachability and attainable utility. These approaches, defined within a Markov decision process framework, address limitations of previous research by incorporating concepts like state reversibility and penalizing unintended side effects."
  }
]